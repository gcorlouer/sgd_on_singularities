{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from typing import Optional\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write classes for linear and singular models that we are going to use train SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.insert(0, \"lib\")\n",
    "from onedmodel import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Linear model and visualise the loss curve and visualise the training dynamics on the loss landscape (for sanity check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pure diffusion\n",
    "SGD makes the trivial model $Y = f(w) \\times X + \\varepsilon$ with $f(w) = w$ diffuse in parameter space $w \\in \\mathbb R$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrivialModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Trivial, single parameter model\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super(TrivialModel, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.randn([1]))\n",
    "\n",
    "    def forward(self, input:Tensor):\n",
    "        return input * self.weight**2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "torch.manual_seed(4) # for reproducibility\n",
    "num_samples = 10\n",
    "num_epochs = 10**2\n",
    "batch_size = 1\n",
    "lr = 0.1\n",
    "\n",
    "x_data, y_data = torch.normal(0, 1, (2, num_samples))\n",
    "dataset = TensorDataset(x_data, y_data)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Train function\n",
    "model = TrivialModel()\n",
    "loss_values, weights_over_epochs =  train_model(model, data_loader, linear = False, num_epochs = num_epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_range = np.linspace(-1, 1, 100)\n",
    "fig, ax = plt.subplots()\n",
    "plot_loss_landscape(ax, model, x_data, y_data, weight_range, weights_over_epochs, linear=False)\n",
    "plt.grid()\n",
    "ax.set_yscale('linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrivialModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Trivial, single parameter model\n",
    "    \"\"\"\n",
    "    def __init__(self, w_init) -> None:\n",
    "        super(TrivialModel, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(w_init)\n",
    "\n",
    "    def forward(self, input:Tensor):\n",
    "        return input * self.weight**2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 420\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2689],\n",
      "        [-0.1077]])\n",
      "batch_y tensor([[0.0934],\n",
      "        [0.2212]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 421\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0681],\n",
      "        [-0.0630]])\n",
      "batch_y tensor([[ 0.6968],\n",
      "        [-0.1353]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 422\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6851],\n",
      "        [-0.2070]])\n",
      "batch_y tensor([[ 0.0188],\n",
      "        [-0.0589]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 423\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 2.0754],\n",
      "        [-0.6170]])\n",
      "batch_y tensor([[0.1136],\n",
      "        [0.0098]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 424\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0025],\n",
      "        [0.1246]])\n",
      "batch_y tensor([[ 0.0217],\n",
      "        [-0.8318]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 425\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1384],\n",
      "        [0.2682]])\n",
      "batch_y tensor([[0.0103],\n",
      "        [0.0053]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 426\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6959],\n",
      "        [0.0313]])\n",
      "batch_y tensor([[0.0223],\n",
      "        [0.4900]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 427\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1249],\n",
      "        [-0.1857]])\n",
      "batch_y tensor([[0.4028],\n",
      "        [3.8361]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 428\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0441],\n",
      "        [-0.2420]])\n",
      "batch_y tensor([[0.3653],\n",
      "        [0.0897]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 429\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2567],\n",
      "        [ 0.1001]])\n",
      "batch_y tensor([[-0.0147],\n",
      "        [ 0.0330]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 430\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0532],\n",
      "        [-0.0904]])\n",
      "batch_y tensor([[ 0.0528],\n",
      "        [-0.0648]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 431\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1370],\n",
      "        [-0.1710]])\n",
      "batch_y tensor([[12.8843],\n",
      "        [ 0.3760]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 432\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1181],\n",
      "        [-0.2015]])\n",
      "batch_y tensor([[-0.4142],\n",
      "        [-0.2740]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 433\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1935],\n",
      "        [ 0.1432]])\n",
      "batch_y tensor([[0.1751],\n",
      "        [0.0661]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 434\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1463],\n",
      "        [-0.2173]])\n",
      "batch_y tensor([[0.0773],\n",
      "        [0.0259]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 435\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1147],\n",
      "        [-0.0313]])\n",
      "batch_y tensor([[-0.0043],\n",
      "        [-0.0214]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 436\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3340],\n",
      "        [0.0376]])\n",
      "batch_y tensor([[-0.0117],\n",
      "        [-0.1359]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 437\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0601],\n",
      "        [0.6642]])\n",
      "batch_y tensor([[-0.0137],\n",
      "        [ 0.0938]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 438\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0710],\n",
      "        [0.2265]])\n",
      "batch_y tensor([[-0.3941],\n",
      "        [ 0.5200]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 439\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0253],\n",
      "        [0.1469]])\n",
      "batch_y tensor([[-0.1333],\n",
      "        [ 0.0380]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 440\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1561],\n",
      "        [-0.1122]])\n",
      "batch_y tensor([[-3.8083],\n",
      "        [ 0.0159]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 441\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0095],\n",
      "        [-0.3791]])\n",
      "batch_y tensor([[ 0.6538],\n",
      "        [-0.0594]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 442\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1157],\n",
      "        [-0.3180]])\n",
      "batch_y tensor([[0.2178],\n",
      "        [0.0201]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 443\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0219],\n",
      "        [0.1177]])\n",
      "batch_y tensor([[-0.0034],\n",
      "        [ 0.0787]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 444\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0287],\n",
      "        [ 0.0335]])\n",
      "batch_y tensor([[-0.0554],\n",
      "        [ 0.0316]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 445\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0184],\n",
      "        [ 0.6700]])\n",
      "batch_y tensor([[0.4155],\n",
      "        [0.1428]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 446\n",
      "================\n",
      "\n",
      "batch_x tensor([[  0.3059],\n",
      "        [-34.8098]])\n",
      "batch_y tensor([[-0.0679],\n",
      "        [ 0.0648]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 447\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1071],\n",
      "        [0.1981]])\n",
      "batch_y tensor([[-0.0128],\n",
      "        [-0.0494]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 448\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0548],\n",
      "        [-0.0773]])\n",
      "batch_y tensor([[0.2107],\n",
      "        [0.5654]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 449\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0656],\n",
      "        [1.9873]])\n",
      "batch_y tensor([[-0.1490],\n",
      "        [ 0.3446]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 450\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1025],\n",
      "        [-0.0290]])\n",
      "batch_y tensor([[ 0.0611],\n",
      "        [-0.0226]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 451\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4072],\n",
      "        [-0.7619]])\n",
      "batch_y tensor([[-0.1418],\n",
      "        [-0.1866]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 452\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0032],\n",
      "        [-0.0427]])\n",
      "batch_y tensor([[0.0582],\n",
      "        [0.1035]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 453\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1348],\n",
      "        [0.0317]])\n",
      "batch_y tensor([[ 0.0442],\n",
      "        [-0.6142]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 454\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0381],\n",
      "        [-0.1205]])\n",
      "batch_y tensor([[0.0301],\n",
      "        [0.1874]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 455\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1403],\n",
      "        [0.0250]])\n",
      "batch_y tensor([[-0.1393],\n",
      "        [-0.3594]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 456\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0729],\n",
      "        [-0.0344]])\n",
      "batch_y tensor([[-0.0030],\n",
      "        [ 0.1308]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 457\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3794],\n",
      "        [-0.0461]])\n",
      "batch_y tensor([[-0.0759],\n",
      "        [ 0.0224]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 458\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0299],\n",
      "        [-0.1965]])\n",
      "batch_y tensor([[ 0.8072],\n",
      "        [-0.1720]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 459\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1340],\n",
      "        [ 0.0435]])\n",
      "batch_y tensor([[0.1586],\n",
      "        [0.2335]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 460\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0790],\n",
      "        [-0.3475]])\n",
      "batch_y tensor([[1.0403],\n",
      "        [0.1288]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 461\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1632],\n",
      "        [0.6032]])\n",
      "batch_y tensor([[ 0.0234],\n",
      "        [-0.0759]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 462\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0307],\n",
      "        [0.3828]])\n",
      "batch_y tensor([[0.0202],\n",
      "        [0.0317]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 463\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1835],\n",
      "        [-0.0048]])\n",
      "batch_y tensor([[-0.0089],\n",
      "        [-0.2239]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 464\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0216],\n",
      "        [ 1.1196]])\n",
      "batch_y tensor([[-0.1879],\n",
      "        [-0.0656]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 465\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1222],\n",
      "        [-0.0779]])\n",
      "batch_y tensor([[-0.1489],\n",
      "        [ 0.0454]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 466\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1194],\n",
      "        [-0.2214]])\n",
      "batch_y tensor([[0.0679],\n",
      "        [0.0134]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 467\n",
      "================\n",
      "\n",
      "batch_x tensor([[-3.6585],\n",
      "        [ 0.0735]])\n",
      "batch_y tensor([[ 0.0729],\n",
      "        [-0.1613]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 468\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2701],\n",
      "        [ 0.0864]])\n",
      "batch_y tensor([[0.4128],\n",
      "        [0.0622]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 469\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0010],\n",
      "        [0.0314]])\n",
      "batch_y tensor([[0.6702],\n",
      "        [0.0384]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 470\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0438],\n",
      "        [ 0.3112]])\n",
      "batch_y tensor([[-0.0421],\n",
      "        [-1.6625]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 471\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0382],\n",
      "        [-0.7639]])\n",
      "batch_y tensor([[-0.0860],\n",
      "        [ 2.9238]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 472\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0565],\n",
      "        [ 0.0567]])\n",
      "batch_y tensor([[-0.1500],\n",
      "        [ 0.5450]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 473\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2488],\n",
      "        [-0.0234]])\n",
      "batch_y tensor([[-0.0688],\n",
      "        [ 0.3033]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 474\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0980],\n",
      "        [-0.2270]])\n",
      "batch_y tensor([[ 0.7191],\n",
      "        [-0.1743]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 475\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0314],\n",
      "        [-0.0189]])\n",
      "batch_y tensor([[-0.0513],\n",
      "        [-1.3523]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 476\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0061],\n",
      "        [-0.0543]])\n",
      "batch_y tensor([[-0.0340],\n",
      "        [-0.1267]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 477\n",
      "================\n",
      "\n",
      "batch_x tensor([[  0.6396],\n",
      "        [-22.1950]])\n",
      "batch_y tensor([[ 0.7479],\n",
      "        [-0.1331]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 478\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0316],\n",
      "        [-0.0504]])\n",
      "batch_y tensor([[-0.2082],\n",
      "        [-0.0190]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 479\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0252],\n",
      "        [-0.0479]])\n",
      "batch_y tensor([[0.0934],\n",
      "        [0.0610]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 480\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1060],\n",
      "        [-0.0443]])\n",
      "batch_y tensor([[-0.1975],\n",
      "        [ 0.0402]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 481\n",
      "================\n",
      "\n",
      "batch_x tensor([[-8.2940e+00],\n",
      "        [ 4.9398e-03]])\n",
      "batch_y tensor([[-0.1497],\n",
      "        [-0.3343]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 482\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1602],\n",
      "        [-0.5552]])\n",
      "batch_y tensor([[ 0.1166],\n",
      "        [-0.0185]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 483\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4914],\n",
      "        [-0.0578]])\n",
      "batch_y tensor([[-0.0077],\n",
      "        [-0.0220]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 484\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0030],\n",
      "        [-0.0588]])\n",
      "batch_y tensor([[-0.0171],\n",
      "        [ 0.0633]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 485\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.1099],\n",
      "        [-0.4542]])\n",
      "batch_y tensor([[-0.0403],\n",
      "        [ 0.0059]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 486\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0137],\n",
      "        [-2.9551]])\n",
      "batch_y tensor([[0.0871],\n",
      "        [0.1838]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 487\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0055],\n",
      "        [-0.2811]])\n",
      "batch_y tensor([[-0.0736],\n",
      "        [ 0.3160]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 488\n",
      "================\n",
      "\n",
      "batch_x tensor([[-3.1850],\n",
      "        [-0.2837]])\n",
      "batch_y tensor([[-0.0756],\n",
      "        [ 0.0339]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 489\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1029],\n",
      "        [ 0.0598]])\n",
      "batch_y tensor([[0.3501],\n",
      "        [0.0309]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 490\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0940],\n",
      "        [0.2329]])\n",
      "batch_y tensor([[1.3751],\n",
      "        [0.1007]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 491\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1447],\n",
      "        [0.1288]])\n",
      "batch_y tensor([[ 0.4693],\n",
      "        [-0.0301]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 492\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.8467],\n",
      "        [-0.1819]])\n",
      "batch_y tensor([[0.1318],\n",
      "        [0.6645]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 493\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6637],\n",
      "        [-0.2479]])\n",
      "batch_y tensor([[-0.0846],\n",
      "        [-0.0443]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 494\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0280],\n",
      "        [-0.0087]])\n",
      "batch_y tensor([[0.1970],\n",
      "        [0.1693]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 495\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5938],\n",
      "        [-0.0780]])\n",
      "batch_y tensor([[-0.0169],\n",
      "        [ 0.1424]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 496\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5540],\n",
      "        [-0.1269]])\n",
      "batch_y tensor([[0.0192],\n",
      "        [0.1622]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 497\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1032],\n",
      "        [-0.1524]])\n",
      "batch_y tensor([[ 0.0145],\n",
      "        [-0.3027]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 498\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0274],\n",
      "        [-0.2255]])\n",
      "batch_y tensor([[0.1619],\n",
      "        [0.0525]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 499\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.9411],\n",
      "        [ 0.0480]])\n",
      "batch_y tensor([[-0.1743],\n",
      "        [ 0.0613]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 0\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1604],\n",
      "        [ 0.0958]])\n",
      "batch_y tensor([[ 0.0136],\n",
      "        [-0.2615]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 1\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.8586],\n",
      "        [ 0.0423]])\n",
      "batch_y tensor([[-0.2599],\n",
      "        [-0.0175]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 2\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0447],\n",
      "        [-0.2070]])\n",
      "batch_y tensor([[ 0.1062],\n",
      "        [-0.0589]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 3\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0013],\n",
      "        [ 0.0303]])\n",
      "batch_y tensor([[-0.0254],\n",
      "        [ 0.1629]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 4\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1048],\n",
      "        [-0.0497]])\n",
      "batch_y tensor([[-0.0367],\n",
      "        [-0.1068]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 5\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0407],\n",
      "        [ 0.0163]])\n",
      "batch_y tensor([[ 0.0641],\n",
      "        [-1.0637]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 6\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1981],\n",
      "        [0.3112]])\n",
      "batch_y tensor([[-0.0494],\n",
      "        [-1.6625]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 7\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0251],\n",
      "        [ 0.3606]])\n",
      "batch_y tensor([[-0.6435],\n",
      "        [ 0.5226]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 8\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0085],\n",
      "        [-0.3951]])\n",
      "batch_y tensor([[0.1964],\n",
      "        [0.1462]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 9\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0044],\n",
      "        [ 0.0772]])\n",
      "batch_y tensor([[-0.3114],\n",
      "        [-0.6835]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 10\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6437],\n",
      "        [ 0.3260]])\n",
      "batch_y tensor([[-0.0498],\n",
      "        [-0.3484]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 11\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0109],\n",
      "        [-0.0106]])\n",
      "batch_y tensor([[-0.1430],\n",
      "        [-0.0464]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 12\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 6.7593e-02],\n",
      "        [-1.1666e+02]])\n",
      "batch_y tensor([[ 0.1392],\n",
      "        [-0.4727]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 13\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.5226],\n",
      "        [0.3763]])\n",
      "batch_y tensor([[-0.3906],\n",
      "        [ 0.0017]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 14\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0257],\n",
      "        [2.3356]])\n",
      "batch_y tensor([[-12.0153],\n",
      "        [ -4.1971]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 15\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0361],\n",
      "        [ 0.2789]])\n",
      "batch_y tensor([[ 0.3883],\n",
      "        [-0.0617]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 16\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0408],\n",
      "        [0.0502]])\n",
      "batch_y tensor([[-0.0292],\n",
      "        [-0.2100]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 17\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0846],\n",
      "        [-0.7334]])\n",
      "batch_y tensor([[ 0.3187],\n",
      "        [-0.0711]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 18\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4624],\n",
      "        [-0.1767]])\n",
      "batch_y tensor([[-0.0838],\n",
      "        [-0.5116]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 19\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1265],\n",
      "        [-0.0049]])\n",
      "batch_y tensor([[0.2331],\n",
      "        [0.0845]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 20\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1340],\n",
      "        [-0.1060]])\n",
      "batch_y tensor([[ 0.1586],\n",
      "        [-0.0911]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 21\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2205],\n",
      "        [ 0.3828]])\n",
      "batch_y tensor([[0.0539],\n",
      "        [0.0317]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 22\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0098],\n",
      "        [0.0216]])\n",
      "batch_y tensor([[-0.0619],\n",
      "        [-2.1257]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 23\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1432],\n",
      "        [0.1428]])\n",
      "batch_y tensor([[ 0.0661],\n",
      "        [-0.1005]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 24\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2548],\n",
      "        [-0.0304]])\n",
      "batch_y tensor([[-1.0940],\n",
      "        [ 0.0206]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 25\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6515],\n",
      "        [ 0.0653]])\n",
      "batch_y tensor([[0.1081],\n",
      "        [0.0373]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 26\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0936],\n",
      "        [-0.0040]])\n",
      "batch_y tensor([[ 0.1237],\n",
      "        [-0.0732]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 27\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0425],\n",
      "        [ 0.0014]])\n",
      "batch_y tensor([[-3.8582],\n",
      "        [-0.0609]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 28\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2715],\n",
      "        [0.8467]])\n",
      "batch_y tensor([[0.0240],\n",
      "        [0.1318]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 29\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1037],\n",
      "        [ 0.1632]])\n",
      "batch_y tensor([[-0.5053],\n",
      "        [ 0.0234]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 30\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0869],\n",
      "        [-0.0438]])\n",
      "batch_y tensor([[ 0.1932],\n",
      "        [-0.0088]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 31\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0391],\n",
      "        [ 0.4920]])\n",
      "batch_y tensor([[ 1.0304e-04],\n",
      "        [-3.3030e-01]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 32\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0532],\n",
      "        [ 0.1586]])\n",
      "batch_y tensor([[0.0528],\n",
      "        [0.8402]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 33\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0853],\n",
      "        [0.0285]])\n",
      "batch_y tensor([[ 0.0802],\n",
      "        [-0.1544]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 34\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0335],\n",
      "        [-0.0745]])\n",
      "batch_y tensor([[ 0.0316],\n",
      "        [-0.1465]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 35\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0758],\n",
      "        [0.0504]])\n",
      "batch_y tensor([[-0.0307],\n",
      "        [-0.1404]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 36\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6032],\n",
      "        [-0.1213]])\n",
      "batch_y tensor([[-0.0759],\n",
      "        [-0.0226]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 37\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5396],\n",
      "        [-0.0663]])\n",
      "batch_y tensor([[0.1226],\n",
      "        [0.2775]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 38\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0036],\n",
      "        [-0.0630]])\n",
      "batch_y tensor([[9.8770e+00],\n",
      "        [7.5831e-03]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 39\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.7025],\n",
      "        [-0.0246]])\n",
      "batch_y tensor([[-1.0155],\n",
      "        [ 0.2093]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 40\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1090],\n",
      "        [-0.0749]])\n",
      "batch_y tensor([[0.0166],\n",
      "        [0.0186]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 41\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.9925],\n",
      "        [-0.1339]])\n",
      "batch_y tensor([[-0.0466],\n",
      "        [-0.1319]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 42\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0466],\n",
      "        [ 0.0118]])\n",
      "batch_y tensor([[-0.0467],\n",
      "        [-0.0301]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 43\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4255],\n",
      "        [ 0.1863]])\n",
      "batch_y tensor([[ 1.8376],\n",
      "        [-0.9076]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 44\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0598],\n",
      "        [0.0643]])\n",
      "batch_y tensor([[0.0309],\n",
      "        [0.1768]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 45\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1146],\n",
      "        [ 0.1040]])\n",
      "batch_y tensor([[ 0.0245],\n",
      "        [-0.0756]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 46\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0835],\n",
      "        [-0.4795]])\n",
      "batch_y tensor([[ 0.0360],\n",
      "        [-0.0924]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 47\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.9411],\n",
      "        [ 0.0056]])\n",
      "batch_y tensor([[-0.1743],\n",
      "        [-0.0999]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 48\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1157],\n",
      "        [ 0.0076]])\n",
      "batch_y tensor([[0.2178],\n",
      "        [0.7841]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 49\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2229],\n",
      "        [-0.0322]])\n",
      "batch_y tensor([[ 0.0560],\n",
      "        [-0.0967]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 50\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1203],\n",
      "        [-0.1169]])\n",
      "batch_y tensor([[ 0.0147],\n",
      "        [-0.5648]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 51\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0487],\n",
      "        [-0.0359]])\n",
      "batch_y tensor([[ 0.0392],\n",
      "        [-0.0695]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 52\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0548],\n",
      "        [-2.8702]])\n",
      "batch_y tensor([[ 0.2107],\n",
      "        [-0.0834]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 53\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1403],\n",
      "        [0.3510]])\n",
      "batch_y tensor([[-0.1393],\n",
      "        [-0.1403]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 54\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1641],\n",
      "        [-0.8598]])\n",
      "batch_y tensor([[0.0285],\n",
      "        [0.1609]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 55\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2905],\n",
      "        [-0.0240]])\n",
      "batch_y tensor([[ 0.0310],\n",
      "        [-0.0761]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 56\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0436],\n",
      "        [0.0557]])\n",
      "batch_y tensor([[-0.0032],\n",
      "        [ 0.1199]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 57\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1710],\n",
      "        [ 0.0094]])\n",
      "batch_y tensor([[0.3760],\n",
      "        [0.0123]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 58\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0277],\n",
      "        [ 0.1274]])\n",
      "batch_y tensor([[0.0043],\n",
      "        [0.0850]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 59\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0905],\n",
      "        [-0.5625]])\n",
      "batch_y tensor([[47.0076],\n",
      "        [ 0.1459]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 60\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2953],\n",
      "        [-0.1861]])\n",
      "batch_y tensor([[-1.7853],\n",
      "        [-0.0635]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 61\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0090],\n",
      "        [-0.2255]])\n",
      "batch_y tensor([[-0.0368],\n",
      "        [ 0.0525]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 62\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0049],\n",
      "        [0.0366]])\n",
      "batch_y tensor([[ 0.0956],\n",
      "        [-0.9923]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 63\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0057],\n",
      "        [0.0185]])\n",
      "batch_y tensor([[-0.0463],\n",
      "        [-0.0824]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 64\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0240],\n",
      "        [0.0101]])\n",
      "batch_y tensor([[-0.0115],\n",
      "        [ 0.0024]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 65\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1440],\n",
      "        [0.0480]])\n",
      "batch_y tensor([[0.0262],\n",
      "        [0.0613]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 66\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2016],\n",
      "        [ 0.0372]])\n",
      "batch_y tensor([[-0.1150],\n",
      "        [ 0.0465]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 67\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0481],\n",
      "        [ 0.2878]])\n",
      "batch_y tensor([[-0.0184],\n",
      "        [-0.1774]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 68\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0145],\n",
      "        [ 0.7449]])\n",
      "batch_y tensor([[-0.0449],\n",
      "        [-0.3689]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 69\n",
      "================\n",
      "\n",
      "batch_x tensor([[-34.8098],\n",
      "        [  0.2386]])\n",
      "batch_y tensor([[ 0.0648],\n",
      "        [-0.1309]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 70\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0252],\n",
      "        [ 0.8248]])\n",
      "batch_y tensor([[ 0.0934],\n",
      "        [-0.0647]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 71\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0178],\n",
      "        [-0.1120]])\n",
      "batch_y tensor([[0.2084],\n",
      "        [0.0543]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 72\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0108],\n",
      "        [-0.5552]])\n",
      "batch_y tensor([[-0.0006],\n",
      "        [-0.0185]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 73\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1276],\n",
      "        [-0.0565]])\n",
      "batch_y tensor([[ 0.1011],\n",
      "        [-0.1500]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 74\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0307],\n",
      "        [0.0333]])\n",
      "batch_y tensor([[ 0.0202],\n",
      "        [-0.0064]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 75\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0868],\n",
      "        [0.0983]])\n",
      "batch_y tensor([[0.0358],\n",
      "        [0.2107]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 76\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1965],\n",
      "        [ 0.0274]])\n",
      "batch_y tensor([[-0.1720],\n",
      "        [-0.7972]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 77\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0381],\n",
      "        [-0.0087]])\n",
      "batch_y tensor([[0.0301],\n",
      "        [0.1693]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 78\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0491],\n",
      "        [-0.0329]])\n",
      "batch_y tensor([[-0.0259],\n",
      "        [-1.7879]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 79\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0641],\n",
      "        [ 0.2097]])\n",
      "batch_y tensor([[-0.1445],\n",
      "        [ 0.0714]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 80\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.6100],\n",
      "        [-0.7019]])\n",
      "batch_y tensor([[-0.1942],\n",
      "        [-0.2484]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 81\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0482],\n",
      "        [0.1463]])\n",
      "batch_y tensor([[-0.0284],\n",
      "        [ 0.0773]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 82\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.2398e-01],\n",
      "        [ 7.0559e-05]])\n",
      "batch_y tensor([[ 0.1792],\n",
      "        [-0.0220]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 83\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0313],\n",
      "        [0.0122]])\n",
      "batch_y tensor([[ 0.4900],\n",
      "        [-0.2908]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 84\n",
      "================\n",
      "\n",
      "batch_x tensor([[13.4745],\n",
      "        [-0.1587]])\n",
      "batch_y tensor([[0.0231],\n",
      "        [0.2074]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 85\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0018],\n",
      "        [-0.0422]])\n",
      "batch_y tensor([[ 0.1391],\n",
      "        [-0.2286]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 86\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0230],\n",
      "        [0.3340]])\n",
      "batch_y tensor([[-0.1815],\n",
      "        [-0.0117]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 87\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0129],\n",
      "        [-0.0438]])\n",
      "batch_y tensor([[-0.1011],\n",
      "        [-0.0421]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 88\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0365],\n",
      "        [-0.1035]])\n",
      "batch_y tensor([[-0.0159],\n",
      "        [ 0.4045]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 89\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0628],\n",
      "        [-0.0007]])\n",
      "batch_y tensor([[0.0894],\n",
      "        [0.9142]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 90\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0438],\n",
      "        [-0.0399]])\n",
      "batch_y tensor([[-0.8253],\n",
      "        [-0.1023]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 91\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2701],\n",
      "        [ 1.0695]])\n",
      "batch_y tensor([[0.4128],\n",
      "        [0.0315]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 92\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0285],\n",
      "        [-0.1237]])\n",
      "batch_y tensor([[ 0.1520],\n",
      "        [-0.1687]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 93\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1077],\n",
      "        [-0.2671]])\n",
      "batch_y tensor([[-0.0273],\n",
      "        [ 0.0076]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 94\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0231],\n",
      "        [ 0.0827]])\n",
      "batch_y tensor([[0.0549],\n",
      "        [0.1214]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 95\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0860],\n",
      "        [-0.1169]])\n",
      "batch_y tensor([[-0.2786],\n",
      "        [ 0.1104]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 96\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0034],\n",
      "        [0.0754]])\n",
      "batch_y tensor([[-0.0027],\n",
      "        [ 0.1254]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 97\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0629],\n",
      "        [-0.2800]])\n",
      "batch_y tensor([[-0.3234],\n",
      "        [ 0.1381]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 98\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0017],\n",
      "        [-0.0010]])\n",
      "batch_y tensor([[-0.1252],\n",
      "        [ 0.0279]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 99\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0733],\n",
      "        [-0.1585]])\n",
      "batch_y tensor([[0.0132],\n",
      "        [0.3778]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 100\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0588],\n",
      "        [ 0.2054]])\n",
      "batch_y tensor([[-0.0454],\n",
      "        [ 0.1343]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 101\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4859],\n",
      "        [ 0.3663]])\n",
      "batch_y tensor([[0.1397],\n",
      "        [0.5751]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 102\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1111],\n",
      "        [ 0.2424]])\n",
      "batch_y tensor([[-0.0658],\n",
      "        [-0.0225]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 103\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2179],\n",
      "        [-0.0980]])\n",
      "batch_y tensor([[-0.0509],\n",
      "        [ 0.7191]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 104\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0524],\n",
      "        [-0.1223]])\n",
      "batch_y tensor([[ 0.9598],\n",
      "        [-0.0043]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 105\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0335],\n",
      "        [-0.2873]])\n",
      "batch_y tensor([[ 0.0103],\n",
      "        [-0.3047]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 106\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0030],\n",
      "        [-0.0924]])\n",
      "batch_y tensor([[-0.0171],\n",
      "        [-0.2056]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 107\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1366],\n",
      "        [-0.0612]])\n",
      "batch_y tensor([[ 0.2516],\n",
      "        [-0.0729]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 108\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1571],\n",
      "        [-0.0371]])\n",
      "batch_y tensor([[0.0096],\n",
      "        [0.0129]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 109\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0052],\n",
      "        [0.1202]])\n",
      "batch_y tensor([[-0.0579],\n",
      "        [-0.0200]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 110\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.9544],\n",
      "        [-0.1879]])\n",
      "batch_y tensor([[-12.2048],\n",
      "        [  0.0126]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 111\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.3196],\n",
      "        [-0.0543]])\n",
      "batch_y tensor([[ 0.3048],\n",
      "        [-0.3313]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 112\n",
      "================\n",
      "\n",
      "batch_x tensor([[2.0899],\n",
      "        [2.3349]])\n",
      "batch_y tensor([[ 0.0265],\n",
      "        [-0.1924]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 113\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0023],\n",
      "        [ 0.1100]])\n",
      "batch_y tensor([[-0.0940],\n",
      "        [-0.0147]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 114\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1981],\n",
      "        [-0.8350]])\n",
      "batch_y tensor([[ 0.4482],\n",
      "        [-0.1049]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 115\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 5.9961],\n",
      "        [-0.6170]])\n",
      "batch_y tensor([[0.0227],\n",
      "        [0.0098]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 116\n",
      "================\n",
      "\n",
      "batch_x tensor([[-8.2940],\n",
      "        [ 0.2709]])\n",
      "batch_y tensor([[-0.1497],\n",
      "        [-1.0447]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 117\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2657],\n",
      "        [-0.0230]])\n",
      "batch_y tensor([[-1.2828],\n",
      "        [ 0.0399]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 118\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3180],\n",
      "        [ 0.1602]])\n",
      "batch_y tensor([[0.0201],\n",
      "        [0.1166]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 119\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1794],\n",
      "        [-0.5470]])\n",
      "batch_y tensor([[ 0.0365],\n",
      "        [-0.0774]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 120\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0574],\n",
      "        [-0.3120]])\n",
      "batch_y tensor([[-0.1083],\n",
      "        [-0.0441]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 121\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2072],\n",
      "        [-0.0377]])\n",
      "batch_y tensor([[0.1975],\n",
      "        [0.3356]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 122\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0864],\n",
      "        [0.2061]])\n",
      "batch_y tensor([[ 0.0622],\n",
      "        [-0.2202]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 123\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0261],\n",
      "        [-0.0543]])\n",
      "batch_y tensor([[ 1.2595],\n",
      "        [-0.1267]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 124\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0344],\n",
      "        [-0.0287]])\n",
      "batch_y tensor([[ 0.1966],\n",
      "        [-0.0554]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 125\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1786],\n",
      "        [-0.1524]])\n",
      "batch_y tensor([[ 0.6692],\n",
      "        [-0.3027]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 126\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1526],\n",
      "        [-0.1557]])\n",
      "batch_y tensor([[ 0.0952],\n",
      "        [-0.3630]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 127\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0092],\n",
      "        [ 0.4107]])\n",
      "batch_y tensor([[-0.0996],\n",
      "        [-0.0836]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 128\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1515],\n",
      "        [0.0601]])\n",
      "batch_y tensor([[-0.1442],\n",
      "        [-0.0137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 129\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0681],\n",
      "        [ 0.0389]])\n",
      "batch_y tensor([[0.6968],\n",
      "        [0.0824]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 130\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0639],\n",
      "        [-7.9219]])\n",
      "batch_y tensor([[-0.0120],\n",
      "        [ 0.1399]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 131\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1469],\n",
      "        [0.0650]])\n",
      "batch_y tensor([[ 0.0380],\n",
      "        [-0.0476]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 132\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6472],\n",
      "        [ 0.0151]])\n",
      "batch_y tensor([[-0.0096],\n",
      "        [ 0.2466]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 133\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0588],\n",
      "        [ 0.3923]])\n",
      "batch_y tensor([[0.0633],\n",
      "        [2.6874]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 134\n",
      "================\n",
      "\n",
      "batch_x tensor([[-9.3257],\n",
      "        [ 0.0276]])\n",
      "batch_y tensor([[ 0.1101],\n",
      "        [-0.2095]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 135\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0186],\n",
      "        [-0.0869]])\n",
      "batch_y tensor([[-0.1993],\n",
      "        [-0.0435]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 136\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1672],\n",
      "        [-0.0175]])\n",
      "batch_y tensor([[-0.1421],\n",
      "        [-0.0710]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 137\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.0324],\n",
      "        [-0.0313]])\n",
      "batch_y tensor([[ 0.0864],\n",
      "        [-0.0214]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 138\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0205],\n",
      "        [ 0.2515]])\n",
      "batch_y tensor([[-0.4021],\n",
      "        [-0.6137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 139\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0215],\n",
      "        [1.3260]])\n",
      "batch_y tensor([[0.0391],\n",
      "        [0.1241]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 140\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2232],\n",
      "        [ 0.0544]])\n",
      "batch_y tensor([[ 0.0623],\n",
      "        [-0.1232]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 141\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0316],\n",
      "        [1.2727]])\n",
      "batch_y tensor([[-0.2082],\n",
      "        [-0.0957]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 142\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0974],\n",
      "        [-0.4029]])\n",
      "batch_y tensor([[ 0.2742],\n",
      "        [-0.1214]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 143\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0646],\n",
      "        [0.0177]])\n",
      "batch_y tensor([[ 0.3476],\n",
      "        [-0.6683]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 144\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5011],\n",
      "        [-0.3351]])\n",
      "batch_y tensor([[-0.2270],\n",
      "        [-0.1528]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 145\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3047],\n",
      "        [-9.5231]])\n",
      "batch_y tensor([[-0.0050],\n",
      "        [-0.4079]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 146\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3364],\n",
      "        [-0.0856]])\n",
      "batch_y tensor([[-0.1883],\n",
      "        [-0.9376]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 147\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0344],\n",
      "        [-0.4425]])\n",
      "batch_y tensor([[0.1308],\n",
      "        [0.7120]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 148\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2123],\n",
      "        [-0.0239]])\n",
      "batch_y tensor([[-0.0576],\n",
      "        [-0.1915]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 149\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6183],\n",
      "        [0.4533]])\n",
      "batch_y tensor([[-0.1388],\n",
      "        [ 0.1555]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 150\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0179],\n",
      "        [ 0.0191]])\n",
      "batch_y tensor([[ 0.0349],\n",
      "        [15.9262]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 151\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0302],\n",
      "        [-6.7449]])\n",
      "batch_y tensor([[-0.0836],\n",
      "        [-0.0033]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 152\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0681],\n",
      "        [-0.0055]])\n",
      "batch_y tensor([[-0.1372],\n",
      "        [ 0.0365]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 153\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0029],\n",
      "        [ 0.0582]])\n",
      "batch_y tensor([[0.5204],\n",
      "        [0.0205]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 154\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0906],\n",
      "        [-0.0961]])\n",
      "batch_y tensor([[-0.4131],\n",
      "        [ 0.0676]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 155\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0025],\n",
      "        [0.1823]])\n",
      "batch_y tensor([[0.0217],\n",
      "        [0.0468]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 156\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0089],\n",
      "        [-0.4542]])\n",
      "batch_y tensor([[-0.2947],\n",
      "        [ 0.0059]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 157\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1859],\n",
      "        [0.0055]])\n",
      "batch_y tensor([[-0.0478],\n",
      "        [-0.0736]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 158\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0791],\n",
      "        [-0.0559]])\n",
      "batch_y tensor([[ 0.0168],\n",
      "        [-0.2908]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 159\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0715],\n",
      "        [1.1196]])\n",
      "batch_y tensor([[-0.0650],\n",
      "        [-0.0656]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 160\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0532],\n",
      "        [0.0024]])\n",
      "batch_y tensor([[ 0.0327],\n",
      "        [-0.1998]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 161\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0184],\n",
      "        [-0.0377]])\n",
      "batch_y tensor([[0.4155],\n",
      "        [0.0307]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 162\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0371],\n",
      "        [0.2767]])\n",
      "batch_y tensor([[0.3098],\n",
      "        [0.0446]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 163\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0323],\n",
      "        [-0.1414]])\n",
      "batch_y tensor([[ 0.0687],\n",
      "        [-0.0798]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 164\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2214],\n",
      "        [ 0.0203]])\n",
      "batch_y tensor([[0.0134],\n",
      "        [0.1145]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 165\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0717],\n",
      "        [0.1246]])\n",
      "batch_y tensor([[-0.1507],\n",
      "        [-0.8318]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 166\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2331],\n",
      "        [0.0322]])\n",
      "batch_y tensor([[-0.0546],\n",
      "        [-0.9194]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 167\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1150],\n",
      "        [-0.2173]])\n",
      "batch_y tensor([[0.1704],\n",
      "        [0.0259]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 168\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1603],\n",
      "        [-0.0259]])\n",
      "batch_y tensor([[-0.0601],\n",
      "        [ 0.0683]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 169\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1813],\n",
      "        [ 0.1222]])\n",
      "batch_y tensor([[-0.0378],\n",
      "        [-0.1489]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 170\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0630],\n",
      "        [-0.0427]])\n",
      "batch_y tensor([[-0.1353],\n",
      "        [-0.4218]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 171\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1731],\n",
      "        [-0.0946]])\n",
      "batch_y tensor([[ 0.0949],\n",
      "        [-0.0851]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 172\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0736],\n",
      "        [-0.0957]])\n",
      "batch_y tensor([[ 0.2004],\n",
      "        [-0.1661]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 173\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0190],\n",
      "        [0.2039]])\n",
      "batch_y tensor([[-0.0100],\n",
      "        [ 0.0208]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 174\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0415],\n",
      "        [-0.0038]])\n",
      "batch_y tensor([[-0.1654],\n",
      "        [-0.0137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 175\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0099],\n",
      "        [-0.1442]])\n",
      "batch_y tensor([[-0.6830],\n",
      "        [-0.1297]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 176\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1171],\n",
      "        [0.0056]])\n",
      "batch_y tensor([[0.0277],\n",
      "        [0.3391]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 177\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0515],\n",
      "        [ 1.9873]])\n",
      "batch_y tensor([[0.0173],\n",
      "        [0.3446]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 178\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0686],\n",
      "        [ 0.0260]])\n",
      "batch_y tensor([[-0.0736],\n",
      "        [ 0.3167]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 179\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0074],\n",
      "        [1.0593]])\n",
      "batch_y tensor([[0.4074],\n",
      "        [0.0873]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 180\n",
      "================\n",
      "\n",
      "batch_x tensor([[3.5573],\n",
      "        [0.1096]])\n",
      "batch_y tensor([[-0.1017],\n",
      "        [-0.0223]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 181\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2273],\n",
      "        [-0.1958]])\n",
      "batch_y tensor([[ 0.0265],\n",
      "        [-0.0804]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 182\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1819],\n",
      "        [-0.1154]])\n",
      "batch_y tensor([[ 0.6645],\n",
      "        [-0.0451]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 183\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0738],\n",
      "        [1.2361]])\n",
      "batch_y tensor([[ 0.3641],\n",
      "        [-0.7221]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 184\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0427],\n",
      "        [ 0.1301]])\n",
      "batch_y tensor([[ 0.1035],\n",
      "        [-0.1916]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 185\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0501],\n",
      "        [0.2265]])\n",
      "batch_y tensor([[0.0228],\n",
      "        [0.5200]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 186\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1216],\n",
      "        [ 0.0049]])\n",
      "batch_y tensor([[-0.1112],\n",
      "        [-0.3343]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 187\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0046],\n",
      "        [-0.3996]])\n",
      "batch_y tensor([[ 0.0511],\n",
      "        [-0.0042]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 188\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0119],\n",
      "        [ 0.0446]])\n",
      "batch_y tensor([[-1.3602],\n",
      "        [ 0.0694]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 189\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1071],\n",
      "        [0.1387]])\n",
      "batch_y tensor([[-0.0128],\n",
      "        [-0.0545]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 190\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0809],\n",
      "        [-0.1630]])\n",
      "batch_y tensor([[0.0146],\n",
      "        [0.7985]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 191\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.5350],\n",
      "        [-0.0519]])\n",
      "batch_y tensor([[-0.0201],\n",
      "        [ 0.0037]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 192\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0127],\n",
      "        [0.1939]])\n",
      "batch_y tensor([[0.0252],\n",
      "        [0.0532]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 193\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2589],\n",
      "        [ 0.0632]])\n",
      "batch_y tensor([[-0.0074],\n",
      "        [-0.0558]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 194\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0294],\n",
      "        [-0.1269]])\n",
      "batch_y tensor([[-0.0438],\n",
      "        [ 0.1622]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 195\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2452],\n",
      "        [ 0.0595]])\n",
      "batch_y tensor([[ 0.0063],\n",
      "        [-0.0408]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 196\n",
      "================\n",
      "\n",
      "batch_x tensor([[-10.0248],\n",
      "        [  0.1399]])\n",
      "batch_y tensor([[-0.0304],\n",
      "        [ 0.0084]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 197\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0264],\n",
      "        [-0.0790]])\n",
      "batch_y tensor([[-1.0639],\n",
      "        [ 1.5125]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 198\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.3629e+01],\n",
      "        [-2.7294e-03]])\n",
      "batch_y tensor([[-0.0316],\n",
      "        [-0.0161]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 199\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0722],\n",
      "        [-0.1302]])\n",
      "batch_y tensor([[0.0285],\n",
      "        [0.2746]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 200\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0072],\n",
      "        [0.0960]])\n",
      "batch_y tensor([[-0.0122],\n",
      "        [-0.6540]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 201\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0964],\n",
      "        [ 0.0860]])\n",
      "batch_y tensor([[-0.1082],\n",
      "        [-0.0937]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 202\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2479],\n",
      "        [-0.0086]])\n",
      "batch_y tensor([[-0.0443],\n",
      "        [ 0.0057]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 203\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6707],\n",
      "        [-0.0271]])\n",
      "batch_y tensor([[ 0.8919],\n",
      "        [-0.1894]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 204\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4280],\n",
      "        [ 0.0364]])\n",
      "batch_y tensor([[0.0663],\n",
      "        [0.0727]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 205\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1795],\n",
      "        [-0.0768]])\n",
      "batch_y tensor([[-0.0851],\n",
      "        [-0.0236]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 206\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1144],\n",
      "        [-0.4585]])\n",
      "batch_y tensor([[-0.0526],\n",
      "        [ 0.0076]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 207\n",
      "================\n",
      "\n",
      "batch_x tensor([[2.5413],\n",
      "        [0.3034]])\n",
      "batch_y tensor([[-0.0471],\n",
      "        [ 1.0029]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 208\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0006],\n",
      "        [ 0.1177]])\n",
      "batch_y tensor([[-0.1052],\n",
      "        [ 0.0787]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 209\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2420],\n",
      "        [-0.1366]])\n",
      "batch_y tensor([[ 0.0897],\n",
      "        [-0.5090]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 210\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0359],\n",
      "        [0.0244]])\n",
      "batch_y tensor([[ 0.1222],\n",
      "        [-0.3775]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 211\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1227],\n",
      "        [-0.0578]])\n",
      "batch_y tensor([[-0.0346],\n",
      "        [-0.0220]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 212\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1210],\n",
      "        [-0.0546]])\n",
      "batch_y tensor([[0.2108],\n",
      "        [0.0149]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 213\n",
      "================\n",
      "\n",
      "batch_x tensor([[-3.9765],\n",
      "        [-0.0552]])\n",
      "batch_y tensor([[ 0.1815],\n",
      "        [-0.0499]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 214\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.3905],\n",
      "        [-0.0499]])\n",
      "batch_y tensor([[-0.0105],\n",
      "        [ 0.1795]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 215\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0048],\n",
      "        [-0.1009]])\n",
      "batch_y tensor([[-0.2239],\n",
      "        [-0.0418]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 216\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3371],\n",
      "        [0.0314]])\n",
      "batch_y tensor([[0.0517],\n",
      "        [0.0384]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 217\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0479],\n",
      "        [-0.1458]])\n",
      "batch_y tensor([[0.0610],\n",
      "        [0.0015]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 218\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3461],\n",
      "        [0.0729]])\n",
      "batch_y tensor([[ 0.0223],\n",
      "        [-0.0030]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 219\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1494],\n",
      "        [ 0.6700]])\n",
      "batch_y tensor([[0.0810],\n",
      "        [0.1428]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 220\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0601],\n",
      "        [0.0048]])\n",
      "batch_y tensor([[-1.1535],\n",
      "        [-0.6878]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 221\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2688],\n",
      "        [ 0.2270]])\n",
      "batch_y tensor([[ 0.4213],\n",
      "        [-1.3681]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 222\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0863],\n",
      "        [-0.1935]])\n",
      "batch_y tensor([[-0.4199],\n",
      "        [ 0.1751]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 223\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0145],\n",
      "        [ 0.0480]])\n",
      "batch_y tensor([[-0.5437],\n",
      "        [-0.3166]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 224\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0583],\n",
      "        [-0.2424]])\n",
      "batch_y tensor([[-0.0908],\n",
      "        [-0.2221]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 225\n",
      "================\n",
      "\n",
      "batch_x tensor([[9.1587],\n",
      "        [0.0123]])\n",
      "batch_y tensor([[0.0069],\n",
      "        [0.0520]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 226\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1820],\n",
      "        [-0.0150]])\n",
      "batch_y tensor([[0.2255],\n",
      "        [0.1102]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 227\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.4091],\n",
      "        [0.0567]])\n",
      "batch_y tensor([[0.0339],\n",
      "        [0.5450]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 228\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0740],\n",
      "        [-0.3142]])\n",
      "batch_y tensor([[0.0974],\n",
      "        [0.0192]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 229\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0240],\n",
      "        [-0.7616]])\n",
      "batch_y tensor([[0.3406],\n",
      "        [0.6223]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 230\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0101],\n",
      "        [0.0243]])\n",
      "batch_y tensor([[-0.3852],\n",
      "        [-0.0222]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 231\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3164],\n",
      "        [-0.1721]])\n",
      "batch_y tensor([[0.0205],\n",
      "        [0.4630]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 232\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0192],\n",
      "        [-0.0339]])\n",
      "batch_y tensor([[ 0.0077],\n",
      "        [-0.0724]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 233\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0055],\n",
      "        [ 0.1181]])\n",
      "batch_y tensor([[-0.1014],\n",
      "        [-0.4142]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 234\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0108],\n",
      "        [0.8126]])\n",
      "batch_y tensor([[-0.1457],\n",
      "        [ 0.1602]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 235\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0005],\n",
      "        [0.2333]])\n",
      "batch_y tensor([[0.0008],\n",
      "        [0.0159]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 236\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0175],\n",
      "        [ 0.2039]])\n",
      "batch_y tensor([[ 0.1103],\n",
      "        [-0.1846]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 237\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2505],\n",
      "        [-0.1293]])\n",
      "batch_y tensor([[-0.0410],\n",
      "        [ 0.0948]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 238\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4522],\n",
      "        [ 0.0512]])\n",
      "batch_y tensor([[-0.4247],\n",
      "        [-0.1365]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 239\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.7639],\n",
      "        [-0.0077]])\n",
      "batch_y tensor([[ 2.9238],\n",
      "        [-0.6504]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 240\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5540],\n",
      "        [-0.1460]])\n",
      "batch_y tensor([[ 0.0192],\n",
      "        [-0.0115]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 241\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1561],\n",
      "        [ 0.7866]])\n",
      "batch_y tensor([[-3.8083],\n",
      "        [ 0.1391]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 242\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0586],\n",
      "        [-2.3456]])\n",
      "batch_y tensor([[ 0.2782],\n",
      "        [-0.2963]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 243\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0253],\n",
      "        [0.1539]])\n",
      "batch_y tensor([[-0.1333],\n",
      "        [ 0.0441]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 244\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.7187],\n",
      "        [ 0.0906]])\n",
      "batch_y tensor([[-0.2239],\n",
      "        [ 0.2538]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 245\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0216],\n",
      "        [ 0.2106]])\n",
      "batch_y tensor([[-0.1879],\n",
      "        [ 0.0461]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 246\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0780],\n",
      "        [-0.0314]])\n",
      "batch_y tensor([[ 0.1424],\n",
      "        [-0.0513]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 247\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2230],\n",
      "        [-0.0435]])\n",
      "batch_y tensor([[-0.0247],\n",
      "        [-0.0681]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 248\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1290],\n",
      "        [ 0.0258]])\n",
      "batch_y tensor([[0.0007],\n",
      "        [0.0522]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 249\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1062],\n",
      "        [-0.0730]])\n",
      "batch_y tensor([[-0.4070],\n",
      "        [-0.0857]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 250\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4072],\n",
      "        [ 0.1113]])\n",
      "batch_y tensor([[-0.1418],\n",
      "        [ 0.1788]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 251\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0755],\n",
      "        [-0.0095]])\n",
      "batch_y tensor([[-0.2830],\n",
      "        [ 0.6538]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 252\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2643],\n",
      "        [-0.0794]])\n",
      "batch_y tensor([[0.0265],\n",
      "        [0.4340]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 253\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0381],\n",
      "        [0.3054]])\n",
      "batch_y tensor([[-0.0628],\n",
      "        [-0.5500]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 254\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0271],\n",
      "        [3.8335]])\n",
      "batch_y tensor([[0.3866],\n",
      "        [0.0094]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 255\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0735],\n",
      "        [-0.0263]])\n",
      "batch_y tensor([[-0.1613],\n",
      "        [ 0.0234]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 256\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0405],\n",
      "        [0.0466]])\n",
      "batch_y tensor([[-0.0079],\n",
      "        [ 0.0162]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 257\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2226],\n",
      "        [0.1883]])\n",
      "batch_y tensor([[-0.2934],\n",
      "        [ 0.0886]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 258\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6692],\n",
      "        [ 0.1370]])\n",
      "batch_y tensor([[-0.0878],\n",
      "        [ 0.1234]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 259\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0430],\n",
      "        [-0.0522]])\n",
      "batch_y tensor([[-0.5469],\n",
      "        [-2.1552]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 260\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0441],\n",
      "        [-0.0384]])\n",
      "batch_y tensor([[ 0.3653],\n",
      "        [-0.0456]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 261\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0096],\n",
      "        [0.3344]])\n",
      "batch_y tensor([[4.2309],\n",
      "        [0.0722]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 262\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0455],\n",
      "        [-0.1530]])\n",
      "batch_y tensor([[ 1.3015],\n",
      "        [-0.1073]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 263\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0540],\n",
      "        [0.0129]])\n",
      "batch_y tensor([[1.7219],\n",
      "        [0.7761]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 264\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1717],\n",
      "        [-0.1623]])\n",
      "batch_y tensor([[-0.0920],\n",
      "        [ 0.0966]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 265\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0376],\n",
      "        [0.0342]])\n",
      "batch_y tensor([[-0.1359],\n",
      "        [ 0.0245]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 266\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0637],\n",
      "        [-0.0542]])\n",
      "batch_y tensor([[ 0.4407],\n",
      "        [-0.1716]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 267\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0044],\n",
      "        [-0.9821]])\n",
      "batch_y tensor([[ 0.0435],\n",
      "        [-0.0354]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 268\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0897],\n",
      "        [ 0.0600]])\n",
      "batch_y tensor([[-0.0188],\n",
      "        [-0.0893]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 269\n",
      "================\n",
      "\n",
      "batch_x tensor([[9.2647],\n",
      "        [0.0435]])\n",
      "batch_y tensor([[-0.4118],\n",
      "        [ 0.2335]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 270\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0730],\n",
      "        [ 0.4154]])\n",
      "batch_y tensor([[1.4516],\n",
      "        [1.2612]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 271\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1884],\n",
      "        [-0.4196]])\n",
      "batch_y tensor([[ 0.0083],\n",
      "        [-0.0131]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 272\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0156],\n",
      "        [-0.0498]])\n",
      "batch_y tensor([[ 0.0900],\n",
      "        [-0.2539]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 273\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0325],\n",
      "        [0.1684]])\n",
      "batch_y tensor([[-0.0564],\n",
      "        [ 3.2787]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 274\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.9312],\n",
      "        [ 0.6959]])\n",
      "batch_y tensor([[0.0874],\n",
      "        [0.0223]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 275\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1019],\n",
      "        [ 0.0357]])\n",
      "batch_y tensor([[-0.2814],\n",
      "        [ 0.1462]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 276\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0567],\n",
      "        [ 0.6143]])\n",
      "batch_y tensor([[0.0175],\n",
      "        [0.0234]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 277\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2339],\n",
      "        [0.2129]])\n",
      "batch_y tensor([[0.0952],\n",
      "        [0.0051]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 278\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2333],\n",
      "        [0.0495]])\n",
      "batch_y tensor([[1.3798],\n",
      "        [0.6738]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 279\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0306],\n",
      "        [0.0211]])\n",
      "batch_y tensor([[0.0366],\n",
      "        [0.3392]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 280\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1676],\n",
      "        [ 1.1838]])\n",
      "batch_y tensor([[0.0067],\n",
      "        [0.1626]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 281\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6594],\n",
      "        [-0.0972]])\n",
      "batch_y tensor([[ 0.0205],\n",
      "        [-0.2611]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 282\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0182],\n",
      "        [0.7275]])\n",
      "batch_y tensor([[-0.0576],\n",
      "        [-0.2754]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 283\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0923],\n",
      "        [-0.0389]])\n",
      "batch_y tensor([[ 0.3393],\n",
      "        [-0.0900]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 284\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0906],\n",
      "        [ 0.0710]])\n",
      "batch_y tensor([[-0.1511],\n",
      "        [-0.3941]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 285\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2983],\n",
      "        [ 0.4895]])\n",
      "batch_y tensor([[-0.0210],\n",
      "        [-0.0754]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 286\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0444],\n",
      "        [-0.2837]])\n",
      "batch_y tensor([[0.0185],\n",
      "        [0.0339]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 287\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0036],\n",
      "        [-0.0630]])\n",
      "batch_y tensor([[-0.2519],\n",
      "        [ 1.2020]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 288\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1122],\n",
      "        [ 0.0258]])\n",
      "batch_y tensor([[ 0.0159],\n",
      "        [-0.1342]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 289\n",
      "================\n",
      "\n",
      "batch_x tensor([[-2.0326],\n",
      "        [-0.0072]])\n",
      "batch_y tensor([[0.0056],\n",
      "        [0.0013]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 290\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6227],\n",
      "        [0.0702]])\n",
      "batch_y tensor([[-0.1194],\n",
      "        [ 0.0252]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 291\n",
      "================\n",
      "\n",
      "batch_x tensor([[-6.9505],\n",
      "        [-0.2107]])\n",
      "batch_y tensor([[-0.0415],\n",
      "        [ 0.3215]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 292\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1201],\n",
      "        [-0.1850]])\n",
      "batch_y tensor([[0.0120],\n",
      "        [0.0458]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 293\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0604],\n",
      "        [-0.1546]])\n",
      "batch_y tensor([[ 0.0979],\n",
      "        [-0.0307]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 294\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0523],\n",
      "        [-0.0997]])\n",
      "batch_y tensor([[-0.0742],\n",
      "        [-0.0248]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 295\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0299],\n",
      "        [-0.1857]])\n",
      "batch_y tensor([[0.8072],\n",
      "        [3.8361]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 296\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1843],\n",
      "        [0.0494]])\n",
      "batch_y tensor([[-0.2624],\n",
      "        [ 0.1046]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 297\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2596],\n",
      "        [-0.0061]])\n",
      "batch_y tensor([[ 0.0172],\n",
      "        [-0.0340]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 298\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0413],\n",
      "        [0.0891]])\n",
      "batch_y tensor([[0.0274],\n",
      "        [0.0546]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 299\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5938],\n",
      "        [-0.0271]])\n",
      "batch_y tensor([[-0.0169],\n",
      "        [ 1.9280]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 300\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4111],\n",
      "        [-0.0630]])\n",
      "batch_y tensor([[-0.4070],\n",
      "        [ 0.0615]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 301\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0040],\n",
      "        [0.0317]])\n",
      "batch_y tensor([[ 0.2142],\n",
      "        [-0.6142]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 302\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0232],\n",
      "        [ 0.4945]])\n",
      "batch_y tensor([[ 0.1965],\n",
      "        [-0.2043]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 303\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0136],\n",
      "        [-0.0920]])\n",
      "batch_y tensor([[-0.0267],\n",
      "        [ 0.0797]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 304\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0191],\n",
      "        [ 0.6851]])\n",
      "batch_y tensor([[-0.3582],\n",
      "        [ 0.0188]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 305\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0775],\n",
      "        [-0.0144]])\n",
      "batch_y tensor([[0.1342],\n",
      "        [0.4075]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 306\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1026],\n",
      "        [-0.0017]])\n",
      "batch_y tensor([[ 0.3623],\n",
      "        [-0.0430]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 307\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0417],\n",
      "        [-0.8556]])\n",
      "batch_y tensor([[0.0295],\n",
      "        [6.8802]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 308\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1835],\n",
      "        [-0.1114]])\n",
      "batch_y tensor([[-2.9778],\n",
      "        [-0.0059]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 309\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0836],\n",
      "        [-0.1025]])\n",
      "batch_y tensor([[-0.0986],\n",
      "        [ 0.0611]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 310\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1590],\n",
      "        [-0.1348]])\n",
      "batch_y tensor([[-0.0136],\n",
      "        [-0.0324]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 311\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0116],\n",
      "        [ 0.1060]])\n",
      "batch_y tensor([[-0.4727],\n",
      "        [-0.0105]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 312\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1029],\n",
      "        [-0.0277]])\n",
      "batch_y tensor([[ 0.3501],\n",
      "        [-0.0163]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 313\n",
      "================\n",
      "\n",
      "batch_x tensor([[-2.9294],\n",
      "        [ 0.2150]])\n",
      "batch_y tensor([[ 0.0002],\n",
      "        [-0.0212]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 314\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0039],\n",
      "        [ 0.2689]])\n",
      "batch_y tensor([[0.1385],\n",
      "        [0.0934]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 315\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0654],\n",
      "        [ 0.6642]])\n",
      "batch_y tensor([[-0.0173],\n",
      "        [ 0.0938]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 316\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1220],\n",
      "        [-0.0904]])\n",
      "batch_y tensor([[-0.0397],\n",
      "        [-0.0648]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 317\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1670],\n",
      "        [-0.3116]])\n",
      "batch_y tensor([[ 0.1113],\n",
      "        [-0.0725]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 318\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0795],\n",
      "        [-0.0891]])\n",
      "batch_y tensor([[ 0.0482],\n",
      "        [-0.0188]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 319\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6637],\n",
      "        [-0.1158]])\n",
      "batch_y tensor([[-0.0846],\n",
      "        [ 0.0559]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 320\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0061],\n",
      "        [-0.0749]])\n",
      "batch_y tensor([[ 0.6132],\n",
      "        [-0.0940]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 321\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1215],\n",
      "        [0.1041]])\n",
      "batch_y tensor([[0.0546],\n",
      "        [0.0924]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 322\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0658],\n",
      "        [-0.1455]])\n",
      "batch_y tensor([[-0.0900],\n",
      "        [ 0.1155]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 323\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0208],\n",
      "        [ 0.1717]])\n",
      "batch_y tensor([[-0.0941],\n",
      "        [-0.1658]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 324\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0043],\n",
      "        [-0.1000]])\n",
      "batch_y tensor([[-0.6834],\n",
      "        [-0.3291]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 325\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2861],\n",
      "        [ 0.1546]])\n",
      "batch_y tensor([[-0.3737],\n",
      "        [ 0.1273]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 326\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1221],\n",
      "        [-0.0779]])\n",
      "batch_y tensor([[2.9606],\n",
      "        [0.0454]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 327\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0382],\n",
      "        [0.0924]])\n",
      "batch_y tensor([[-0.0860],\n",
      "        [ 0.8969]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 328\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0050],\n",
      "        [-0.0008]])\n",
      "batch_y tensor([[-0.2178],\n",
      "        [ 0.3119]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 329\n",
      "================\n",
      "\n",
      "batch_x tensor([[-2.9551],\n",
      "        [-0.3791]])\n",
      "batch_y tensor([[ 0.1838],\n",
      "        [-0.0594]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 330\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1812],\n",
      "        [-0.1170]])\n",
      "batch_y tensor([[-0.1107],\n",
      "        [ 0.0271]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 331\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0076],\n",
      "        [-0.7619]])\n",
      "batch_y tensor([[-0.0595],\n",
      "        [-0.1866]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 332\n",
      "================\n",
      "\n",
      "batch_x tensor([[-11.0609],\n",
      "        [  0.0534]])\n",
      "batch_y tensor([[-5.9082],\n",
      "        [ 0.3405]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 333\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1205],\n",
      "        [ 0.0746]])\n",
      "batch_y tensor([[ 0.1874],\n",
      "        [-0.0283]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 334\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0280],\n",
      "        [ 0.1487]])\n",
      "batch_y tensor([[ 0.1970],\n",
      "        [-2.4040]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 335\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1147],\n",
      "        [-0.1337]])\n",
      "batch_y tensor([[-0.0043],\n",
      "        [-0.0082]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 336\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0068],\n",
      "        [0.0625]])\n",
      "batch_y tensor([[0.0832],\n",
      "        [0.0099]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 337\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.1910],\n",
      "        [-0.2675]])\n",
      "batch_y tensor([[-0.0185],\n",
      "        [ 0.0484]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 338\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0373],\n",
      "        [-0.1365]])\n",
      "batch_y tensor([[0.1220],\n",
      "        [0.8182]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 339\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1355],\n",
      "        [-3.2533]])\n",
      "batch_y tensor([[-0.1264],\n",
      "        [-0.1710]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 340\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0137],\n",
      "        [-0.2996]])\n",
      "batch_y tensor([[ 0.0871],\n",
      "        [-0.0872]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 341\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0077],\n",
      "        [ 0.2329]])\n",
      "batch_y tensor([[0.0062],\n",
      "        [0.1007]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 342\n",
      "================\n",
      "\n",
      "batch_x tensor([[-3.6585],\n",
      "        [ 0.0896]])\n",
      "batch_y tensor([[0.0729],\n",
      "        [0.2049]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 343\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0975],\n",
      "        [-0.0349]])\n",
      "batch_y tensor([[ 0.3060],\n",
      "        [-1.5215]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 344\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0312],\n",
      "        [ 0.0878]])\n",
      "batch_y tensor([[-0.2576],\n",
      "        [-0.1688]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 345\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0408],\n",
      "        [0.0239]])\n",
      "batch_y tensor([[0.4257],\n",
      "        [6.7613]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 346\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 9.2424],\n",
      "        [-0.0189]])\n",
      "batch_y tensor([[-0.0536],\n",
      "        [-1.3523]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 347\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0462],\n",
      "        [-0.0005]])\n",
      "batch_y tensor([[-0.0186],\n",
      "        [-0.3376]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 348\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1038],\n",
      "        [0.1029]])\n",
      "batch_y tensor([[2.2430e+01],\n",
      "        [3.1689e-03]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 349\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0276],\n",
      "        [-0.0170]])\n",
      "batch_y tensor([[-0.0782],\n",
      "        [ 0.4522]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 350\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0259],\n",
      "        [-0.2811]])\n",
      "batch_y tensor([[-0.0007],\n",
      "        [ 0.3160]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 351\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0179],\n",
      "        [ 1.7610]])\n",
      "batch_y tensor([[0.2357],\n",
      "        [0.1777]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 352\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1447],\n",
      "        [0.3214]])\n",
      "batch_y tensor([[ 0.4693],\n",
      "        [-0.1618]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 353\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3087],\n",
      "        [-0.0259]])\n",
      "batch_y tensor([[ 0.0241],\n",
      "        [-0.0858]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 354\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4044],\n",
      "        [ 0.1384]])\n",
      "batch_y tensor([[-0.6524],\n",
      "        [ 0.0103]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 355\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.4746],\n",
      "        [ 0.0982]])\n",
      "batch_y tensor([[0.3970],\n",
      "        [0.1598]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 356\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0099],\n",
      "        [0.7842]])\n",
      "batch_y tensor([[-0.0094],\n",
      "        [ 0.1413]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 357\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0219],\n",
      "        [0.1249]])\n",
      "batch_y tensor([[-0.0034],\n",
      "        [ 0.4028]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 358\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0064],\n",
      "        [-0.3784]])\n",
      "batch_y tensor([[-0.0043],\n",
      "        [ 0.3571]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 359\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0528],\n",
      "        [ 0.0067]])\n",
      "batch_y tensor([[-0.1208],\n",
      "        [ 0.1452]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 360\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0021],\n",
      "        [ 0.0160]])\n",
      "batch_y tensor([[ 0.0152],\n",
      "        [-0.0648]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 361\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0504],\n",
      "        [ 0.1348]])\n",
      "batch_y tensor([[-0.0190],\n",
      "        [ 0.0442]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 362\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1288],\n",
      "        [2.0754]])\n",
      "batch_y tensor([[-0.0301],\n",
      "        [ 0.1136]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 363\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0219],\n",
      "        [-0.4643]])\n",
      "batch_y tensor([[-0.0929],\n",
      "        [-0.0328]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 364\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5093],\n",
      "        [ 0.0310]])\n",
      "batch_y tensor([[0.0945],\n",
      "        [0.0145]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 365\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0278],\n",
      "        [0.3400]])\n",
      "batch_y tensor([[ 0.1093],\n",
      "        [-0.3813]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 366\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0656],\n",
      "        [-0.2919]])\n",
      "batch_y tensor([[-0.1490],\n",
      "        [ 0.0876]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 367\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2734],\n",
      "        [-0.4914]])\n",
      "batch_y tensor([[ 5.0138],\n",
      "        [-0.0077]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 368\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2206],\n",
      "        [0.0443]])\n",
      "batch_y tensor([[-0.0444],\n",
      "        [-0.2654]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 369\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0195],\n",
      "        [0.0940]])\n",
      "batch_y tensor([[0.0767],\n",
      "        [1.3751]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 370\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1096],\n",
      "        [-0.0234]])\n",
      "batch_y tensor([[-0.2422],\n",
      "        [ 0.3033]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 371\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2323],\n",
      "        [-0.1487]])\n",
      "batch_y tensor([[-0.2737],\n",
      "        [-0.0216]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 372\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0021],\n",
      "        [ 0.1060]])\n",
      "batch_y tensor([[-0.0638],\n",
      "        [-0.1975]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 373\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0876],\n",
      "        [-0.0701]])\n",
      "batch_y tensor([[ 0.1390],\n",
      "        [-0.0392]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 374\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0630],\n",
      "        [0.0323]])\n",
      "batch_y tensor([[0.4658],\n",
      "        [0.0044]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 375\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0035],\n",
      "        [-0.4221]])\n",
      "batch_y tensor([[-0.8611],\n",
      "        [-0.0375]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 376\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0010],\n",
      "        [-0.3794]])\n",
      "batch_y tensor([[ 0.6702],\n",
      "        [-0.0759]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 377\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0232],\n",
      "        [-0.0739]])\n",
      "batch_y tensor([[-0.0905],\n",
      "        [ 0.0674]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 378\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0112],\n",
      "        [ 0.0231]])\n",
      "batch_y tensor([[-0.1118],\n",
      "        [-0.0988]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 379\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0347],\n",
      "        [-0.0722]])\n",
      "batch_y tensor([[ 0.1468],\n",
      "        [-0.1266]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 380\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0149],\n",
      "        [-0.0211]])\n",
      "batch_y tensor([[ 0.3111],\n",
      "        [-0.0175]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 381\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0405],\n",
      "        [-0.0649]])\n",
      "batch_y tensor([[ 0.0020],\n",
      "        [-0.2736]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 382\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0996],\n",
      "        [-0.1701]])\n",
      "batch_y tensor([[-0.2761],\n",
      "        [ 0.0478]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 383\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0487],\n",
      "        [-0.0443]])\n",
      "batch_y tensor([[-0.0186],\n",
      "        [ 0.0402]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 384\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0340],\n",
      "        [0.0218]])\n",
      "batch_y tensor([[0.5585],\n",
      "        [0.0749]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 385\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2938],\n",
      "        [0.0969]])\n",
      "batch_y tensor([[-0.1107],\n",
      "        [-0.0663]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 386\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2682],\n",
      "        [-0.0038]])\n",
      "batch_y tensor([[0.0053],\n",
      "        [0.0021]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 387\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.5440],\n",
      "        [0.0193]])\n",
      "batch_y tensor([[ 0.5176],\n",
      "        [-0.3555]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 388\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.1099],\n",
      "        [-0.0311]])\n",
      "batch_y tensor([[-0.0403],\n",
      "        [-0.0025]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 389\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0947],\n",
      "        [-0.0584]])\n",
      "batch_y tensor([[0.0823],\n",
      "        [0.0412]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 390\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1275],\n",
      "        [-0.4995]])\n",
      "batch_y tensor([[ 0.2255],\n",
      "        [-0.0327]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 391\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3475],\n",
      "        [ 0.3999]])\n",
      "batch_y tensor([[ 0.1288],\n",
      "        [-0.5492]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 392\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0372],\n",
      "        [-0.1674]])\n",
      "batch_y tensor([[-0.5305],\n",
      "        [-5.2304]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 393\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0719],\n",
      "        [-0.0172]])\n",
      "batch_y tensor([[-0.1990],\n",
      "        [-0.0026]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 394\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.2773e+00],\n",
      "        [6.4881e-04]])\n",
      "batch_y tensor([[0.0932],\n",
      "        [0.0137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 395\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.1810],\n",
      "        [-0.1358]])\n",
      "batch_y tensor([[-1.7052],\n",
      "        [-0.1947]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 396\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.4373],\n",
      "        [0.0155]])\n",
      "batch_y tensor([[ 0.1213],\n",
      "        [-2.9458]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 397\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0771],\n",
      "        [0.0236]])\n",
      "batch_y tensor([[-0.1744],\n",
      "        [ 0.1371]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 398\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1096],\n",
      "        [-0.0527]])\n",
      "batch_y tensor([[ 0.1923],\n",
      "        [-0.0829]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 399\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1384],\n",
      "        [-0.4882]])\n",
      "batch_y tensor([[0.0170],\n",
      "        [0.1256]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 400\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1214],\n",
      "        [-0.1032]])\n",
      "batch_y tensor([[-0.1671],\n",
      "        [ 0.0145]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 401\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0388],\n",
      "        [0.1416]])\n",
      "batch_y tensor([[-0.0794],\n",
      "        [ 0.0145]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 402\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1721],\n",
      "        [-0.1699]])\n",
      "batch_y tensor([[-0.0161],\n",
      "        [ 0.1653]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 403\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2154],\n",
      "        [ 0.0207]])\n",
      "batch_y tensor([[-0.0170],\n",
      "        [ 0.4405]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 404\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1793],\n",
      "        [-0.2688]])\n",
      "batch_y tensor([[-1.6202],\n",
      "        [ 0.0777]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 405\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0130],\n",
      "        [-0.0228]])\n",
      "batch_y tensor([[0.4965],\n",
      "        [0.3376]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 406\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0238],\n",
      "        [-0.2358]])\n",
      "batch_y tensor([[ 0.0244],\n",
      "        [-0.0392]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 407\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2797],\n",
      "        [ 0.3178]])\n",
      "batch_y tensor([[-0.2957],\n",
      "        [-0.0264]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 408\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3121],\n",
      "        [0.0580]])\n",
      "batch_y tensor([[-0.1386],\n",
      "        [ 0.0024]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 409\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 2.0909],\n",
      "        [-0.0357]])\n",
      "batch_y tensor([[-0.0635],\n",
      "        [ 0.3158]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 410\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6326],\n",
      "        [-0.0819]])\n",
      "batch_y tensor([[0.0656],\n",
      "        [0.2819]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 411\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4237],\n",
      "        [-0.4430]])\n",
      "batch_y tensor([[0.1527],\n",
      "        [0.1011]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 412\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0385],\n",
      "        [-0.0495]])\n",
      "batch_y tensor([[-0.0455],\n",
      "        [-0.0558]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 413\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0516],\n",
      "        [-0.2015]])\n",
      "batch_y tensor([[ 0.1064],\n",
      "        [-0.2740]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 414\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5590],\n",
      "        [-0.0857]])\n",
      "batch_y tensor([[3.7534],\n",
      "        [0.1795]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 415\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0069],\n",
      "        [-0.0922]])\n",
      "batch_y tensor([[ 0.1682],\n",
      "        [-0.0440]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 416\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0879],\n",
      "        [ 0.1529]])\n",
      "batch_y tensor([[0.2403],\n",
      "        [0.5244]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 417\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0847],\n",
      "        [-0.0381]])\n",
      "batch_y tensor([[-0.0587],\n",
      "        [-0.2117]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 418\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0773],\n",
      "        [-4.7651]])\n",
      "batch_y tensor([[0.5654],\n",
      "        [0.0306]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 419\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0290],\n",
      "        [-0.0730]])\n",
      "batch_y tensor([[-0.1551],\n",
      "        [ 0.0605]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 420\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0072],\n",
      "        [-0.1260]])\n",
      "batch_y tensor([[0.2603],\n",
      "        [0.0780]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 421\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3256],\n",
      "        [-0.1835]])\n",
      "batch_y tensor([[ 0.0298],\n",
      "        [-0.0089]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 422\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1258],\n",
      "        [-0.1318]])\n",
      "batch_y tensor([[-0.0408],\n",
      "        [ 0.0774]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 423\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0140],\n",
      "        [-0.1318]])\n",
      "batch_y tensor([[0.0448],\n",
      "        [0.1320]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 424\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.4076],\n",
      "        [ 0.3334]])\n",
      "batch_y tensor([[0.0470],\n",
      "        [0.1496]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 425\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2707],\n",
      "        [ 0.2991]])\n",
      "batch_y tensor([[ 0.1510],\n",
      "        [-0.0526]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 426\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4256],\n",
      "        [ 1.0411]])\n",
      "batch_y tensor([[ 0.0086],\n",
      "        [-0.4166]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 427\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.1094],\n",
      "        [ 0.0631]])\n",
      "batch_y tensor([[-0.0576],\n",
      "        [-0.0763]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 428\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0854],\n",
      "        [-0.0526]])\n",
      "batch_y tensor([[0.2240],\n",
      "        [0.1420]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 429\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5936],\n",
      "        [-0.0290]])\n",
      "batch_y tensor([[-0.0433],\n",
      "        [-0.0226]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 430\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0461],\n",
      "        [ 0.0768]])\n",
      "batch_y tensor([[0.0224],\n",
      "        [0.5039]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 431\n",
      "================\n",
      "\n",
      "batch_x tensor([[2.3350],\n",
      "        [0.3059]])\n",
      "batch_y tensor([[ 0.0270],\n",
      "        [-0.0679]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 432\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0484],\n",
      "        [ 0.1129]])\n",
      "batch_y tensor([[-0.1931],\n",
      "        [ 0.1008]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 433\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2733],\n",
      "        [-0.1934]])\n",
      "batch_y tensor([[0.0231],\n",
      "        [0.0406]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 434\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2268],\n",
      "        [0.0526]])\n",
      "batch_y tensor([[0.1663],\n",
      "        [0.0003]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 435\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0731],\n",
      "        [-0.1074]])\n",
      "batch_y tensor([[-0.0077],\n",
      "        [ 0.0183]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 436\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1724],\n",
      "        [ 0.1057]])\n",
      "batch_y tensor([[ 0.1358],\n",
      "        [-0.7170]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 437\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0057],\n",
      "        [ 0.6396]])\n",
      "batch_y tensor([[0.0088],\n",
      "        [0.7479]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 438\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2108],\n",
      "        [-3.1850]])\n",
      "batch_y tensor([[ 0.4934],\n",
      "        [-0.0756]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 439\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3218],\n",
      "        [0.0571]])\n",
      "batch_y tensor([[ 0.0328],\n",
      "        [-0.4094]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 440\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1057],\n",
      "        [-0.0022]])\n",
      "batch_y tensor([[ 0.7384],\n",
      "        [-0.0289]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 441\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0698],\n",
      "        [-0.0188]])\n",
      "batch_y tensor([[-0.0467],\n",
      "        [ 0.2029]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 442\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1618],\n",
      "        [ 0.0434]])\n",
      "batch_y tensor([[-0.1909],\n",
      "        [-0.3743]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 443\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.5100],\n",
      "        [-0.2433]])\n",
      "batch_y tensor([[-0.0044],\n",
      "        [ 0.0363]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 444\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.2070],\n",
      "        [0.6503]])\n",
      "batch_y tensor([[-0.0710],\n",
      "        [ 0.1543]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 445\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1820],\n",
      "        [ 0.0790]])\n",
      "batch_y tensor([[-0.3703],\n",
      "        [ 1.0403]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 446\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5204],\n",
      "        [-0.0332]])\n",
      "batch_y tensor([[0.1277],\n",
      "        [0.1379]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 447\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3962],\n",
      "        [-0.2332]])\n",
      "batch_y tensor([[-0.0633],\n",
      "        [ 0.1918]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 448\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2858],\n",
      "        [0.0491]])\n",
      "batch_y tensor([[-0.0187],\n",
      "        [ 0.0141]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 449\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3521],\n",
      "        [0.0845]])\n",
      "batch_y tensor([[ 0.1633],\n",
      "        [-0.0894]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 450\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0379],\n",
      "        [ 0.2982]])\n",
      "batch_y tensor([[-0.0137],\n",
      "        [-0.8488]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 451\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2866],\n",
      "        [ 0.1896]])\n",
      "batch_y tensor([[0.0466],\n",
      "        [0.3805]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 452\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0273],\n",
      "        [0.1370]])\n",
      "batch_y tensor([[-0.0564],\n",
      "        [-0.3812]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 453\n",
      "================\n",
      "\n",
      "batch_x tensor([[  0.1194],\n",
      "        [-13.5472]])\n",
      "batch_y tensor([[ 0.0679],\n",
      "        [-0.2685]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 454\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0223],\n",
      "        [0.1732]])\n",
      "batch_y tensor([[ 0.2031],\n",
      "        [-0.5055]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 455\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0074],\n",
      "        [-0.0354]])\n",
      "batch_y tensor([[ 0.1387],\n",
      "        [-0.0202]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 456\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0276],\n",
      "        [-4.5253]])\n",
      "batch_y tensor([[-0.0953],\n",
      "        [-0.2021]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 457\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0540],\n",
      "        [0.0811]])\n",
      "batch_y tensor([[ 0.1724],\n",
      "        [-0.0809]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 458\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3393],\n",
      "        [ 0.0183]])\n",
      "batch_y tensor([[-0.0249],\n",
      "        [-0.0720]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 459\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0288],\n",
      "        [0.0383]])\n",
      "batch_y tensor([[0.0240],\n",
      "        [0.1094]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 460\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0626],\n",
      "        [-0.1599]])\n",
      "batch_y tensor([[-6.8772],\n",
      "        [-0.0563]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 461\n",
      "================\n",
      "\n",
      "batch_x tensor([[-2.2195e+01],\n",
      "        [-3.2241e-03]])\n",
      "batch_y tensor([[-0.1331],\n",
      "        [ 0.0582]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 462\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0496],\n",
      "        [-0.1077]])\n",
      "batch_y tensor([[0.3400],\n",
      "        [0.2212]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 463\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0136],\n",
      "        [-0.0855]])\n",
      "batch_y tensor([[ 0.5060],\n",
      "        [-0.0816]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 464\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1381],\n",
      "        [0.0271]])\n",
      "batch_y tensor([[-4.4293],\n",
      "        [-0.4447]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 465\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1356],\n",
      "        [-0.2690]])\n",
      "batch_y tensor([[-0.1491],\n",
      "        [-0.1438]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 466\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1001],\n",
      "        [-0.0443]])\n",
      "batch_y tensor([[ 0.0330],\n",
      "        [-0.0763]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 467\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1960],\n",
      "        [-0.0674]])\n",
      "batch_y tensor([[ 0.0083],\n",
      "        [-0.2691]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 468\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.5105],\n",
      "        [-0.0622]])\n",
      "batch_y tensor([[ 0.0613],\n",
      "        [-0.0546]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 469\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0250],\n",
      "        [-0.1119]])\n",
      "batch_y tensor([[-0.3594],\n",
      "        [ 0.0735]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 470\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0907],\n",
      "        [0.1460]])\n",
      "batch_y tensor([[ 0.0043],\n",
      "        [-0.0213]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 471\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.9400],\n",
      "        [-0.0131]])\n",
      "batch_y tensor([[0.0604],\n",
      "        [0.0804]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 472\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.3905],\n",
      "        [ 0.0245]])\n",
      "batch_y tensor([[-0.0414],\n",
      "        [-0.0316]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 473\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0490],\n",
      "        [-0.0933]])\n",
      "batch_y tensor([[0.0527],\n",
      "        [0.0577]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 474\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1232],\n",
      "        [-0.1117]])\n",
      "batch_y tensor([[-0.0628],\n",
      "        [-0.0511]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 475\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1370],\n",
      "        [-0.0818]])\n",
      "batch_y tensor([[12.8843],\n",
      "        [ 0.0209]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 476\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0330],\n",
      "        [-0.0186]])\n",
      "batch_y tensor([[-0.1167],\n",
      "        [-0.1553]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 477\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0635],\n",
      "        [-0.0343]])\n",
      "batch_y tensor([[0.0310],\n",
      "        [0.0388]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 478\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0546],\n",
      "        [1.5555]])\n",
      "batch_y tensor([[-5.2447],\n",
      "        [ 0.1036]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 479\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0170],\n",
      "        [0.1971]])\n",
      "batch_y tensor([[0.0904],\n",
      "        [0.0739]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 480\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0716],\n",
      "        [ 0.1782]])\n",
      "batch_y tensor([[-0.1300],\n",
      "        [ 0.0909]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 481\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0630],\n",
      "        [0.6400]])\n",
      "batch_y tensor([[ 0.0304],\n",
      "        [-1.2248]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 482\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2160],\n",
      "        [-0.0168]])\n",
      "batch_y tensor([[ 0.0806],\n",
      "        [-1.1459]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 483\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0241],\n",
      "        [-0.0394]])\n",
      "batch_y tensor([[-0.0175],\n",
      "        [ 0.0412]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 484\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2023],\n",
      "        [-0.3282]])\n",
      "batch_y tensor([[-0.2743],\n",
      "        [-1.0422]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 485\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2270],\n",
      "        [ 0.0195]])\n",
      "batch_y tensor([[-0.1743],\n",
      "        [ 0.3847]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 486\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0184],\n",
      "        [-0.2567]])\n",
      "batch_y tensor([[ 0.0398],\n",
      "        [-0.0147]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 487\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0508],\n",
      "        [ 0.0481]])\n",
      "batch_y tensor([[-0.0669],\n",
      "        [ 0.1894]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 488\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.5258],\n",
      "        [0.0553]])\n",
      "batch_y tensor([[-0.2878],\n",
      "        [-0.3698]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 489\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0326],\n",
      "        [-0.0751]])\n",
      "batch_y tensor([[ 0.0807],\n",
      "        [-0.3107]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 490\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0113],\n",
      "        [-1.2384]])\n",
      "batch_y tensor([[-0.2971],\n",
      "        [-0.0416]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 491\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5483],\n",
      "        [-0.0274]])\n",
      "batch_y tensor([[-0.2069],\n",
      "        [ 0.1619]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 492\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4726],\n",
      "        [ 0.0494]])\n",
      "batch_y tensor([[-0.0243],\n",
      "        [-0.1218]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 493\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0550],\n",
      "        [ 0.0551]])\n",
      "batch_y tensor([[0.1565],\n",
      "        [0.0103]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 494\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.9553],\n",
      "        [-0.0382]])\n",
      "batch_y tensor([[ 0.0549],\n",
      "        [-0.4732]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 495\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0381],\n",
      "        [-0.0528]])\n",
      "batch_y tensor([[-0.0843],\n",
      "        [ 0.0562]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 496\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2488],\n",
      "        [0.0142]])\n",
      "batch_y tensor([[-0.0688],\n",
      "        [ 0.1492]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 497\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0272],\n",
      "        [ 0.0820]])\n",
      "batch_y tensor([[-0.0358],\n",
      "        [ 0.0283]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 498\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6610],\n",
      "        [-0.0013]])\n",
      "batch_y tensor([[-1.9760],\n",
      "        [-0.0277]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 499\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2716],\n",
      "        [-0.1156]])\n",
      "batch_y tensor([[ 0.5787],\n",
      "        [-0.0925]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 0\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2072],\n",
      "        [0.0630]])\n",
      "batch_y tensor([[0.1975],\n",
      "        [0.0304]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 1\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0377],\n",
      "        [-0.2701]])\n",
      "batch_y tensor([[0.3356],\n",
      "        [0.4128]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 2\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0245],\n",
      "        [0.0544]])\n",
      "batch_y tensor([[-0.0316],\n",
      "        [-0.1232]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 3\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.4533],\n",
      "        [-0.0304]])\n",
      "batch_y tensor([[0.1555],\n",
      "        [0.0206]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 4\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1202],\n",
      "        [0.0278]])\n",
      "batch_y tensor([[-0.0200],\n",
      "        [ 0.1093]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 5\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1674],\n",
      "        [-0.1216]])\n",
      "batch_y tensor([[-5.2304],\n",
      "        [-0.1112]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 6\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1269],\n",
      "        [-1.9411]])\n",
      "batch_y tensor([[ 0.1622],\n",
      "        [-0.1743]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 7\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1060],\n",
      "        [1.2773]])\n",
      "batch_y tensor([[-0.1975],\n",
      "        [ 0.0932]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 8\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0980],\n",
      "        [ 0.0729]])\n",
      "batch_y tensor([[ 0.7191],\n",
      "        [-0.0030]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 9\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0021],\n",
      "        [-0.0072]])\n",
      "batch_y tensor([[0.0152],\n",
      "        [0.0013]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 10\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0335],\n",
      "        [-0.1221]])\n",
      "batch_y tensor([[0.0103],\n",
      "        [2.9606]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 11\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1356],\n",
      "        [0.2097]])\n",
      "batch_y tensor([[-0.1491],\n",
      "        [ 0.0714]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 12\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0854],\n",
      "        [ 0.0466]])\n",
      "batch_y tensor([[0.2240],\n",
      "        [0.0162]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 13\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2938],\n",
      "        [0.3763]])\n",
      "batch_y tensor([[-0.1107],\n",
      "        [ 0.0017]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 14\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0905],\n",
      "        [-0.0904]])\n",
      "batch_y tensor([[47.0076],\n",
      "        [-0.0648]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 15\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2016],\n",
      "        [ 0.0260]])\n",
      "batch_y tensor([[-0.1150],\n",
      "        [ 0.3167]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 16\n",
      "================\n",
      "\n",
      "batch_x tensor([[-13.6289],\n",
      "        [ -0.0974]])\n",
      "batch_y tensor([[-0.0316],\n",
      "        [ 0.2742]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 17\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1670],\n",
      "        [ 1.3905]])\n",
      "batch_y tensor([[ 0.1113],\n",
      "        [-0.0105]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 18\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0896],\n",
      "        [-0.0528]])\n",
      "batch_y tensor([[0.2049],\n",
      "        [0.0562]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 19\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0435],\n",
      "        [-0.1813]])\n",
      "batch_y tensor([[-0.0681],\n",
      "        [-0.0378]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 20\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3034],\n",
      "        [-0.1302]])\n",
      "batch_y tensor([[1.0029],\n",
      "        [0.2746]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 21\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2733],\n",
      "        [-0.4256]])\n",
      "batch_y tensor([[0.0231],\n",
      "        [0.0086]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 22\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2054],\n",
      "        [-1.1094]])\n",
      "batch_y tensor([[ 0.1343],\n",
      "        [-0.0576]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 23\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.8350],\n",
      "        [-0.0086]])\n",
      "batch_y tensor([[-0.1049],\n",
      "        [ 0.0057]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 24\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1455],\n",
      "        [-0.0495]])\n",
      "batch_y tensor([[ 0.1155],\n",
      "        [-0.0558]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 25\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2657],\n",
      "        [-0.0263]])\n",
      "batch_y tensor([[-1.2828],\n",
      "        [ 0.0234]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 26\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0686],\n",
      "        [-0.1717]])\n",
      "batch_y tensor([[-0.0736],\n",
      "        [-0.0920]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 27\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0032],\n",
      "        [ 0.0639]])\n",
      "batch_y tensor([[ 0.0582],\n",
      "        [-0.0120]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 28\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0188],\n",
      "        [ 0.2331]])\n",
      "batch_y tensor([[ 0.2029],\n",
      "        [-0.0546]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 29\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4643],\n",
      "        [-0.0674]])\n",
      "batch_y tensor([[-0.0328],\n",
      "        [-0.2691]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 30\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0129],\n",
      "        [-0.0239]])\n",
      "batch_y tensor([[-0.1011],\n",
      "        [-0.1915]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 31\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6437],\n",
      "        [ 0.0598]])\n",
      "batch_y tensor([[-0.0498],\n",
      "        [ 0.0309]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 32\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0172],\n",
      "        [-0.0379]])\n",
      "batch_y tensor([[-0.0026],\n",
      "        [-0.0137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 33\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2270],\n",
      "        [-6.9505]])\n",
      "batch_y tensor([[-0.1743],\n",
      "        [-0.0415]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 34\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5396],\n",
      "        [ 0.0878]])\n",
      "batch_y tensor([[ 0.1226],\n",
      "        [-0.1688]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 35\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1169],\n",
      "        [-0.0228]])\n",
      "batch_y tensor([[0.1104],\n",
      "        [0.3376]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 36\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0496],\n",
      "        [ 0.2270]])\n",
      "batch_y tensor([[ 0.3400],\n",
      "        [-1.3681]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 37\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0408],\n",
      "        [-0.0519]])\n",
      "batch_y tensor([[-0.0292],\n",
      "        [ 0.0037]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 38\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0551],\n",
      "        [-0.0716]])\n",
      "batch_y tensor([[ 0.0103],\n",
      "        [-0.1300]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 39\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0407],\n",
      "        [-0.1835]])\n",
      "batch_y tensor([[ 0.0641],\n",
      "        [-0.0089]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 40\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1524],\n",
      "        [-0.1318]])\n",
      "batch_y tensor([[-0.3027],\n",
      "        [ 0.0774]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 41\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1884],\n",
      "        [-0.0455]])\n",
      "batch_y tensor([[0.0083],\n",
      "        [1.3015]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 42\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0101],\n",
      "        [-0.1358]])\n",
      "batch_y tensor([[ 0.0024],\n",
      "        [-0.1947]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 43\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0250],\n",
      "        [-0.2690]])\n",
      "batch_y tensor([[-0.3594],\n",
      "        [-0.1438]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 44\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0924],\n",
      "        [ 0.3663]])\n",
      "batch_y tensor([[-0.2056],\n",
      "        [ 0.5751]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 45\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0048],\n",
      "        [-0.0604]])\n",
      "batch_y tensor([[-0.2239],\n",
      "        [ 0.0979]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 46\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2452],\n",
      "        [ 0.1370]])\n",
      "batch_y tensor([[ 0.0063],\n",
      "        [-0.3812]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 47\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0532],\n",
      "        [0.0307]])\n",
      "batch_y tensor([[0.0327],\n",
      "        [0.0202]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 48\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0391],\n",
      "        [-0.3393]])\n",
      "batch_y tensor([[ 0.0001],\n",
      "        [-0.0249]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 49\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4237],\n",
      "        [ 0.0018]])\n",
      "batch_y tensor([[0.1527],\n",
      "        [0.1391]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 50\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1699],\n",
      "        [ 0.1529]])\n",
      "batch_y tensor([[0.1653],\n",
      "        [0.5244]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 51\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0487],\n",
      "        [-0.1060]])\n",
      "batch_y tensor([[ 0.0392],\n",
      "        [-0.0911]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 52\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0036],\n",
      "        [-0.2107]])\n",
      "batch_y tensor([[9.8770],\n",
      "        [0.3215]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 53\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0230],\n",
      "        [-0.0144]])\n",
      "batch_y tensor([[0.0399],\n",
      "        [0.4075]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 54\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0021],\n",
      "        [-0.1120]])\n",
      "batch_y tensor([[-0.0638],\n",
      "        [ 0.0543]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 55\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0584],\n",
      "        [ 0.3059]])\n",
      "batch_y tensor([[ 0.0412],\n",
      "        [-0.0679]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 56\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2015],\n",
      "        [ 0.2767]])\n",
      "batch_y tensor([[-0.2740],\n",
      "        [ 0.0446]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 57\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0022],\n",
      "        [ 0.0540]])\n",
      "batch_y tensor([[-0.0289],\n",
      "        [ 1.7219]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 58\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0438],\n",
      "        [ 0.0676]])\n",
      "batch_y tensor([[-0.0421],\n",
      "        [ 0.1392]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 59\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1122],\n",
      "        [ 0.0366]])\n",
      "batch_y tensor([[ 0.0159],\n",
      "        [-0.9923]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 60\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0299],\n",
      "        [0.8126]])\n",
      "batch_y tensor([[0.8072],\n",
      "        [0.1602]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 61\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0853],\n",
      "        [0.0495]])\n",
      "batch_y tensor([[0.0802],\n",
      "        [0.6738]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 62\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0546],\n",
      "        [ 0.6707]])\n",
      "batch_y tensor([[0.0149],\n",
      "        [0.8919]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 63\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0240],\n",
      "        [0.0317]])\n",
      "batch_y tensor([[ 0.3406],\n",
      "        [-0.6142]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 64\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1290],\n",
      "        [-0.5093]])\n",
      "batch_y tensor([[0.0007],\n",
      "        [0.0945]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 65\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1032],\n",
      "        [ 0.0906]])\n",
      "batch_y tensor([[0.0145],\n",
      "        [0.2538]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 66\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3962],\n",
      "        [0.1220]])\n",
      "batch_y tensor([[-0.0633],\n",
      "        [-0.0397]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 67\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1602],\n",
      "        [0.3344]])\n",
      "batch_y tensor([[0.1166],\n",
      "        [0.0722]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 68\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5470],\n",
      "        [-0.1460]])\n",
      "batch_y tensor([[-0.0774],\n",
      "        [-0.0115]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 69\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4029],\n",
      "        [ 0.0372]])\n",
      "batch_y tensor([[-0.1214],\n",
      "        [ 0.0465]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 70\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0055],\n",
      "        [-0.0550]])\n",
      "batch_y tensor([[-0.1014],\n",
      "        [ 0.1565]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 71\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0302],\n",
      "        [-0.0116]])\n",
      "batch_y tensor([[-0.0836],\n",
      "        [-0.4727]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 72\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3121],\n",
      "        [0.0512]])\n",
      "batch_y tensor([[-0.1386],\n",
      "        [-0.1365]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 73\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1850],\n",
      "        [-0.0055]])\n",
      "batch_y tensor([[0.0458],\n",
      "        [0.0365]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 74\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0108],\n",
      "        [-0.6472]])\n",
      "batch_y tensor([[-0.1457],\n",
      "        [-0.0096]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 75\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0960],\n",
      "        [-0.3791]])\n",
      "batch_y tensor([[-0.6540],\n",
      "        [-0.0594]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 76\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0864],\n",
      "        [-0.2688]])\n",
      "batch_y tensor([[0.0622],\n",
      "        [0.4213]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 77\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2179],\n",
      "        [-0.1672]])\n",
      "batch_y tensor([[-0.0509],\n",
      "        [-0.1421]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 78\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2488],\n",
      "        [0.0768]])\n",
      "batch_y tensor([[-0.0688],\n",
      "        [ 0.5039]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 79\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2424],\n",
      "        [ 0.2905]])\n",
      "batch_y tensor([[-0.2221],\n",
      "        [ 0.0310]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 80\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0461],\n",
      "        [ 0.0193]])\n",
      "batch_y tensor([[ 0.0224],\n",
      "        [-0.3555]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 81\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0094],\n",
      "        [0.3461]])\n",
      "batch_y tensor([[0.0123],\n",
      "        [0.0223]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 82\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0290],\n",
      "        [-0.2589]])\n",
      "batch_y tensor([[-0.1551],\n",
      "        [-0.0074]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 83\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0061],\n",
      "        [ 2.5413]])\n",
      "batch_y tensor([[ 0.6132],\n",
      "        [-0.0471]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 84\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.9873],\n",
      "        [3.8335]])\n",
      "batch_y tensor([[0.3446],\n",
      "        [0.0094]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 85\n",
      "================\n",
      "\n",
      "batch_x tensor([[-3.2533],\n",
      "        [-0.0326]])\n",
      "batch_y tensor([[-0.1710],\n",
      "        [ 0.0807]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 86\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0170],\n",
      "        [0.0122]])\n",
      "batch_y tensor([[ 0.0904],\n",
      "        [-0.2908]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 87\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1387],\n",
      "        [0.0163]])\n",
      "batch_y tensor([[-0.0545],\n",
      "        [-1.0637]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 88\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1129],\n",
      "        [-0.0526]])\n",
      "batch_y tensor([[0.1008],\n",
      "        [0.1420]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 89\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2106],\n",
      "        [0.1301]])\n",
      "batch_y tensor([[ 0.0461],\n",
      "        [-0.1916]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 90\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2709],\n",
      "        [-0.0017]])\n",
      "batch_y tensor([[-1.0447],\n",
      "        [-0.0430]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 91\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0189],\n",
      "        [-0.0751]])\n",
      "batch_y tensor([[-1.3523],\n",
      "        [-0.3107]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 92\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2332],\n",
      "        [ 0.2206]])\n",
      "batch_y tensor([[ 0.1918],\n",
      "        [-0.0444]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 93\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.2070],\n",
      "        [-0.0038]])\n",
      "batch_y tensor([[-0.0710],\n",
      "        [-0.0137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 94\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1399],\n",
      "        [-0.2358]])\n",
      "batch_y tensor([[ 0.0084],\n",
      "        [-0.0392]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 95\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0434],\n",
      "        [-0.1965]])\n",
      "batch_y tensor([[-0.3743],\n",
      "        [-0.1720]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 96\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0343],\n",
      "        [-3.1850]])\n",
      "batch_y tensor([[ 0.0388],\n",
      "        [-0.0756]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 97\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1171],\n",
      "        [0.0219]])\n",
      "batch_y tensor([[ 0.0277],\n",
      "        [-0.0034]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 98\n",
      "================\n",
      "\n",
      "batch_x tensor([[-4.7651],\n",
      "        [-0.0516]])\n",
      "batch_y tensor([[0.0306],\n",
      "        [0.1064]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 99\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0869],\n",
      "        [-0.1096]])\n",
      "batch_y tensor([[0.1932],\n",
      "        [0.1923]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 100\n",
      "================\n",
      "\n",
      "batch_x tensor([[3.5573],\n",
      "        [0.0068]])\n",
      "batch_y tensor([[-0.1017],\n",
      "        [ 0.0832]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 101\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0160],\n",
      "        [0.3364]])\n",
      "batch_y tensor([[-0.0648],\n",
      "        [-0.1883]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 102\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2173],\n",
      "        [ 0.1381]])\n",
      "batch_y tensor([[ 0.0259],\n",
      "        [-4.4293]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 103\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0745],\n",
      "        [-0.4859]])\n",
      "batch_y tensor([[-0.1465],\n",
      "        [ 0.1397]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 104\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0259],\n",
      "        [ 0.0357]])\n",
      "batch_y tensor([[0.0683],\n",
      "        [0.1462]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 105\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1859],\n",
      "        [-0.0322]])\n",
      "batch_y tensor([[-0.0478],\n",
      "        [-0.0967]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 106\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1077],\n",
      "        [-0.0583]])\n",
      "batch_y tensor([[ 0.2212],\n",
      "        [-0.0908]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 107\n",
      "================\n",
      "\n",
      "batch_x tensor([[-13.5472],\n",
      "        [ -0.6637]])\n",
      "batch_y tensor([[-0.2685],\n",
      "        [-0.0846]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 108\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.7449],\n",
      "        [0.0490]])\n",
      "batch_y tensor([[-0.3689],\n",
      "        [ 0.0527]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 109\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0946],\n",
      "        [ 0.1863]])\n",
      "batch_y tensor([[-0.0851],\n",
      "        [-0.9076]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 110\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1701],\n",
      "        [ 0.0423]])\n",
      "batch_y tensor([[ 0.0478],\n",
      "        [-0.0175]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 111\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0314],\n",
      "        [-0.0522]])\n",
      "batch_y tensor([[ 0.0384],\n",
      "        [-2.1552]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 112\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2232],\n",
      "        [ 0.0480]])\n",
      "batch_y tensor([[0.0623],\n",
      "        [0.0613]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 113\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 7.5809e-03],\n",
      "        [-2.2195e+01]])\n",
      "batch_y tensor([[-0.0595],\n",
      "        [-0.1331]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 114\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0891],\n",
      "        [0.0136]])\n",
      "batch_y tensor([[0.0546],\n",
      "        [0.5060]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 115\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6503],\n",
      "        [0.0288]])\n",
      "batch_y tensor([[0.1543],\n",
      "        [0.0240]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 116\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0540],\n",
      "        [-0.0876]])\n",
      "batch_y tensor([[0.1724],\n",
      "        [0.1390]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 117\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.8586],\n",
      "        [ 0.0625]])\n",
      "batch_y tensor([[-0.2599],\n",
      "        [ 0.0099]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 118\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0211],\n",
      "        [ 0.1586]])\n",
      "batch_y tensor([[-0.0175],\n",
      "        [ 0.8402]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 119\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.1838],\n",
      "        [0.0983]])\n",
      "batch_y tensor([[0.1626],\n",
      "        [0.2107]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 120\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0565],\n",
      "        [ 5.9961]])\n",
      "batch_y tensor([[-0.1500],\n",
      "        [ 0.0227]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 121\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0013],\n",
      "        [-0.0311]])\n",
      "batch_y tensor([[-0.0277],\n",
      "        [-0.0025]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 122\n",
      "================\n",
      "\n",
      "batch_x tensor([[  0.1546],\n",
      "        [-34.8098]])\n",
      "batch_y tensor([[0.1273],\n",
      "        [0.0648]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 123\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6326],\n",
      "        [0.1057]])\n",
      "batch_y tensor([[ 0.0656],\n",
      "        [-0.7170]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 124\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0879],\n",
      "        [-0.0922]])\n",
      "batch_y tensor([[ 0.2403],\n",
      "        [-0.0440]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 125\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0034],\n",
      "        [-0.1365]])\n",
      "batch_y tensor([[-0.0027],\n",
      "        [ 0.8182]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 126\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0050],\n",
      "        [0.1274]])\n",
      "batch_y tensor([[-0.2178],\n",
      "        [ 0.0850]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 127\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0077],\n",
      "        [-0.0240]])\n",
      "batch_y tensor([[ 0.0062],\n",
      "        [-0.0761]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 128\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0014],\n",
      "        [0.0190]])\n",
      "batch_y tensor([[-0.0609],\n",
      "        [-0.0100]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 129\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0287],\n",
      "        [ 0.0098]])\n",
      "batch_y tensor([[-0.0554],\n",
      "        [-0.0619]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 130\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.2727],\n",
      "        [-2.9294]])\n",
      "batch_y tensor([[-0.0957],\n",
      "        [ 0.0002]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 131\n",
      "================\n",
      "\n",
      "batch_x tensor([[-6.7449],\n",
      "        [ 0.6594]])\n",
      "batch_y tensor([[-0.0033],\n",
      "        [ 0.0205]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 132\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.5540],\n",
      "        [0.0184]])\n",
      "batch_y tensor([[0.0192],\n",
      "        [0.0398]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 133\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3178],\n",
      "        [0.2108]])\n",
      "batch_y tensor([[-0.0264],\n",
      "        [ 0.4934]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 134\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0232],\n",
      "        [-0.2873]])\n",
      "batch_y tensor([[ 0.1965],\n",
      "        [-0.3047]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 135\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2671],\n",
      "        [-0.0857]])\n",
      "batch_y tensor([[0.0076],\n",
      "        [0.1795]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 136\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0710],\n",
      "        [0.0118]])\n",
      "batch_y tensor([[-0.3941],\n",
      "        [-0.0301]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 137\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0790],\n",
      "        [ 0.1416]])\n",
      "batch_y tensor([[1.5125],\n",
      "        [0.0145]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 138\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0394],\n",
      "        [-0.1223]])\n",
      "batch_y tensor([[ 0.0412],\n",
      "        [-0.0043]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 139\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0663],\n",
      "        [ 0.3047]])\n",
      "batch_y tensor([[ 0.2775],\n",
      "        [-0.0050]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 140\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.1196],\n",
      "        [-0.0112]])\n",
      "batch_y tensor([[-0.0656],\n",
      "        [-0.1118]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 141\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1111],\n",
      "        [ 0.2548]])\n",
      "batch_y tensor([[-0.0658],\n",
      "        [-1.0940]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 142\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.3260],\n",
      "        [-0.0043]])\n",
      "batch_y tensor([[ 0.1241],\n",
      "        [-0.6834]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 143\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0313],\n",
      "        [-0.0339]])\n",
      "batch_y tensor([[ 0.4900],\n",
      "        [-0.0724]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 144\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1213],\n",
      "        [ 0.0698]])\n",
      "batch_y tensor([[-0.0226],\n",
      "        [-0.0467]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 145\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0860],\n",
      "        [0.2061]])\n",
      "batch_y tensor([[-0.0937],\n",
      "        [-0.2202]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 146\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1146],\n",
      "        [-0.0739]])\n",
      "batch_y tensor([[0.0245],\n",
      "        [0.0674]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 147\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0733],\n",
      "        [-0.0612]])\n",
      "batch_y tensor([[ 0.0132],\n",
      "        [-0.0729]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 148\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2675],\n",
      "        [-0.0234]])\n",
      "batch_y tensor([[0.0484],\n",
      "        [0.3033]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 149\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0046],\n",
      "        [-0.2688]])\n",
      "batch_y tensor([[0.0511],\n",
      "        [0.0777]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 150\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1194],\n",
      "        [1.0593]])\n",
      "batch_y tensor([[0.0679],\n",
      "        [0.0873]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 151\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1557],\n",
      "        [-0.1348]])\n",
      "batch_y tensor([[-0.3630],\n",
      "        [-0.0324]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 152\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0772],\n",
      "        [2.0754]])\n",
      "batch_y tensor([[-0.6835],\n",
      "        [ 0.1136]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 153\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0499],\n",
      "        [ 9.2647]])\n",
      "batch_y tensor([[ 0.1795],\n",
      "        [-0.4118]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 154\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0435],\n",
      "        [0.1276]])\n",
      "batch_y tensor([[0.2335],\n",
      "        [0.1011]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 155\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1958],\n",
      "        [ 0.0052]])\n",
      "batch_y tensor([[-0.0804],\n",
      "        [-0.0579]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 156\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1119],\n",
      "        [-0.0277]])\n",
      "batch_y tensor([[0.0735],\n",
      "        [0.0043]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 157\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0340],\n",
      "        [-0.0863]])\n",
      "batch_y tensor([[ 0.5585],\n",
      "        [-0.4199]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 158\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0151],\n",
      "        [-0.2983]])\n",
      "batch_y tensor([[ 0.2466],\n",
      "        [-0.0210]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 159\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0780],\n",
      "        [ 0.1896]])\n",
      "batch_y tensor([[0.1424],\n",
      "        [0.3805]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 160\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.9821],\n",
      "        [ 0.0057]])\n",
      "batch_y tensor([[-0.0354],\n",
      "        [-0.0463]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 161\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 7.0559e-05],\n",
      "        [-6.3034e-02]])\n",
      "batch_y tensor([[-0.0220],\n",
      "        [-0.1353]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 162\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0092],\n",
      "        [-0.2837]])\n",
      "batch_y tensor([[-0.0996],\n",
      "        [ 0.0339]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 163\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.4076],\n",
      "        [-0.7639]])\n",
      "batch_y tensor([[0.0470],\n",
      "        [2.9238]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 164\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0109],\n",
      "        [-0.1117]])\n",
      "batch_y tensor([[-0.1430],\n",
      "        [-0.0511]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 165\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1732],\n",
      "        [0.0969]])\n",
      "batch_y tensor([[-0.5055],\n",
      "        [-0.0663]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 166\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1246],\n",
      "        [-0.4221]])\n",
      "batch_y tensor([[-0.8318],\n",
      "        [-0.0375]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 167\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2420],\n",
      "        [ 0.2333]])\n",
      "batch_y tensor([[0.0897],\n",
      "        [1.3798]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 168\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0257],\n",
      "        [0.1641]])\n",
      "batch_y tensor([[-12.0153],\n",
      "        [  0.0285]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 169\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0487],\n",
      "        [1.2361]])\n",
      "batch_y tensor([[-0.0186],\n",
      "        [-0.7221]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 170\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0203],\n",
      "        [0.0024]])\n",
      "batch_y tensor([[ 0.1145],\n",
      "        [-0.1998]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 171\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0177],\n",
      "        [0.1717]])\n",
      "batch_y tensor([[-0.6683],\n",
      "        [-0.1658]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 172\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1154],\n",
      "        [ 0.0567]])\n",
      "batch_y tensor([[-0.0451],\n",
      "        [ 0.5450]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 173\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0048],\n",
      "        [-0.0251]])\n",
      "batch_y tensor([[-0.6878],\n",
      "        [-0.6435]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 174\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0856],\n",
      "        [-0.0290]])\n",
      "batch_y tensor([[-0.9376],\n",
      "        [-0.0226]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 175\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1025],\n",
      "        [ 0.1222]])\n",
      "batch_y tensor([[ 0.0611],\n",
      "        [-0.1489]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 176\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0376],\n",
      "        [-0.4430]])\n",
      "batch_y tensor([[-0.1359],\n",
      "        [ 0.1011]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 177\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0936],\n",
      "        [-0.0156]])\n",
      "batch_y tensor([[0.1237],\n",
      "        [0.0900]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 178\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2339],\n",
      "        [-0.4542]])\n",
      "batch_y tensor([[0.0952],\n",
      "        [0.0059]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 179\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0462],\n",
      "        [ 0.2226]])\n",
      "batch_y tensor([[-0.0186],\n",
      "        [-0.2934]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 180\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0791],\n",
      "        [-2.3456]])\n",
      "batch_y tensor([[ 0.0168],\n",
      "        [-0.2963]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 181\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.9312],\n",
      "        [ 0.0571]])\n",
      "batch_y tensor([[ 0.0874],\n",
      "        [-0.4094]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 182\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0185],\n",
      "        [-0.0933]])\n",
      "batch_y tensor([[-0.0824],\n",
      "        [ 0.0577]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 183\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2811],\n",
      "        [-0.1384]])\n",
      "batch_y tensor([[0.3160],\n",
      "        [0.0170]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 184\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0491],\n",
      "        [-0.0417]])\n",
      "batch_y tensor([[0.0141],\n",
      "        [0.0295]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 185\n",
      "================\n",
      "\n",
      "batch_x tensor([[-9.3257],\n",
      "        [ 0.0847]])\n",
      "batch_y tensor([[ 0.1101],\n",
      "        [-0.0587]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 186\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0430],\n",
      "        [ 0.1971]])\n",
      "batch_y tensor([[-0.5469],\n",
      "        [ 0.0739]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 187\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6400],\n",
      "        [-0.4726]])\n",
      "batch_y tensor([[-1.2248],\n",
      "        [-0.0243]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 188\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1414],\n",
      "        [ 0.0523]])\n",
      "batch_y tensor([[-0.0798],\n",
      "        [-0.0742]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 189\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.6100],\n",
      "        [-0.0543]])\n",
      "batch_y tensor([[-0.1942],\n",
      "        [-0.1267]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 190\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0381],\n",
      "        [-0.0006]])\n",
      "batch_y tensor([[-0.0628],\n",
      "        [-0.1052]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 191\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0013],\n",
      "        [ 0.1113]])\n",
      "batch_y tensor([[-0.0254],\n",
      "        [ 0.1788]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 192\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1147],\n",
      "        [-0.0701]])\n",
      "batch_y tensor([[-0.0043],\n",
      "        [-0.0392]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 193\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0580],\n",
      "        [0.1487]])\n",
      "batch_y tensor([[ 0.0024],\n",
      "        [-2.4040]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 194\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0731],\n",
      "        [ 0.0231]])\n",
      "batch_y tensor([[-0.0077],\n",
      "        [-0.0988]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 195\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2716],\n",
      "        [-0.0768]])\n",
      "batch_y tensor([[ 0.5787],\n",
      "        [-0.0236]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 196\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2154],\n",
      "        [-0.0087]])\n",
      "batch_y tensor([[-0.0170],\n",
      "        [ 0.1693]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 197\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0072],\n",
      "        [-0.0630]])\n",
      "batch_y tensor([[0.2603],\n",
      "        [0.0076]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 198\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0106],\n",
      "        [-0.0794]])\n",
      "batch_y tensor([[-0.0464],\n",
      "        [ 0.4340]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 199\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3951],\n",
      "        [ 0.3400]])\n",
      "batch_y tensor([[ 0.1462],\n",
      "        [-0.3813]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 200\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2265],\n",
      "        [-0.1214]])\n",
      "batch_y tensor([[ 0.5200],\n",
      "        [-0.1671]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 201\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0646],\n",
      "        [0.0553]])\n",
      "batch_y tensor([[ 0.3476],\n",
      "        [-0.3698]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 202\n",
      "================\n",
      "\n",
      "batch_x tensor([[-7.9219e+00],\n",
      "        [ 4.8546e-03]])\n",
      "batch_y tensor([[0.1399],\n",
      "        [0.0956]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 203\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0168],\n",
      "        [ 0.1835]])\n",
      "batch_y tensor([[-1.1459],\n",
      "        [-2.9778]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 204\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1181],\n",
      "        [0.1981]])\n",
      "batch_y tensor([[-0.4142],\n",
      "        [-0.0494]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 205\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1820],\n",
      "        [0.0101]])\n",
      "batch_y tensor([[ 0.2255],\n",
      "        [-0.3852]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 206\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.4091],\n",
      "        [0.0982]])\n",
      "batch_y tensor([[0.0339],\n",
      "        [0.1598]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 207\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0481],\n",
      "        [-0.0622]])\n",
      "batch_y tensor([[ 0.1894],\n",
      "        [-0.0546]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 208\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0425],\n",
      "        [ 0.0211]])\n",
      "batch_y tensor([[-3.8582],\n",
      "        [ 0.3392]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 209\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2268],\n",
      "        [0.0310]])\n",
      "batch_y tensor([[0.1663],\n",
      "        [0.0145]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 210\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0230],\n",
      "        [-1.9544]])\n",
      "batch_y tensor([[ -0.1815],\n",
      "        [-12.2048]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 211\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0907],\n",
      "        [-0.0007]])\n",
      "batch_y tensor([[0.0043],\n",
      "        [0.9142]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 212\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2205],\n",
      "        [-0.0285]])\n",
      "batch_y tensor([[0.0539],\n",
      "        [0.1520]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 213\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1318],\n",
      "        [ 0.2150]])\n",
      "batch_y tensor([[ 0.1320],\n",
      "        [-0.0212]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 214\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0552],\n",
      "        [-0.1934]])\n",
      "batch_y tensor([[-0.0499],\n",
      "        [ 0.0406]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 215\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.9925],\n",
      "        [ 0.0049]])\n",
      "batch_y tensor([[-0.0466],\n",
      "        [-0.3343]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 216\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.7275],\n",
      "        [0.0811]])\n",
      "batch_y tensor([[-0.2754],\n",
      "        [-0.0809]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 217\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0526],\n",
      "        [-0.1205]])\n",
      "batch_y tensor([[0.0003],\n",
      "        [0.1874]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 218\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1169],\n",
      "        [ 0.1526]])\n",
      "batch_y tensor([[-0.5648],\n",
      "        [ 0.0952]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 219\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2386],\n",
      "        [0.2858]])\n",
      "batch_y tensor([[-0.1309],\n",
      "        [-0.0187]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 220\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4255],\n",
      "        [-0.2479]])\n",
      "batch_y tensor([[ 1.8376],\n",
      "        [-0.0443]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 221\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0342],\n",
      "        [-0.0722]])\n",
      "batch_y tensor([[ 0.0245],\n",
      "        [-0.1266]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 222\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0175],\n",
      "        [-0.1935]])\n",
      "batch_y tensor([[-0.0710],\n",
      "        [ 0.1751]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 223\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1724],\n",
      "        [-0.0186]])\n",
      "batch_y tensor([[ 0.1358],\n",
      "        [-0.1553]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 224\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0906],\n",
      "        [-0.0749]])\n",
      "batch_y tensor([[-0.4131],\n",
      "        [ 0.0186]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 225\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0444],\n",
      "        [-0.2023]])\n",
      "batch_y tensor([[ 0.0185],\n",
      "        [-0.2743]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 226\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3054],\n",
      "        [-0.0997]])\n",
      "batch_y tensor([[-0.5500],\n",
      "        [-0.0248]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 227\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0359],\n",
      "        [-0.0964]])\n",
      "batch_y tensor([[ 0.1222],\n",
      "        [-0.1082]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 228\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2323],\n",
      "        [ 0.2160]])\n",
      "batch_y tensor([[-0.2737],\n",
      "        [ 0.0806]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 229\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0036],\n",
      "        [-0.0649]])\n",
      "batch_y tensor([[-0.2519],\n",
      "        [-0.2736]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 230\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0277],\n",
      "        [ 0.5936]])\n",
      "batch_y tensor([[-0.0163],\n",
      "        [-0.0433]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 231\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0809],\n",
      "        [0.1355]])\n",
      "batch_y tensor([[ 0.0146],\n",
      "        [-0.1264]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 232\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2123],\n",
      "        [-0.0131]])\n",
      "batch_y tensor([[-0.0576],\n",
      "        [ 0.0804]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 233\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.7334],\n",
      "        [ 0.1786]])\n",
      "batch_y tensor([[-0.0711],\n",
      "        [ 0.6692]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 234\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1339],\n",
      "        [-0.1458]])\n",
      "batch_y tensor([[-0.1319],\n",
      "        [ 0.0015]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 235\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0175],\n",
      "        [ 9.2424]])\n",
      "batch_y tensor([[ 0.1103],\n",
      "        [-0.0536]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 236\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0035],\n",
      "        [-1.3196]])\n",
      "batch_y tensor([[-0.8611],\n",
      "        [ 0.3048]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 237\n",
      "================\n",
      "\n",
      "batch_x tensor([[-9.5231],\n",
      "        [ 0.0595]])\n",
      "batch_y tensor([[-0.4079],\n",
      "        [-0.0408]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 238\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1630],\n",
      "        [ 0.0735]])\n",
      "batch_y tensor([[ 0.7985],\n",
      "        [-0.1613]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 239\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1240],\n",
      "        [-0.0259]])\n",
      "batch_y tensor([[ 0.1792],\n",
      "        [-0.0858]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 240\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0515],\n",
      "        [ 0.6227]])\n",
      "batch_y tensor([[ 0.0173],\n",
      "        [-0.1194]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 241\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0137],\n",
      "        [-0.4995]])\n",
      "batch_y tensor([[ 0.0871],\n",
      "        [-0.0327]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 242\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0637],\n",
      "        [0.7025]])\n",
      "batch_y tensor([[ 0.4407],\n",
      "        [-1.0155]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 243\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.8248],\n",
      "        [-0.4280]])\n",
      "batch_y tensor([[-0.0647],\n",
      "        [ 0.0663]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 244\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3510],\n",
      "        [0.3112]])\n",
      "batch_y tensor([[-0.1403],\n",
      "        [-1.6625]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 245\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0600],\n",
      "        [-0.3180]])\n",
      "batch_y tensor([[-0.0893],\n",
      "        [ 0.0201]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 246\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0170],\n",
      "        [ 0.0215]])\n",
      "batch_y tensor([[0.4522],\n",
      "        [0.0391]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 247\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0130],\n",
      "        [ 0.4895]])\n",
      "batch_y tensor([[ 0.4965],\n",
      "        [-0.0754]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 248\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0155],\n",
      "        [-0.0543]])\n",
      "batch_y tensor([[-2.9458],\n",
      "        [-0.3313]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 249\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0238],\n",
      "        [ 0.6183]])\n",
      "batch_y tensor([[ 0.0244],\n",
      "        [-0.1388]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 250\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.7619],\n",
      "        [-0.0749]])\n",
      "batch_y tensor([[-0.1866],\n",
      "        [-0.0940]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 251\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0294],\n",
      "        [-0.0354]])\n",
      "batch_y tensor([[-0.0438],\n",
      "        [-0.0202]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 252\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2643],\n",
      "        [0.3828]])\n",
      "batch_y tensor([[0.0265],\n",
      "        [0.0317]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 253\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3142],\n",
      "        [-0.0498]])\n",
      "batch_y tensor([[ 0.0192],\n",
      "        [-0.2539]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 254\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0491],\n",
      "        [ 0.0129]])\n",
      "batch_y tensor([[-0.0259],\n",
      "        [ 0.7761]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 255\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0029],\n",
      "        [-0.6170]])\n",
      "batch_y tensor([[0.5204],\n",
      "        [0.0098]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 256\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0371],\n",
      "        [-0.0730]])\n",
      "batch_y tensor([[ 0.0129],\n",
      "        [-0.0857]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 257\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1603],\n",
      "        [-0.1820]])\n",
      "batch_y tensor([[-0.0601],\n",
      "        [-0.3703]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 258\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0271],\n",
      "        [0.0771]])\n",
      "batch_y tensor([[-0.4447],\n",
      "        [-0.1744]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 259\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0099],\n",
      "        [ 0.4107]])\n",
      "batch_y tensor([[-0.6830],\n",
      "        [-0.0836]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 260\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0264],\n",
      "        [ 0.0241]])\n",
      "batch_y tensor([[-1.0639],\n",
      "        [-0.0175]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 261\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1981],\n",
      "        [-0.0626]])\n",
      "batch_y tensor([[ 0.4482],\n",
      "        [-6.8772]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 262\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0381],\n",
      "        [0.6642]])\n",
      "batch_y tensor([[-0.0843],\n",
      "        [ 0.0938]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 263\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0441],\n",
      "        [-0.5590]])\n",
      "batch_y tensor([[0.3653],\n",
      "        [3.7534]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 264\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6959],\n",
      "        [-0.0548]])\n",
      "batch_y tensor([[0.0223],\n",
      "        [0.2107]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 265\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1432],\n",
      "        [-0.0508]])\n",
      "batch_y tensor([[ 0.0661],\n",
      "        [-0.0669]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 266\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0795],\n",
      "        [0.1515]])\n",
      "batch_y tensor([[ 0.0482],\n",
      "        [-0.1442]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 267\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0546],\n",
      "        [-0.0040]])\n",
      "batch_y tensor([[-5.2447],\n",
      "        [-0.0732]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 268\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1227],\n",
      "        [0.0186]])\n",
      "batch_y tensor([[-0.0346],\n",
      "        [-0.1993]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 269\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0040],\n",
      "        [0.0845]])\n",
      "batch_y tensor([[ 0.2142],\n",
      "        [-0.0894]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 270\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1114],\n",
      "        [ 0.0413]])\n",
      "batch_y tensor([[-0.0059],\n",
      "        [ 0.0274]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 271\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1265],\n",
      "        [-0.1157]])\n",
      "batch_y tensor([[0.2331],\n",
      "        [0.2178]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 272\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3923],\n",
      "        [-0.0246]])\n",
      "batch_y tensor([[2.6874],\n",
      "        [0.2093]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 273\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4111],\n",
      "        [-0.1585]])\n",
      "batch_y tensor([[-0.4070],\n",
      "        [ 0.3778]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 274\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3087],\n",
      "        [-0.1077]])\n",
      "batch_y tensor([[ 0.0241],\n",
      "        [-0.0273]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 275\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0479],\n",
      "        [ 0.0632]])\n",
      "batch_y tensor([[ 0.0610],\n",
      "        [-0.0558]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 276\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1599],\n",
      "        [-0.1293]])\n",
      "batch_y tensor([[-0.0563],\n",
      "        [ 0.0948]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 277\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1041],\n",
      "        [0.0192]])\n",
      "batch_y tensor([[0.0924],\n",
      "        [0.0077]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 278\n",
      "================\n",
      "\n",
      "batch_x tensor([[-2.9551],\n",
      "        [-0.0365]])\n",
      "batch_y tensor([[ 0.1838],\n",
      "        [-0.0159]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 279\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1096],\n",
      "        [-0.0208]])\n",
      "batch_y tensor([[-0.2422],\n",
      "        [-0.0941]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 280\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1009],\n",
      "        [-0.1201]])\n",
      "batch_y tensor([[-0.0418],\n",
      "        [ 0.0120]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 281\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1590],\n",
      "        [ 0.0722]])\n",
      "batch_y tensor([[-0.0136],\n",
      "        [ 0.0285]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 282\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1721],\n",
      "        [ 0.3164]])\n",
      "batch_y tensor([[0.4630],\n",
      "        [0.0205]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 283\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0480],\n",
      "        [-0.1561]])\n",
      "batch_y tensor([[-0.3166],\n",
      "        [-3.8083]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 284\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1057],\n",
      "        [-0.4522]])\n",
      "batch_y tensor([[ 0.7384],\n",
      "        [-0.4247]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 285\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0323],\n",
      "        [-2.8702]])\n",
      "batch_y tensor([[ 0.0044],\n",
      "        [-0.0834]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 286\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.7616],\n",
      "        [ 0.0025]])\n",
      "batch_y tensor([[0.6223],\n",
      "        [0.0217]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 287\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0586],\n",
      "        [-0.0145]])\n",
      "batch_y tensor([[ 0.2782],\n",
      "        [-0.0449]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 288\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1861],\n",
      "        [ 0.0643]])\n",
      "batch_y tensor([[-0.0635],\n",
      "        [ 0.1768]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 289\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0860],\n",
      "        [0.0447]])\n",
      "batch_y tensor([[-0.2786],\n",
      "        [ 0.1062]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 290\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2682],\n",
      "        [-0.1035]])\n",
      "batch_y tensor([[0.0053],\n",
      "        [0.4045]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 291\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.5100],\n",
      "        [0.0113]])\n",
      "batch_y tensor([[-0.0044],\n",
      "        [-0.2971]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 292\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1879],\n",
      "        [-0.0039]])\n",
      "batch_y tensor([[0.0126],\n",
      "        [0.1385]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 293\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0702],\n",
      "        [0.2982]])\n",
      "batch_y tensor([[ 0.0252],\n",
      "        [-0.8488]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 294\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5552],\n",
      "        [ 0.1370]])\n",
      "batch_y tensor([[-0.0185],\n",
      "        [ 0.1234]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 295\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0179],\n",
      "        [-0.0049]])\n",
      "batch_y tensor([[0.0349],\n",
      "        [0.0845]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 296\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0408],\n",
      "        [-0.0184]])\n",
      "batch_y tensor([[0.4257],\n",
      "        [0.4155]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 297\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0972],\n",
      "        [ 0.1812]])\n",
      "batch_y tensor([[-0.2611],\n",
      "        [-0.1107]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 298\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0195],\n",
      "        [-0.0252]])\n",
      "batch_y tensor([[0.0767],\n",
      "        [0.0934]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 299\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0179],\n",
      "        [ 0.2333]])\n",
      "batch_y tensor([[0.2357],\n",
      "        [0.0159]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 300\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5440],\n",
      "        [-0.0330]])\n",
      "batch_y tensor([[ 0.5176],\n",
      "        [-0.1167]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 301\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0347],\n",
      "        [-0.2070]])\n",
      "batch_y tensor([[ 0.1468],\n",
      "        [-0.0589]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 302\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.7187],\n",
      "        [-0.0023]])\n",
      "batch_y tensor([[-0.2239],\n",
      "        [-0.0940]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 303\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1428],\n",
      "        [0.0240]])\n",
      "batch_y tensor([[-0.1005],\n",
      "        [-0.0115]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 304\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0388],\n",
      "        [-0.1170]])\n",
      "batch_y tensor([[-0.0794],\n",
      "        [ 0.0271]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 305\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.4746],\n",
      "        [ 0.6143]])\n",
      "batch_y tensor([[0.3970],\n",
      "        [0.0234]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 306\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.5555],\n",
      "        [0.0371]])\n",
      "batch_y tensor([[0.1036],\n",
      "        [0.3098]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 307\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 2.3350],\n",
      "        [-0.2861]])\n",
      "batch_y tensor([[ 0.0270],\n",
      "        [-0.3737]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 308\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0389],\n",
      "        [0.0827]])\n",
      "batch_y tensor([[0.0824],\n",
      "        [0.1214]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 309\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0773],\n",
      "        [-0.3116]])\n",
      "batch_y tensor([[ 0.5654],\n",
      "        [-0.0725]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 310\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0359],\n",
      "        [-0.0377]])\n",
      "batch_y tensor([[-0.0695],\n",
      "        [ 0.0307]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 311\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0361],\n",
      "        [ 0.0136]])\n",
      "batch_y tensor([[ 0.3883],\n",
      "        [-0.0267]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 312\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2866],\n",
      "        [ 0.3999]])\n",
      "batch_y tensor([[ 0.0466],\n",
      "        [-0.5492]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 313\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0836],\n",
      "        [-0.0216]])\n",
      "batch_y tensor([[-0.0986],\n",
      "        [-0.1879]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 314\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0095],\n",
      "        [-1.1810]])\n",
      "batch_y tensor([[ 0.6538],\n",
      "        [-1.7052]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 315\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0630],\n",
      "        [0.0067]])\n",
      "batch_y tensor([[0.4658],\n",
      "        [0.1452]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 316\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1062],\n",
      "        [-0.1819]])\n",
      "batch_y tensor([[-0.4070],\n",
      "        [ 0.6645]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 317\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0191],\n",
      "        [0.1288]])\n",
      "batch_y tensor([[15.9262],\n",
      "        [-0.0301]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 318\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1587],\n",
      "        [ 1.7610]])\n",
      "batch_y tensor([[0.2074],\n",
      "        [0.1777]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 319\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5011],\n",
      "        [13.4745]])\n",
      "batch_y tensor([[-0.2270],\n",
      "        [ 0.0231]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 320\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0819],\n",
      "        [ 0.0306]])\n",
      "batch_y tensor([[0.2819],\n",
      "        [0.0366]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 321\n",
      "================\n",
      "\n",
      "batch_x tensor([[2.0909],\n",
      "        [0.5483]])\n",
      "batch_y tensor([[-0.0635],\n",
      "        [-0.2069]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 322\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0096],\n",
      "        [0.0790]])\n",
      "batch_y tensor([[4.2309],\n",
      "        [1.0403]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 323\n",
      "================\n",
      "\n",
      "batch_x tensor([[-8.2940],\n",
      "        [ 0.1632]])\n",
      "batch_y tensor([[-0.1497],\n",
      "        [ 0.0234]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 324\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0074],\n",
      "        [-0.0681]])\n",
      "batch_y tensor([[0.4074],\n",
      "        [0.6968]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 325\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1177],\n",
      "        [0.1215]])\n",
      "batch_y tensor([[0.0787],\n",
      "        [0.0546]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 326\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1384],\n",
      "        [-0.0231]])\n",
      "batch_y tensor([[0.0103],\n",
      "        [0.0549]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 327\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0349],\n",
      "        [ 0.0940]])\n",
      "batch_y tensor([[-1.5215],\n",
      "        [ 1.3751]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 328\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.4154],\n",
      "        [0.0405]])\n",
      "batch_y tensor([[ 1.2612],\n",
      "        [-0.0079]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 329\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0205],\n",
      "        [-0.4882]])\n",
      "batch_y tensor([[-0.4021],\n",
      "        [ 0.1256]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 330\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0629],\n",
      "        [ 0.4920]])\n",
      "batch_y tensor([[-0.3234],\n",
      "        [-0.3303]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 331\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0758],\n",
      "        [0.0276]])\n",
      "batch_y tensor([[-0.0307],\n",
      "        [-0.0782]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 332\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0481],\n",
      "        [ 0.0736]])\n",
      "batch_y tensor([[-0.0184],\n",
      "        [ 0.2004]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 333\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0195],\n",
      "        [-0.1370]])\n",
      "batch_y tensor([[ 0.3847],\n",
      "        [12.8843]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 334\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.8556],\n",
      "        [ 0.3334]])\n",
      "batch_y tensor([[6.8802],\n",
      "        [0.1496]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 335\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0528],\n",
      "        [-2.0326]])\n",
      "batch_y tensor([[-0.1208],\n",
      "        [ 0.0056]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 336\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.5226],\n",
      "        [0.3371]])\n",
      "batch_y tensor([[-0.3906],\n",
      "        [ 0.0517]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 337\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0243],\n",
      "        [0.3340]])\n",
      "batch_y tensor([[-0.0222],\n",
      "        [-0.0117]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 338\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3996],\n",
      "        [ 0.0820]])\n",
      "batch_y tensor([[-0.0042],\n",
      "        [ 0.0283]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 339\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0344],\n",
      "        [-0.0654]])\n",
      "batch_y tensor([[ 0.1966],\n",
      "        [-0.0173]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 340\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0064],\n",
      "        [-0.4795]])\n",
      "batch_y tensor([[-0.0043],\n",
      "        [-0.0924]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 341\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0846],\n",
      "        [-0.2567]])\n",
      "batch_y tensor([[ 0.3187],\n",
      "        [-0.0147]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 342\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0484],\n",
      "        [-0.0119]])\n",
      "batch_y tensor([[-0.1931],\n",
      "        [-1.3602]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 343\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.0411],\n",
      "        [0.0754]])\n",
      "batch_y tensor([[-0.4166],\n",
      "        [ 0.1254]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 344\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0650],\n",
      "        [-0.6515]])\n",
      "batch_y tensor([[-0.0476],\n",
      "        [ 0.1081]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 345\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1721],\n",
      "        [-0.1232]])\n",
      "batch_y tensor([[-0.0161],\n",
      "        [-0.0628]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 346\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0271],\n",
      "        [0.1060]])\n",
      "batch_y tensor([[ 0.3866],\n",
      "        [-0.0105]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 347\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1144],\n",
      "        [-4.5253]])\n",
      "batch_y tensor([[-0.0526],\n",
      "        [-0.2021]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 348\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1366],\n",
      "        [ 0.2039]])\n",
      "batch_y tensor([[-0.5090],\n",
      "        [-0.1846]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 349\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0443],\n",
      "        [0.0501]])\n",
      "batch_y tensor([[-0.2654],\n",
      "        [ 0.0228]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 350\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1237],\n",
      "        [ 0.0273]])\n",
      "batch_y tensor([[-0.1687],\n",
      "        [-0.0564]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 351\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0755],\n",
      "        [-0.0312]])\n",
      "batch_y tensor([[-0.2830],\n",
      "        [-0.2576]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 352\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0730],\n",
      "        [ 0.2039]])\n",
      "batch_y tensor([[0.0605],\n",
      "        [0.0208]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 353\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0631],\n",
      "        [-0.0389]])\n",
      "batch_y tensor([[-0.0763],\n",
      "        [-0.0900]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 354\n",
      "================\n",
      "\n",
      "batch_x tensor([[-3.9765],\n",
      "        [-0.0719]])\n",
      "batch_y tensor([[ 0.1815],\n",
      "        [-0.1990]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 355\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2255],\n",
      "        [ 0.3214]])\n",
      "batch_y tensor([[ 0.0525],\n",
      "        [-0.1618]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 356\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.2384],\n",
      "        [-0.1026]])\n",
      "batch_y tensor([[-0.0416],\n",
      "        [ 0.3623]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 357\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4624],\n",
      "        [ 0.0285]])\n",
      "batch_y tensor([[-0.0838],\n",
      "        [-0.1544]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 358\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0259],\n",
      "        [-0.2797]])\n",
      "batch_y tensor([[-0.0007],\n",
      "        [-0.2957]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 359\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0582],\n",
      "        [-0.0044]])\n",
      "batch_y tensor([[ 0.0205],\n",
      "        [-0.3114]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 360\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0010],\n",
      "        [0.0253]])\n",
      "batch_y tensor([[ 0.6702],\n",
      "        [-0.1333]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 361\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0436],\n",
      "        [0.0261]])\n",
      "batch_y tensor([[-0.0032],\n",
      "        [ 1.2595]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 362\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0868],\n",
      "        [-0.3351]])\n",
      "batch_y tensor([[ 0.0358],\n",
      "        [-0.1528]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 363\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1156],\n",
      "        [ 0.1684]])\n",
      "batch_y tensor([[-0.0925],\n",
      "        [ 3.2787]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 364\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0329],\n",
      "        [-0.1158]])\n",
      "batch_y tensor([[-1.7879],\n",
      "        [ 0.0559]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 365\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0383],\n",
      "        [-0.0382]])\n",
      "batch_y tensor([[ 0.1094],\n",
      "        [-0.4732]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 366\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0314],\n",
      "        [ 0.0658]])\n",
      "batch_y tensor([[-0.0513],\n",
      "        [-0.0900]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 367\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1710],\n",
      "        [-1.3905]])\n",
      "batch_y tensor([[ 0.3760],\n",
      "        [-0.0414]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 368\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0061],\n",
      "        [-0.4914]])\n",
      "batch_y tensor([[-0.0340],\n",
      "        [-0.0077]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 369\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0207],\n",
      "        [0.0223]])\n",
      "batch_y tensor([[0.4405],\n",
      "        [0.2031]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 370\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0150],\n",
      "        [ 0.1071]])\n",
      "batch_y tensor([[ 0.1102],\n",
      "        [-0.0128]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 371\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1403],\n",
      "        [-0.3784]])\n",
      "batch_y tensor([[-0.1393],\n",
      "        [ 0.3571]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 372\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0494],\n",
      "        [0.6700]])\n",
      "batch_y tensor([[-0.1218],\n",
      "        [ 0.1428]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 373\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.4945],\n",
      "        [-0.4072]])\n",
      "batch_y tensor([[-0.2043],\n",
      "        [-0.1418]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 374\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0074],\n",
      "        [ 0.2129]])\n",
      "batch_y tensor([[0.1387],\n",
      "        [0.0051]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 375\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0276],\n",
      "        [-0.2505]])\n",
      "batch_y tensor([[-0.2095],\n",
      "        [-0.0410]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 376\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.7866],\n",
      "        [0.0076]])\n",
      "batch_y tensor([[0.1391],\n",
      "        [0.7841]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 377\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3120],\n",
      "        [ 0.1939]])\n",
      "batch_y tensor([[-0.0441],\n",
      "        [ 0.0532]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 378\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0855],\n",
      "        [-0.0399]])\n",
      "batch_y tensor([[-0.0816],\n",
      "        [-0.1023]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 379\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0494],\n",
      "        [0.0218]])\n",
      "batch_y tensor([[0.1046],\n",
      "        [0.0749]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 380\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0090],\n",
      "        [-0.0923]])\n",
      "batch_y tensor([[-0.0368],\n",
      "        [ 0.3393]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 381\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0127],\n",
      "        [0.0534]])\n",
      "batch_y tensor([[0.0252],\n",
      "        [0.3405]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 382\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2229],\n",
      "        [-0.0422]])\n",
      "batch_y tensor([[ 0.0560],\n",
      "        [-0.2286]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 383\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0730],\n",
      "        [-0.1340]])\n",
      "batch_y tensor([[1.4516],\n",
      "        [0.1586]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 384\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0140],\n",
      "        [0.0219]])\n",
      "batch_y tensor([[ 0.0448],\n",
      "        [-0.0929]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 385\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.8467],\n",
      "        [-0.0740]])\n",
      "batch_y tensor([[0.1318],\n",
      "        [0.0974]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 386\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0775],\n",
      "        [-0.0108]])\n",
      "batch_y tensor([[ 0.1342],\n",
      "        [-0.0006]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 387\n",
      "================\n",
      "\n",
      "batch_x tensor([[   9.1587],\n",
      "        [-116.6590]])\n",
      "batch_y tensor([[ 0.0069],\n",
      "        [-0.4727]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 388\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1604],\n",
      "        [ 0.0601]])\n",
      "batch_y tensor([[ 0.0136],\n",
      "        [-1.1535]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 389\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0089],\n",
      "        [-0.0567]])\n",
      "batch_y tensor([[-0.2947],\n",
      "        [ 0.0175]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 390\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1090],\n",
      "        [ 0.1571]])\n",
      "batch_y tensor([[0.0166],\n",
      "        [0.0096]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 391\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1782],\n",
      "        [0.2789]])\n",
      "batch_y tensor([[ 0.0909],\n",
      "        [-0.0617]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 392\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0443],\n",
      "        [ 0.0258]])\n",
      "batch_y tensor([[ 0.0402],\n",
      "        [-0.1342]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 393\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1447],\n",
      "        [0.2230]])\n",
      "batch_y tensor([[ 0.4693],\n",
      "        [-0.0247]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 394\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1019],\n",
      "        [ 0.1275]])\n",
      "batch_y tensor([[-0.2814],\n",
      "        [ 0.2255]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 395\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0438],\n",
      "        [-0.0008]])\n",
      "batch_y tensor([[-0.8253],\n",
      "        [ 0.3119]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 396\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2515],\n",
      "        [0.3521]])\n",
      "batch_y tensor([[-0.6137],\n",
      "        [ 0.1633]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 397\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0574],\n",
      "        [-0.1530]])\n",
      "batch_y tensor([[-0.1083],\n",
      "        [-0.1073]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 398\n",
      "================\n",
      "\n",
      "batch_x tensor([[-11.0609],\n",
      "        [ -0.0681]])\n",
      "batch_y tensor([[-5.9082],\n",
      "        [-0.1372]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 399\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.5938],\n",
      "        [0.2424]])\n",
      "batch_y tensor([[-0.0169],\n",
      "        [-0.0225]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 400\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5258],\n",
      "        [-0.0438]])\n",
      "batch_y tensor([[-0.2878],\n",
      "        [-0.0088]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 401\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0276],\n",
      "        [ 0.0244]])\n",
      "batch_y tensor([[-0.0953],\n",
      "        [-0.3775]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 402\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0384],\n",
      "        [-0.1676]])\n",
      "batch_y tensor([[-0.0456],\n",
      "        [ 0.0067]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 403\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0030],\n",
      "        [0.2329]])\n",
      "batch_y tensor([[-0.0171],\n",
      "        [ 0.1007]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 404\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3606],\n",
      "        [-0.1048]])\n",
      "batch_y tensor([[ 0.5226],\n",
      "        [-0.0367]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 405\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1539],\n",
      "        [-0.0149]])\n",
      "batch_y tensor([[0.0441],\n",
      "        [0.3111]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 406\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0323],\n",
      "        [ 0.4373]])\n",
      "batch_y tensor([[0.0687],\n",
      "        [0.1213]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 407\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0818],\n",
      "        [-0.0381]])\n",
      "batch_y tensor([[ 0.0209],\n",
      "        [-0.2117]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 408\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0005],\n",
      "        [-0.0191]])\n",
      "batch_y tensor([[ 0.0008],\n",
      "        [-0.3582]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 409\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0524],\n",
      "        [-0.0372]])\n",
      "batch_y tensor([[ 0.9598],\n",
      "        [-0.5305]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 410\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0344],\n",
      "        [-0.0897]])\n",
      "batch_y tensor([[ 0.1308],\n",
      "        [-0.0188]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 411\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0216],\n",
      "        [0.1249]])\n",
      "batch_y tensor([[-2.1257],\n",
      "        [ 0.4028]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 412\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1823],\n",
      "        [0.0364]])\n",
      "batch_y tensor([[0.0468],\n",
      "        [0.0727]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 413\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4044],\n",
      "        [-0.0630]])\n",
      "batch_y tensor([[-0.6524],\n",
      "        [ 1.2020]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 414\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4425],\n",
      "        [ 1.5105]])\n",
      "batch_y tensor([[0.7120],\n",
      "        [0.0613]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 415\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5625],\n",
      "        [-0.0779]])\n",
      "batch_y tensor([[0.1459],\n",
      "        [0.0454]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 416\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0382],\n",
      "        [-0.1074]])\n",
      "batch_y tensor([[-0.0860],\n",
      "        [ 0.0183]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 417\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0656],\n",
      "        [0.0303]])\n",
      "batch_y tensor([[-0.1490],\n",
      "        [ 0.1629]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 418\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0010],\n",
      "        [ 0.6396]])\n",
      "batch_y tensor([[0.0279],\n",
      "        [0.7479]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 419\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0504],\n",
      "        [-0.0635]])\n",
      "batch_y tensor([[-0.1404],\n",
      "        [ 0.0310]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 420\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0077],\n",
      "        [ 0.0142]])\n",
      "batch_y tensor([[-0.6504],\n",
      "        [ 0.1492]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 421\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.0324],\n",
      "        [-0.0542]])\n",
      "batch_y tensor([[ 0.0864],\n",
      "        [-0.1716]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 422\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6610],\n",
      "        [-0.3282]])\n",
      "batch_y tensor([[-1.9760],\n",
      "        [-1.0422]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 423\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0961],\n",
      "        [-0.0313]])\n",
      "batch_y tensor([[ 0.0676],\n",
      "        [-0.0214]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 424\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1618],\n",
      "        [ 0.2953]])\n",
      "batch_y tensor([[-0.1909],\n",
      "        [-1.7853]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 425\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0239],\n",
      "        [0.1469]])\n",
      "batch_y tensor([[6.7613],\n",
      "        [0.0380]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 426\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1258],\n",
      "        [-0.1487]])\n",
      "batch_y tensor([[-0.0408],\n",
      "        [-0.0216]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 427\n",
      "================\n",
      "\n",
      "batch_x tensor([[-5.0564e-04],\n",
      "        [ 1.0695e+00]])\n",
      "batch_y tensor([[-0.3376],\n",
      "        [ 0.0315]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 428\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0373],\n",
      "        [-0.7019]])\n",
      "batch_y tensor([[ 0.1220],\n",
      "        [-0.2484]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 429\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0272],\n",
      "        [-0.0271]])\n",
      "batch_y tensor([[-0.0358],\n",
      "        [ 1.9280]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 430\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.1910],\n",
      "        [0.0835]])\n",
      "batch_y tensor([[-0.0185],\n",
      "        [ 0.0360]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 431\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1460],\n",
      "        [0.0274]])\n",
      "batch_y tensor([[-0.0213],\n",
      "        [-0.7972]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 432\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3260],\n",
      "        [-0.0527]])\n",
      "batch_y tensor([[-0.3484],\n",
      "        [-0.0829]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 433\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6692],\n",
      "        [-0.0504]])\n",
      "batch_y tensor([[-0.0878],\n",
      "        [-0.0190]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 434\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.5350],\n",
      "        [0.0017]])\n",
      "batch_y tensor([[-0.0201],\n",
      "        [-0.1252]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 435\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0405],\n",
      "        [0.1210]])\n",
      "batch_y tensor([[0.0020],\n",
      "        [0.2108]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 436\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0947],\n",
      "        [-0.0588]])\n",
      "batch_y tensor([[ 0.0823],\n",
      "        [-0.0454]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 437\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.1099],\n",
      "        [-0.0069]])\n",
      "batch_y tensor([[-0.0403],\n",
      "        [ 0.1682]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 438\n",
      "================\n",
      "\n",
      "batch_x tensor([[-10.0248],\n",
      "        [ -0.0920]])\n",
      "batch_y tensor([[-0.0304],\n",
      "        [ 0.0797]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 439\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0056],\n",
      "        [-0.2919]])\n",
      "batch_y tensor([[-0.0999],\n",
      "        [ 0.0876]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 440\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4585],\n",
      "        [ 0.0381]])\n",
      "batch_y tensor([[0.0076],\n",
      "        [0.0301]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 441\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0996],\n",
      "        [0.0601]])\n",
      "batch_y tensor([[-0.2761],\n",
      "        [-0.0137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 442\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.7842],\n",
      "        [-0.0641]])\n",
      "batch_y tensor([[ 0.1413],\n",
      "        [-0.1445]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 443\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1794],\n",
      "        [ 0.0006]])\n",
      "batch_y tensor([[0.0365],\n",
      "        [0.0137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 444\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0924],\n",
      "        [-0.2433]])\n",
      "batch_y tensor([[0.8969],\n",
      "        [0.0363]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 445\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2715],\n",
      "        [0.1366]])\n",
      "batch_y tensor([[0.0240],\n",
      "        [0.2516]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 446\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0044],\n",
      "        [ 0.1793]])\n",
      "batch_y tensor([[ 0.0435],\n",
      "        [-1.6202]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 447\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0415],\n",
      "        [0.1843]])\n",
      "batch_y tensor([[-0.1654],\n",
      "        [-0.2624]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 448\n",
      "================\n",
      "\n",
      "batch_x tensor([[2.0899],\n",
      "        [0.0055]])\n",
      "batch_y tensor([[ 0.0265],\n",
      "        [-0.0736]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 449\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6032],\n",
      "        [0.2991]])\n",
      "batch_y tensor([[-0.0759],\n",
      "        [-0.0526]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 450\n",
      "================\n",
      "\n",
      "batch_x tensor([[-3.6585],\n",
      "        [-0.0443]])\n",
      "batch_y tensor([[ 0.0729],\n",
      "        [-0.0763]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 451\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1337],\n",
      "        [-0.0588]])\n",
      "batch_y tensor([[-0.0082],\n",
      "        [ 0.0633]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 452\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0715],\n",
      "        [-0.0274]])\n",
      "batch_y tensor([[-0.0650],\n",
      "        [ 0.1619]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 453\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2689],\n",
      "        [0.0322]])\n",
      "batch_y tensor([[ 0.0934],\n",
      "        [-0.9194]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 454\n",
      "================\n",
      "\n",
      "batch_x tensor([[2.3349],\n",
      "        [0.0385]])\n",
      "batch_y tensor([[-0.1924],\n",
      "        [-0.0455]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 455\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0332],\n",
      "        [ 1.9400]])\n",
      "batch_y tensor([[0.1379],\n",
      "        [0.0604]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 456\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0717],\n",
      "        [-0.1960]])\n",
      "batch_y tensor([[-0.1507],\n",
      "        [ 0.0083]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 457\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0559],\n",
      "        [-0.1260]])\n",
      "batch_y tensor([[-0.2908],\n",
      "        [ 0.0780]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 458\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1463],\n",
      "        [0.2878]])\n",
      "batch_y tensor([[ 0.0773],\n",
      "        [-0.1774]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 459\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0038],\n",
      "        [-0.1037]])\n",
      "batch_y tensor([[ 0.0021],\n",
      "        [-0.5053]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 460\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1100],\n",
      "        [-0.0630]])\n",
      "batch_y tensor([[-0.0147],\n",
      "        [ 0.0615]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 461\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3475],\n",
      "        [ 0.0056]])\n",
      "batch_y tensor([[0.1288],\n",
      "        [0.3391]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 462\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1000],\n",
      "        [-0.0057]])\n",
      "batch_y tensor([[-0.3291],\n",
      "        [ 0.0088]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 463\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0427],\n",
      "        [-0.5204]])\n",
      "batch_y tensor([[-0.4218],\n",
      "        [ 0.1277]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 464\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0357],\n",
      "        [-0.0497]])\n",
      "batch_y tensor([[ 0.3158],\n",
      "        [-0.1068]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 465\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0557],\n",
      "        [0.0325]])\n",
      "batch_y tensor([[ 0.1199],\n",
      "        [-0.0564]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 466\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1883],\n",
      "        [-0.1623]])\n",
      "batch_y tensor([[0.0886],\n",
      "        [0.0966]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 467\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0335],\n",
      "        [0.0628]])\n",
      "batch_y tensor([[0.0316],\n",
      "        [0.0894]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 468\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.8598],\n",
      "        [-0.0178]])\n",
      "batch_y tensor([[0.1609],\n",
      "        [0.2084]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 469\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3794],\n",
      "        [ 0.0446]])\n",
      "batch_y tensor([[-0.0759],\n",
      "        [ 0.0694]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 470\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1440],\n",
      "        [-0.2800]])\n",
      "batch_y tensor([[0.0262],\n",
      "        [0.1381]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 471\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3218],\n",
      "        [0.0183]])\n",
      "batch_y tensor([[ 0.0328],\n",
      "        [-0.0720]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 472\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2273],\n",
      "        [0.0958]])\n",
      "batch_y tensor([[ 0.0265],\n",
      "        [-0.2615]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 473\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4196],\n",
      "        [-0.2214]])\n",
      "batch_y tensor([[-0.0131],\n",
      "        [ 0.0134]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 474\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0236],\n",
      "        [-0.1767]])\n",
      "batch_y tensor([[ 0.1371],\n",
      "        [-0.5116]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 475\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2996],\n",
      "        [-0.1731]])\n",
      "batch_y tensor([[-0.0872],\n",
      "        [ 0.0949]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 476\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0182],\n",
      "        [0.0258]])\n",
      "batch_y tensor([[-0.0576],\n",
      "        [ 0.0522]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 477\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0957],\n",
      "        [-0.0906]])\n",
      "batch_y tensor([[-0.1661],\n",
      "        [-0.1511]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 478\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0333],\n",
      "        [0.0746]])\n",
      "batch_y tensor([[-0.0064],\n",
      "        [-0.0283]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 479\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0653],\n",
      "        [0.1096]])\n",
      "batch_y tensor([[ 0.0373],\n",
      "        [-0.0223]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 480\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1038],\n",
      "        [-0.9553]])\n",
      "batch_y tensor([[22.4297],\n",
      "        [ 0.0549]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 481\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0869],\n",
      "        [ 0.0232]])\n",
      "batch_y tensor([[-0.0435],\n",
      "        [-0.0905]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 482\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1040],\n",
      "        [0.2596]])\n",
      "batch_y tensor([[-0.0756],\n",
      "        [ 0.0172]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 483\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0085],\n",
      "        [-0.1029]])\n",
      "batch_y tensor([[0.1964],\n",
      "        [0.3501]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 484\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0145],\n",
      "        [ 0.0482]])\n",
      "batch_y tensor([[-0.5437],\n",
      "        [-0.0284]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 485\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1029],\n",
      "        [2.3356]])\n",
      "batch_y tensor([[ 3.1689e-03],\n",
      "        [-4.1971e+00]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 486\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2734],\n",
      "        [-0.0975]])\n",
      "batch_y tensor([[5.0138],\n",
      "        [0.3060]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 487\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1150],\n",
      "        [-0.0271]])\n",
      "batch_y tensor([[ 0.1704],\n",
      "        [-0.1894]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 488\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0738],\n",
      "        [-0.0532]])\n",
      "batch_y tensor([[0.3641],\n",
      "        [0.0528]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 489\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1857],\n",
      "        [ 0.0072]])\n",
      "batch_y tensor([[ 3.8361],\n",
      "        [-0.0122]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 490\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1348],\n",
      "        [0.1001]])\n",
      "batch_y tensor([[0.0442],\n",
      "        [0.0330]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 491\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0027],\n",
      "        [-0.3256]])\n",
      "batch_y tensor([[-0.0161],\n",
      "        [ 0.0298]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 492\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0891],\n",
      "        [-0.1203]])\n",
      "batch_y tensor([[-0.0188],\n",
      "        [ 0.0147]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 493\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0427],\n",
      "        [-0.0466]])\n",
      "batch_y tensor([[ 0.1035],\n",
      "        [-0.0467]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 494\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0099],\n",
      "        [-0.0280]])\n",
      "batch_y tensor([[-0.0094],\n",
      "        [ 0.1970]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 495\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1442],\n",
      "        [ 0.0123]])\n",
      "batch_y tensor([[-0.1297],\n",
      "        [ 0.0520]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 496\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1494],\n",
      "        [-0.2707]])\n",
      "batch_y tensor([[0.0810],\n",
      "        [0.1510]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 497\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6851],\n",
      "        [-0.1795]])\n",
      "batch_y tensor([[ 0.0188],\n",
      "        [-0.0851]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 498\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0502],\n",
      "        [-0.0578]])\n",
      "batch_y tensor([[-0.2100],\n",
      "        [-0.0220]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 499\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0316],\n",
      "        [-0.1546]])\n",
      "batch_y tensor([[-0.2082],\n",
      "        [-0.0307]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 0\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1463],\n",
      "        [0.0261]])\n",
      "batch_y tensor([[0.0773],\n",
      "        [1.2595]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 1\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2333],\n",
      "        [0.0243]])\n",
      "batch_y tensor([[ 0.0159],\n",
      "        [-0.0222]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 2\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4256],\n",
      "        [ 0.0546]])\n",
      "batch_y tensor([[ 0.0086],\n",
      "        [-5.2447]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 3\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1782],\n",
      "        [-0.1458]])\n",
      "batch_y tensor([[0.0909],\n",
      "        [0.0015]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 4\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.2773],\n",
      "        [0.0076]])\n",
      "batch_y tensor([[ 0.0932],\n",
      "        [-0.0595]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 5\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0277],\n",
      "        [-0.1170]])\n",
      "batch_y tensor([[0.0043],\n",
      "        [0.0271]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 6\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0857],\n",
      "        [ 0.0906]])\n",
      "batch_y tensor([[ 0.1795],\n",
      "        [-0.4131]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 7\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1177],\n",
      "        [-0.0108]])\n",
      "batch_y tensor([[ 0.0787],\n",
      "        [-0.0006]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 8\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3510],\n",
      "        [0.0791]])\n",
      "batch_y tensor([[-0.1403],\n",
      "        [ 0.0168]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 9\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0407],\n",
      "        [ 0.0322]])\n",
      "batch_y tensor([[ 0.0641],\n",
      "        [-0.9194]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 10\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 2.3349e+00],\n",
      "        [-8.2897e-04]])\n",
      "batch_y tensor([[-0.1924],\n",
      "        [ 0.3119]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 11\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0864],\n",
      "        [0.0982]])\n",
      "batch_y tensor([[0.0622],\n",
      "        [0.1598]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 12\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0175],\n",
      "        [-0.4542]])\n",
      "batch_y tensor([[-0.0710],\n",
      "        [ 0.0059]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 13\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0365],\n",
      "        [ 0.0090]])\n",
      "batch_y tensor([[-0.0159],\n",
      "        [-0.0368]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 14\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1246],\n",
      "        [0.1399]])\n",
      "batch_y tensor([[-0.8318],\n",
      "        [ 0.0084]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 15\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1786],\n",
      "        [-0.0013]])\n",
      "batch_y tensor([[ 0.6692],\n",
      "        [-0.0254]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 16\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0057],\n",
      "        [-0.0559]])\n",
      "batch_y tensor([[-0.0463],\n",
      "        [-0.2908]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 17\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0663],\n",
      "        [ 0.0382]])\n",
      "batch_y tensor([[ 0.2775],\n",
      "        [-0.0860]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 18\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0818],\n",
      "        [-0.0443]])\n",
      "batch_y tensor([[0.0209],\n",
      "        [0.0402]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 19\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0751],\n",
      "        [-0.0846]])\n",
      "batch_y tensor([[-0.3107],\n",
      "        [ 0.3187]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 20\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0487],\n",
      "        [0.0231]])\n",
      "batch_y tensor([[-0.0186],\n",
      "        [-0.0988]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 21\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0364],\n",
      "        [-0.0496]])\n",
      "batch_y tensor([[0.0727],\n",
      "        [0.3400]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 22\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1835],\n",
      "        [-0.1861]])\n",
      "batch_y tensor([[-2.9778],\n",
      "        [-0.0635]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 23\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0332],\n",
      "        [ 0.0101]])\n",
      "batch_y tensor([[ 0.1379],\n",
      "        [-0.3852]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 24\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0515],\n",
      "        [ 0.2331]])\n",
      "batch_y tensor([[ 0.0173],\n",
      "        [-0.0546]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 25\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0231],\n",
      "        [-0.5093]])\n",
      "batch_y tensor([[0.0549],\n",
      "        [0.0945]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 26\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1215],\n",
      "        [0.2767]])\n",
      "batch_y tensor([[0.0546],\n",
      "        [0.0446]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 27\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0276],\n",
      "        [-0.2332]])\n",
      "batch_y tensor([[-0.0953],\n",
      "        [ 0.1918]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 28\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0252],\n",
      "        [-0.0856]])\n",
      "batch_y tensor([[ 0.0934],\n",
      "        [-0.9376]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 29\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0061],\n",
      "        [ 0.0415]])\n",
      "batch_y tensor([[-0.0340],\n",
      "        [-0.1654]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 30\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1216],\n",
      "        [ 0.2129]])\n",
      "batch_y tensor([[-0.1112],\n",
      "        [ 0.0051]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 31\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4072],\n",
      "        [-0.0740]])\n",
      "batch_y tensor([[-0.1418],\n",
      "        [ 0.0974]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 32\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1203],\n",
      "        [-0.0543]])\n",
      "batch_y tensor([[ 0.0147],\n",
      "        [-0.1267]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 33\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1717],\n",
      "        [ 0.2268]])\n",
      "batch_y tensor([[-0.0920],\n",
      "        [ 0.1663]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 34\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0232],\n",
      "        [0.0259]])\n",
      "batch_y tensor([[-0.0905],\n",
      "        [-0.0007]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 35\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0049],\n",
      "        [-0.1590]])\n",
      "batch_y tensor([[-0.3343],\n",
      "        [-0.0136]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 36\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0385],\n",
      "        [-0.0438]])\n",
      "batch_y tensor([[-0.0455],\n",
      "        [-0.0421]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 37\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2054],\n",
      "        [0.0381]])\n",
      "batch_y tensor([[ 0.1343],\n",
      "        [-0.0843]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 38\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0924],\n",
      "        [-0.0106]])\n",
      "batch_y tensor([[ 0.8969],\n",
      "        [-0.0464]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 39\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3400],\n",
      "        [0.6143]])\n",
      "batch_y tensor([[-0.3813],\n",
      "        [ 0.0234]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 40\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0342],\n",
      "        [0.1381]])\n",
      "batch_y tensor([[ 0.0245],\n",
      "        [-4.4293]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 41\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1029],\n",
      "        [ 0.0586]])\n",
      "batch_y tensor([[0.3501],\n",
      "        [0.2782]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 42\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3393],\n",
      "        [-0.0373]])\n",
      "batch_y tensor([[-0.0249],\n",
      "        [ 0.1220]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 43\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3282],\n",
      "        [ 0.0582]])\n",
      "batch_y tensor([[-1.0422],\n",
      "        [ 0.0205]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 44\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2982],\n",
      "        [-0.4643]])\n",
      "batch_y tensor([[-0.8488],\n",
      "        [-0.0328]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 45\n",
      "================\n",
      "\n",
      "batch_x tensor([[-2.3456],\n",
      "        [ 0.0136]])\n",
      "batch_y tensor([[-0.2963],\n",
      "        [-0.0267]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 46\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0629],\n",
      "        [ 0.0024]])\n",
      "batch_y tensor([[-0.3234],\n",
      "        [-0.1998]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 47\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0259],\n",
      "        [-0.2675]])\n",
      "batch_y tensor([[0.0683],\n",
      "        [0.0484]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 48\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2386],\n",
      "        [-0.0630]])\n",
      "batch_y tensor([[-0.1309],\n",
      "        [ 0.0615]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 49\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3962],\n",
      "        [-0.0064]])\n",
      "batch_y tensor([[-0.0633],\n",
      "        [-0.0043]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 50\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3214],\n",
      "        [-0.0234]])\n",
      "batch_y tensor([[-0.1618],\n",
      "        [ 0.3033]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 51\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0112],\n",
      "        [-8.2940]])\n",
      "batch_y tensor([[-0.1118],\n",
      "        [-0.1497]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 52\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0809],\n",
      "        [0.1812]])\n",
      "batch_y tensor([[ 0.0146],\n",
      "        [-0.1107]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 53\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0272],\n",
      "        [ 0.0035]])\n",
      "batch_y tensor([[-0.0358],\n",
      "        [-0.8611]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 54\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1348],\n",
      "        [ 2.0754]])\n",
      "batch_y tensor([[-0.0324],\n",
      "        [ 0.1136]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 55\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2858],\n",
      "        [0.0676]])\n",
      "batch_y tensor([[-0.0187],\n",
      "        [ 0.1392]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 56\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0203],\n",
      "        [0.4920]])\n",
      "batch_y tensor([[ 0.1145],\n",
      "        [-0.3303]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 57\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0735],\n",
      "        [0.1210]])\n",
      "batch_y tensor([[-0.1613],\n",
      "        [ 0.2108]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 58\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.2361],\n",
      "        [0.4107]])\n",
      "batch_y tensor([[-0.7221],\n",
      "        [-0.0836]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 59\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1113],\n",
      "        [0.0878]])\n",
      "batch_y tensor([[ 0.1788],\n",
      "        [-0.1688]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 60\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5483],\n",
      "        [-0.0516]])\n",
      "batch_y tensor([[-0.2069],\n",
      "        [ 0.1064]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 61\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0304],\n",
      "        [-0.0508]])\n",
      "batch_y tensor([[ 0.0206],\n",
      "        [-0.0669]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 62\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4522],\n",
      "        [-0.0017]])\n",
      "batch_y tensor([[-0.4247],\n",
      "        [-0.0430]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 63\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0512],\n",
      "        [0.0129]])\n",
      "batch_y tensor([[-0.1365],\n",
      "        [-0.1011]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 64\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3344],\n",
      "        [-0.0095]])\n",
      "batch_y tensor([[0.0722],\n",
      "        [0.6538]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 65\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0790],\n",
      "        [ 0.0325]])\n",
      "batch_y tensor([[ 1.5125],\n",
      "        [-0.0564]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 66\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0029],\n",
      "        [-0.0329]])\n",
      "batch_y tensor([[ 0.5204],\n",
      "        [-1.7879]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 67\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0376],\n",
      "        [-0.1455]])\n",
      "batch_y tensor([[-0.1359],\n",
      "        [ 0.1155]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 68\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5552],\n",
      "        [ 0.3923]])\n",
      "batch_y tensor([[-0.0185],\n",
      "        [ 2.6874]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 69\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2107],\n",
      "        [ 0.0302]])\n",
      "batch_y tensor([[ 0.3215],\n",
      "        [-0.0836]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 70\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5470],\n",
      "        [-0.1767]])\n",
      "batch_y tensor([[-0.0774],\n",
      "        [-0.5116]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 71\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0497],\n",
      "        [-0.0897]])\n",
      "batch_y tensor([[-0.1068],\n",
      "        [-0.0188]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 72\n",
      "================\n",
      "\n",
      "batch_x tensor([[-4.7651],\n",
      "        [ 0.1432]])\n",
      "batch_y tensor([[0.0306],\n",
      "        [0.0661]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 73\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.9312],\n",
      "        [-0.0920]])\n",
      "batch_y tensor([[0.0874],\n",
      "        [0.0797]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 74\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0754],\n",
      "        [-0.0049]])\n",
      "batch_y tensor([[0.1254],\n",
      "        [0.0845]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 75\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0239],\n",
      "        [0.0630]])\n",
      "batch_y tensor([[6.7613],\n",
      "        [0.0304]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 76\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1290],\n",
      "        [-0.0430]])\n",
      "batch_y tensor([[ 0.0007],\n",
      "        [-0.5469]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 77\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0730],\n",
      "        [-0.1460]])\n",
      "batch_y tensor([[ 0.0605],\n",
      "        [-0.0115]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 78\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2596],\n",
      "        [0.0068]])\n",
      "batch_y tensor([[0.0172],\n",
      "        [0.0832]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 79\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3256],\n",
      "        [-0.0641]])\n",
      "batch_y tensor([[ 0.0298],\n",
      "        [-0.1445]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 80\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1530],\n",
      "        [-0.0526]])\n",
      "batch_y tensor([[-0.1073],\n",
      "        [ 0.1420]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 81\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0186],\n",
      "        [-0.1670]])\n",
      "batch_y tensor([[-0.1553],\n",
      "        [ 0.1113]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 82\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0551],\n",
      "        [-0.2797]])\n",
      "batch_y tensor([[ 0.0103],\n",
      "        [-0.2957]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 83\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2339],\n",
      "        [-0.0578]])\n",
      "batch_y tensor([[ 0.0952],\n",
      "        [-0.0220]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 84\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1213],\n",
      "        [-0.2707]])\n",
      "batch_y tensor([[-0.0226],\n",
      "        [ 0.1510]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 85\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0654],\n",
      "        [ 0.3178]])\n",
      "batch_y tensor([[-0.0173],\n",
      "        [-0.0264]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 86\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0504],\n",
      "        [-0.0072]])\n",
      "batch_y tensor([[-0.1404],\n",
      "        [ 0.2603]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 87\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 7.0559e-05],\n",
      "        [-2.2703e-01]])\n",
      "batch_y tensor([[-0.0220],\n",
      "        [-0.1743]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 88\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0771],\n",
      "        [-0.0498]])\n",
      "batch_y tensor([[-0.1744],\n",
      "        [-0.2539]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 89\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1358],\n",
      "        [ 0.0869]])\n",
      "batch_y tensor([[-0.1947],\n",
      "        [ 0.1932]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 90\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0271],\n",
      "        [-0.0006]])\n",
      "batch_y tensor([[-0.1894],\n",
      "        [-0.1052]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 91\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.5105],\n",
      "        [0.0170]])\n",
      "batch_y tensor([[0.0613],\n",
      "        [0.0904]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 92\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2682],\n",
      "        [0.0408]])\n",
      "batch_y tensor([[ 0.0053],\n",
      "        [-0.0292]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 93\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2232],\n",
      "        [-0.1025]])\n",
      "batch_y tensor([[0.0623],\n",
      "        [0.0611]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 94\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6400],\n",
      "        [0.0253]])\n",
      "batch_y tensor([[-1.2248],\n",
      "        [-0.1333]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 95\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1721],\n",
      "        [-0.1585]])\n",
      "batch_y tensor([[-0.0161],\n",
      "        [ 0.3778]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 96\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1057],\n",
      "        [ 0.0907]])\n",
      "batch_y tensor([[0.7384],\n",
      "        [0.0043]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 97\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0055],\n",
      "        [0.0372]])\n",
      "batch_y tensor([[-0.0736],\n",
      "        [ 0.0465]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 98\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0343],\n",
      "        [-0.0359]])\n",
      "batch_y tensor([[ 0.0388],\n",
      "        [-0.0695]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 99\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0957],\n",
      "        [-0.1820]])\n",
      "batch_y tensor([[-0.1661],\n",
      "        [-0.3703]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 100\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0151],\n",
      "        [1.5100]])\n",
      "batch_y tensor([[ 0.2466],\n",
      "        [-0.0044]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 101\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0481],\n",
      "        [ 0.8126]])\n",
      "batch_y tensor([[-0.0184],\n",
      "        [ 0.1602]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 102\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0425],\n",
      "        [-0.1077]])\n",
      "batch_y tensor([[-3.8582],\n",
      "        [-0.0273]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 103\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2214],\n",
      "        [-4.5253]])\n",
      "batch_y tensor([[ 0.0134],\n",
      "        [-0.2021]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 104\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1129],\n",
      "        [-0.1557]])\n",
      "batch_y tensor([[ 0.1008],\n",
      "        [-0.3630]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 105\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.9873],\n",
      "        [-0.4280]])\n",
      "batch_y tensor([[0.3446],\n",
      "        [0.0663]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 106\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2688],\n",
      "        [ 0.2270]])\n",
      "batch_y tensor([[ 0.4213],\n",
      "        [-1.3681]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 107\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0502],\n",
      "        [-0.0394]])\n",
      "batch_y tensor([[-0.2100],\n",
      "        [ 0.0412]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 108\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1037],\n",
      "        [-0.1340]])\n",
      "batch_y tensor([[-0.5053],\n",
      "        [ 0.1586]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 109\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0628],\n",
      "        [0.0046]])\n",
      "batch_y tensor([[0.0894],\n",
      "        [0.0511]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 110\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1515],\n",
      "        [0.2160]])\n",
      "batch_y tensor([[-0.1442],\n",
      "        [ 0.0806]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 111\n",
      "================\n",
      "\n",
      "batch_x tensor([[-2.0326],\n",
      "        [ 0.3763]])\n",
      "batch_y tensor([[0.0056],\n",
      "        [0.0017]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 112\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.4895],\n",
      "        [0.1041]])\n",
      "batch_y tensor([[-0.0754],\n",
      "        [ 0.0924]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 113\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0768],\n",
      "        [ 0.0056]])\n",
      "batch_y tensor([[-0.0236],\n",
      "        [ 0.3391]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 114\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2878],\n",
      "        [9.1587]])\n",
      "batch_y tensor([[-0.1774],\n",
      "        [ 0.0069]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 115\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0048],\n",
      "        [0.0183]])\n",
      "batch_y tensor([[-0.6878],\n",
      "        [-0.0720]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 116\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1939],\n",
      "        [0.1275]])\n",
      "batch_y tensor([[0.0532],\n",
      "        [0.2255]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 117\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0722],\n",
      "        [-0.3087]])\n",
      "batch_y tensor([[-0.1266],\n",
      "        [ 0.0241]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 118\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0643],\n",
      "        [0.1539]])\n",
      "batch_y tensor([[0.1768],\n",
      "        [0.0441]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 119\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0014],\n",
      "        [-0.0326]])\n",
      "batch_y tensor([[-0.0609],\n",
      "        [ 0.0807]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 120\n",
      "================\n",
      "\n",
      "batch_x tensor([[-3.9765],\n",
      "        [-0.0216]])\n",
      "batch_y tensor([[ 0.1815],\n",
      "        [-0.1879]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 121\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6326],\n",
      "        [-0.2016]])\n",
      "batch_y tensor([[ 0.0656],\n",
      "        [-0.1150]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 122\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0674],\n",
      "        [ 0.0052]])\n",
      "batch_y tensor([[-0.2691],\n",
      "        [-0.0579]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 123\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1843],\n",
      "        [-0.0044]])\n",
      "batch_y tensor([[-0.2624],\n",
      "        [-0.3114]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 124\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0384],\n",
      "        [-0.0441]])\n",
      "batch_y tensor([[-0.0456],\n",
      "        [ 0.3653]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 125\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0980],\n",
      "        [ 0.0443]])\n",
      "batch_y tensor([[ 0.7191],\n",
      "        [-0.2654]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 126\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2150],\n",
      "        [-0.0399]])\n",
      "batch_y tensor([[-0.0212],\n",
      "        [-0.1023]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 127\n",
      "================\n",
      "\n",
      "batch_x tensor([[-9.3257],\n",
      "        [ 0.0738]])\n",
      "batch_y tensor([[0.1101],\n",
      "        [0.3641]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 128\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0580],\n",
      "        [-0.0274]])\n",
      "batch_y tensor([[0.0024],\n",
      "        [0.1619]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 129\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0845],\n",
      "        [0.0650]])\n",
      "batch_y tensor([[-0.0894],\n",
      "        [-0.0476]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 130\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6183],\n",
      "        [0.0371]])\n",
      "batch_y tensor([[-0.1388],\n",
      "        [ 0.3098]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 131\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0719],\n",
      "        [ 0.0702]])\n",
      "batch_y tensor([[-0.1990],\n",
      "        [ 0.0252]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 132\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0405],\n",
      "        [-0.1935]])\n",
      "batch_y tensor([[-0.0079],\n",
      "        [ 0.1751]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 133\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1009],\n",
      "        [-0.0285]])\n",
      "batch_y tensor([[-0.0418],\n",
      "        [ 0.1520]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 134\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3121],\n",
      "        [-0.0879]])\n",
      "batch_y tensor([[-0.1386],\n",
      "        [ 0.2403]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 135\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1604],\n",
      "        [-0.1232]])\n",
      "batch_y tensor([[ 0.0136],\n",
      "        [-0.0628]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 136\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0099],\n",
      "        [0.1356]])\n",
      "batch_y tensor([[-0.0094],\n",
      "        [-0.1491]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 137\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1672],\n",
      "        [-0.0438]])\n",
      "batch_y tensor([[-0.1421],\n",
      "        [-0.0088]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 138\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0571],\n",
      "        [-6.9505]])\n",
      "batch_y tensor([[-0.4094],\n",
      "        [-0.0415]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 139\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0936],\n",
      "        [0.1202]])\n",
      "batch_y tensor([[ 0.1237],\n",
      "        [-0.0200]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 140\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0491],\n",
      "        [-0.1150]])\n",
      "batch_y tensor([[0.0141],\n",
      "        [0.1704]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 141\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0896],\n",
      "        [0.0357]])\n",
      "batch_y tensor([[0.2049],\n",
      "        [0.1462]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 142\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.1810],\n",
      "        [ 0.0207]])\n",
      "batch_y tensor([[-1.7052],\n",
      "        [ 0.4405]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 143\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1414],\n",
      "        [-0.0230]])\n",
      "batch_y tensor([[-0.0798],\n",
      "        [ 0.0399]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 144\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2905],\n",
      "        [0.0860]])\n",
      "batch_y tensor([[ 0.0310],\n",
      "        [-0.2786]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 145\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0184],\n",
      "        [-0.4859]])\n",
      "batch_y tensor([[0.0398],\n",
      "        [0.1397]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 146\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3606],\n",
      "        [0.0853]])\n",
      "batch_y tensor([[0.5226],\n",
      "        [0.0802]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 147\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0484],\n",
      "        [-2.8702]])\n",
      "batch_y tensor([[-0.1931],\n",
      "        [-0.0834]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 148\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0438],\n",
      "        [ 0.2072]])\n",
      "batch_y tensor([[-0.8253],\n",
      "        [ 0.1975]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 149\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1269],\n",
      "        [ 0.0482]])\n",
      "batch_y tensor([[ 0.1622],\n",
      "        [-0.0284]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 150\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1370],\n",
      "        [-0.0189]])\n",
      "batch_y tensor([[ 0.1234],\n",
      "        [-1.3523]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 151\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1819],\n",
      "        [ 0.0600]])\n",
      "batch_y tensor([[ 0.6645],\n",
      "        [-0.0893]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 152\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1442],\n",
      "        [ 0.0223]])\n",
      "batch_y tensor([[-0.1297],\n",
      "        [ 0.2031]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 153\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2039],\n",
      "        [0.1859]])\n",
      "batch_y tensor([[ 0.0208],\n",
      "        [-0.0478]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 154\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4430],\n",
      "        [-0.6610]])\n",
      "batch_y tensor([[ 0.1011],\n",
      "        [-1.9760]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 155\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0025],\n",
      "        [1.1099]])\n",
      "batch_y tensor([[ 0.0217],\n",
      "        [-0.0403]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 156\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0869],\n",
      "        [ 0.3260]])\n",
      "batch_y tensor([[-0.0435],\n",
      "        [-0.3484]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 157\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0388],\n",
      "        [0.2715]])\n",
      "batch_y tensor([[-0.0794],\n",
      "        [ 0.0240]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 158\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2991],\n",
      "        [-0.3142]])\n",
      "batch_y tensor([[-0.0526],\n",
      "        [ 0.0192]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 159\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0278],\n",
      "        [-0.1835]])\n",
      "batch_y tensor([[ 0.1093],\n",
      "        [-0.0089]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 160\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0096],\n",
      "        [0.0733]])\n",
      "batch_y tensor([[4.2309],\n",
      "        [0.0132]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 161\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0178],\n",
      "        [ 0.1096]])\n",
      "batch_y tensor([[ 0.2084],\n",
      "        [-0.0223]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 162\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1981],\n",
      "        [2.3356]])\n",
      "batch_y tensor([[-0.0494],\n",
      "        [-4.1971]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 163\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0215],\n",
      "        [1.1838]])\n",
      "batch_y tensor([[0.0391],\n",
      "        [0.1626]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 164\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0466],\n",
      "        [2.5413]])\n",
      "batch_y tensor([[ 0.0162],\n",
      "        [-0.0471]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 165\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.1094],\n",
      "        [-0.1048]])\n",
      "batch_y tensor([[-0.0576],\n",
      "        [-0.0367]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 166\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1823],\n",
      "        [-0.0550]])\n",
      "batch_y tensor([[0.0468],\n",
      "        [0.1565]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 167\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0116],\n",
      "        [-0.1587]])\n",
      "batch_y tensor([[-0.4727],\n",
      "        [ 0.2074]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 168\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0251],\n",
      "        [-0.0072]])\n",
      "batch_y tensor([[-0.6435],\n",
      "        [ 0.0013]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 169\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0656],\n",
      "        [0.0447]])\n",
      "batch_y tensor([[-0.1490],\n",
      "        [ 0.1062]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 170\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0061],\n",
      "        [-0.0339]])\n",
      "batch_y tensor([[ 0.6132],\n",
      "        [-0.0724]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 171\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0344],\n",
      "        [-0.4255]])\n",
      "batch_y tensor([[0.1966],\n",
      "        [1.8376]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 172\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5540],\n",
      "        [-0.0499]])\n",
      "batch_y tensor([[0.0192],\n",
      "        [0.1795]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 173\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2733],\n",
      "        [-0.0946]])\n",
      "batch_y tensor([[ 0.0231],\n",
      "        [-0.0851]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 174\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6700],\n",
      "        [-0.0730]])\n",
      "batch_y tensor([[0.1428],\n",
      "        [1.4516]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 175\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1370],\n",
      "        [ 1.0324]])\n",
      "batch_y tensor([[12.8843],\n",
      "        [ 0.0864]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 176\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1260],\n",
      "        [-0.0997]])\n",
      "batch_y tensor([[ 0.0780],\n",
      "        [-0.0248]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 177\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0381],\n",
      "        [-2.9294]])\n",
      "batch_y tensor([[0.0301],\n",
      "        [0.0002]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 178\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1146],\n",
      "        [-0.0119]])\n",
      "batch_y tensor([[ 0.0245],\n",
      "        [-1.3602]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 179\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.4091],\n",
      "        [0.4945]])\n",
      "batch_y tensor([[ 0.0339],\n",
      "        [-0.2043]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 180\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2709],\n",
      "        [-0.2154]])\n",
      "batch_y tensor([[-1.0447],\n",
      "        [-0.0170]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 181\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0436],\n",
      "        [0.3112]])\n",
      "batch_y tensor([[-0.0032],\n",
      "        [-1.6625]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 182\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0069],\n",
      "        [ 0.0487]])\n",
      "batch_y tensor([[0.1682],\n",
      "        [0.0392]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 183\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0036],\n",
      "        [-0.0354]])\n",
      "batch_y tensor([[ 9.8770],\n",
      "        [-0.0202]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 184\n",
      "================\n",
      "\n",
      "batch_x tensor([[-34.8098],\n",
      "        [  0.0891]])\n",
      "batch_y tensor([[0.0648],\n",
      "        [0.0546]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 185\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0481],\n",
      "        [-0.0149]])\n",
      "batch_y tensor([[0.1894],\n",
      "        [0.3111]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 186\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0755],\n",
      "        [ 0.0835]])\n",
      "batch_y tensor([[-0.2830],\n",
      "        [ 0.0360]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 187\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0584],\n",
      "        [ 0.0625]])\n",
      "batch_y tensor([[0.0412],\n",
      "        [0.0099]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 188\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0565],\n",
      "        [ 0.0216]])\n",
      "batch_y tensor([[-0.1500],\n",
      "        [-2.1257]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 189\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3054],\n",
      "        [0.1057]])\n",
      "batch_y tensor([[-0.5500],\n",
      "        [-0.7170]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 190\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.7610],\n",
      "        [-0.9553]])\n",
      "batch_y tensor([[0.1777],\n",
      "        [0.0549]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 191\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0335],\n",
      "        [-0.1119]])\n",
      "batch_y tensor([[0.0316],\n",
      "        [0.0735]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 192\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0188],\n",
      "        [-0.0974]])\n",
      "batch_y tensor([[0.2029],\n",
      "        [0.2742]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 193\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0381],\n",
      "        [-0.0604]])\n",
      "batch_y tensor([[-0.0628],\n",
      "        [ 0.0979]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 194\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0330],\n",
      "        [-0.0422]])\n",
      "batch_y tensor([[-0.1167],\n",
      "        [-0.2286]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 195\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0768],\n",
      "        [-0.0263]])\n",
      "batch_y tensor([[0.5039],\n",
      "        [0.0234]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 196\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0495],\n",
      "        [0.0050]])\n",
      "batch_y tensor([[ 0.6738],\n",
      "        [-0.2178]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 197\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0491],\n",
      "        [ 0.1147]])\n",
      "batch_y tensor([[-0.0259],\n",
      "        [-0.0043]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 198\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5440],\n",
      "        [-0.0232]])\n",
      "batch_y tensor([[0.5176],\n",
      "        [0.1965]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 199\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0749],\n",
      "        [-0.2424]])\n",
      "batch_y tensor([[ 0.0186],\n",
      "        [-0.2221]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 200\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2433],\n",
      "        [-0.1318]])\n",
      "batch_y tensor([[0.0363],\n",
      "        [0.1320]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 201\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1529],\n",
      "        [0.0795]])\n",
      "batch_y tensor([[0.5244],\n",
      "        [0.0482]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 202\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1403],\n",
      "        [-0.0588]])\n",
      "batch_y tensor([[-0.1393],\n",
      "        [-0.0454]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 203\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3461],\n",
      "        [-0.0567]])\n",
      "batch_y tensor([[0.0223],\n",
      "        [0.0175]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 204\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1301],\n",
      "        [-0.0137]])\n",
      "batch_y tensor([[-0.1916],\n",
      "        [ 0.0871]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 205\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1302],\n",
      "        [ 0.0258]])\n",
      "batch_y tensor([[0.2746],\n",
      "        [0.0522]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 206\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0285],\n",
      "        [0.0405]])\n",
      "batch_y tensor([[-0.1544],\n",
      "        [ 0.0020]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 207\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0960],\n",
      "        [-0.0546]])\n",
      "batch_y tensor([[-0.6540],\n",
      "        [ 0.0149]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 208\n",
      "================\n",
      "\n",
      "batch_x tensor([[-6.7449],\n",
      "        [ 0.1001]])\n",
      "batch_y tensor([[-0.0033],\n",
      "        [ 0.0330]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 209\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0186],\n",
      "        [0.6642]])\n",
      "batch_y tensor([[-0.1993],\n",
      "        [ 0.0938]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 210\n",
      "================\n",
      "\n",
      "batch_x tensor([[ -0.2255],\n",
      "        [-13.5472]])\n",
      "batch_y tensor([[ 0.0525],\n",
      "        [-0.2685]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 211\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0303],\n",
      "        [0.2039]])\n",
      "batch_y tensor([[ 0.1629],\n",
      "        [-0.1846]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 212\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1571],\n",
      "        [-0.2505]])\n",
      "batch_y tensor([[ 0.0096],\n",
      "        [-0.0410]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 213\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0191],\n",
      "        [0.1971]])\n",
      "batch_y tensor([[15.9262],\n",
      "        [ 0.0739]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 214\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0379],\n",
      "        [-0.0854]])\n",
      "batch_y tensor([[-0.0137],\n",
      "        [ 0.2240]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 215\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2996],\n",
      "        [ 0.1249]])\n",
      "batch_y tensor([[-0.0872],\n",
      "        [ 0.4028]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 216\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0218],\n",
      "        [-0.0038]])\n",
      "batch_y tensor([[0.0749],\n",
      "        [0.0021]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 217\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0131],\n",
      "        [-0.1599]])\n",
      "batch_y tensor([[ 0.0804],\n",
      "        [-0.0563]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 218\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0274],\n",
      "        [2.3350]])\n",
      "batch_y tensor([[-0.7972],\n",
      "        [ 0.0270]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 219\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1169],\n",
      "        [-0.7187]])\n",
      "batch_y tensor([[ 0.1104],\n",
      "        [-0.2239]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 220\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0123],\n",
      "        [0.1632]])\n",
      "batch_y tensor([[0.0520],\n",
      "        [0.0234]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 221\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0311],\n",
      "        [ 1.1196]])\n",
      "batch_y tensor([[-0.0025],\n",
      "        [-0.0656]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 222\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1460],\n",
      "        [0.2716]])\n",
      "batch_y tensor([[-0.0213],\n",
      "        [ 0.5787]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 223\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0357],\n",
      "        [ 0.0306]])\n",
      "batch_y tensor([[0.3158],\n",
      "        [0.0366]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 224\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0635],\n",
      "        [ 0.7449]])\n",
      "batch_y tensor([[ 0.0310],\n",
      "        [-0.3689]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 225\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0377],\n",
      "        [-0.0287]])\n",
      "batch_y tensor([[ 0.0307],\n",
      "        [-0.0554]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 226\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.8248],\n",
      "        [-0.0023]])\n",
      "batch_y tensor([[-0.0647],\n",
      "        [-0.0940]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 227\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0108],\n",
      "        [0.0637]])\n",
      "batch_y tensor([[-0.1457],\n",
      "        [ 0.4407]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 228\n",
      "================\n",
      "\n",
      "batch_x tensor([[-7.9219],\n",
      "        [-0.4726]])\n",
      "batch_y tensor([[ 0.1399],\n",
      "        [-0.0243]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 229\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1674],\n",
      "        [-0.0168]])\n",
      "batch_y tensor([[-5.2304],\n",
      "        [-1.1459]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 230\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0543],\n",
      "        [-0.4995]])\n",
      "batch_y tensor([[-0.3313],\n",
      "        [-0.0327]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 231\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4795],\n",
      "        [-0.0211]])\n",
      "batch_y tensor([[-0.0924],\n",
      "        [-0.0175]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 232\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.9400],\n",
      "        [0.0113]])\n",
      "batch_y tensor([[ 0.0604],\n",
      "        [-0.2971]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 233\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1337],\n",
      "        [-0.0150]])\n",
      "batch_y tensor([[-0.0082],\n",
      "        [ 0.1102]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 234\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0312],\n",
      "        [-0.0322]])\n",
      "batch_y tensor([[-0.2576],\n",
      "        [-0.0967]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 235\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2097],\n",
      "        [-0.1117]])\n",
      "batch_y tensor([[ 0.0714],\n",
      "        [-0.0511]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 236\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2789],\n",
      "        [0.0089]])\n",
      "batch_y tensor([[-0.0617],\n",
      "        [-0.2947]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 237\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0219],\n",
      "        [-0.0730]])\n",
      "batch_y tensor([[-0.0929],\n",
      "        [-0.0857]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 238\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1100],\n",
      "        [-0.3116]])\n",
      "batch_y tensor([[-0.0147],\n",
      "        [-0.0725]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 239\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0427],\n",
      "        [ 0.1863]])\n",
      "batch_y tensor([[-0.4218],\n",
      "        [-0.9076]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 240\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1000],\n",
      "        [-0.0372]])\n",
      "batch_y tensor([[-0.3291],\n",
      "        [-0.5305]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 241\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0175],\n",
      "        [ 0.0359]])\n",
      "batch_y tensor([[0.1103],\n",
      "        [0.1222]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 242\n",
      "================\n",
      "\n",
      "batch_x tensor([[-9.8651e-04],\n",
      "        [-1.1061e+01]])\n",
      "batch_y tensor([[ 0.0279],\n",
      "        [-5.9082]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 243\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0630],\n",
      "        [ 0.6959]])\n",
      "batch_y tensor([[0.0076],\n",
      "        [0.0223]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 244\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1732],\n",
      "        [0.0192]])\n",
      "batch_y tensor([[-0.5055],\n",
      "        [ 0.0077]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 245\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0172],\n",
      "        [-0.1795]])\n",
      "batch_y tensor([[-0.0026],\n",
      "        [-0.0851]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 246\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1157],\n",
      "        [-0.2589]])\n",
      "batch_y tensor([[ 0.2178],\n",
      "        [-0.0074]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 247\n",
      "================\n",
      "\n",
      "batch_x tensor([[  0.0729],\n",
      "        [-10.0248]])\n",
      "batch_y tensor([[-0.0030],\n",
      "        [-0.0304]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 248\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0130],\n",
      "        [-0.3351]])\n",
      "batch_y tensor([[ 0.4965],\n",
      "        [-0.1528]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 249\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0855],\n",
      "        [ 0.3828]])\n",
      "batch_y tensor([[-0.0816],\n",
      "        [ 0.0317]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 250\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0085],\n",
      "        [-0.0264]])\n",
      "batch_y tensor([[ 0.1964],\n",
      "        [-1.0639]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 251\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1096],\n",
      "        [-0.1623]])\n",
      "batch_y tensor([[-0.2422],\n",
      "        [ 0.0966]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 252\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.8467],\n",
      "        [0.2061]])\n",
      "batch_y tensor([[ 0.1318],\n",
      "        [-0.2202]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 253\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6515],\n",
      "        [-0.2701]])\n",
      "batch_y tensor([[0.1081],\n",
      "        [0.4128]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 254\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0290],\n",
      "        [ 0.0423]])\n",
      "batch_y tensor([[-0.0226],\n",
      "        [-0.0175]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 255\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0972],\n",
      "        [ 0.0036]])\n",
      "batch_y tensor([[-0.2611],\n",
      "        [-0.2519]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 256\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0540],\n",
      "        [-0.4425]])\n",
      "batch_y tensor([[1.7219],\n",
      "        [0.7120]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 257\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2329],\n",
      "        [0.7842]])\n",
      "batch_y tensor([[0.1007],\n",
      "        [0.1413]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 258\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2515],\n",
      "        [0.0127]])\n",
      "batch_y tensor([[-0.6137],\n",
      "        [ 0.0252]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 259\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0389],\n",
      "        [-0.0775]])\n",
      "batch_y tensor([[0.0824],\n",
      "        [0.1342]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 260\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0681],\n",
      "        [ 0.0177]])\n",
      "batch_y tensor([[ 0.6968],\n",
      "        [-0.6683]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 261\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0043],\n",
      "        [ 0.0260]])\n",
      "batch_y tensor([[-0.6834],\n",
      "        [ 0.3167]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 262\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0039],\n",
      "        [ 0.0271]])\n",
      "batch_y tensor([[ 0.1385],\n",
      "        [-0.4447]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 263\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1384],\n",
      "        [ 0.0072]])\n",
      "batch_y tensor([[ 0.0170],\n",
      "        [-0.0122]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 264\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0230],\n",
      "        [-0.0443]])\n",
      "batch_y tensor([[-0.1815],\n",
      "        [-0.0763]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 265\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1171],\n",
      "        [0.0413]])\n",
      "batch_y tensor([[0.0277],\n",
      "        [0.0274]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 266\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.9821],\n",
      "        [-0.0086]])\n",
      "batch_y tensor([[-0.0354],\n",
      "        [ 0.0057]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 267\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2420],\n",
      "        [-0.0027]])\n",
      "batch_y tensor([[ 0.0897],\n",
      "        [-0.0161]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 268\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3475],\n",
      "        [ 0.0258]])\n",
      "batch_y tensor([[ 0.1288],\n",
      "        [-0.1342]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 269\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.8586],\n",
      "        [-0.5625]])\n",
      "batch_y tensor([[-0.2599],\n",
      "        [ 0.1459]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 270\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0377],\n",
      "        [ 0.0434]])\n",
      "batch_y tensor([[ 0.3356],\n",
      "        [-0.3743]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 271\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0038],\n",
      "        [ 0.0811]])\n",
      "batch_y tensor([[-0.0137],\n",
      "        [-0.0809]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 272\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2689],\n",
      "        [-0.0184]])\n",
      "batch_y tensor([[0.0934],\n",
      "        [0.4155]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 273\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1158],\n",
      "        [-0.0271]])\n",
      "batch_y tensor([[0.0559],\n",
      "        [1.9280]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 274\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0317],\n",
      "        [0.0307]])\n",
      "batch_y tensor([[-0.6142],\n",
      "        [ 0.0202]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 275\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0145],\n",
      "        [-0.1144]])\n",
      "batch_y tensor([[-0.5437],\n",
      "        [-0.0526]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 276\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0819],\n",
      "        [-0.0904]])\n",
      "batch_y tensor([[ 0.2819],\n",
      "        [-0.0648]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 277\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0049],\n",
      "        [0.0408]])\n",
      "batch_y tensor([[0.0956],\n",
      "        [0.4257]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 278\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0179],\n",
      "        [-0.0964]])\n",
      "batch_y tensor([[ 0.2357],\n",
      "        [-0.1082]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 279\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1029],\n",
      "        [3.8335]])\n",
      "batch_y tensor([[0.0032],\n",
      "        [0.0094]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 280\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0294],\n",
      "        [ 1.0695]])\n",
      "batch_y tensor([[-0.0438],\n",
      "        [ 0.0315]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 281\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0323],\n",
      "        [0.0250]])\n",
      "batch_y tensor([[ 0.0044],\n",
      "        [-0.3594]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 282\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0288],\n",
      "        [0.0240]])\n",
      "batch_y tensor([[ 0.0240],\n",
      "        [-0.0115]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 283\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6637],\n",
      "        [-0.0906]])\n",
      "batch_y tensor([[-0.0846],\n",
      "        [-0.1511]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 284\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2567],\n",
      "        [-0.0417]])\n",
      "batch_y tensor([[-0.0147],\n",
      "        [ 0.0295]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 285\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1071],\n",
      "        [-0.0259]])\n",
      "batch_y tensor([[-0.0128],\n",
      "        [-0.0858]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 286\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0193],\n",
      "        [-0.8350]])\n",
      "batch_y tensor([[-0.3555],\n",
      "        [-0.1049]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 287\n",
      "================\n",
      "\n",
      "batch_x tensor([[   0.1981],\n",
      "        [-116.6590]])\n",
      "batch_y tensor([[ 0.4482],\n",
      "        [-0.4727]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 288\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6170],\n",
      "        [-0.0055]])\n",
      "batch_y tensor([[ 0.0098],\n",
      "        [-0.1014]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 289\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4044],\n",
      "        [-0.1494]])\n",
      "batch_y tensor([[-0.6524],\n",
      "        [ 0.0810]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 290\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3364],\n",
      "        [0.0653]])\n",
      "batch_y tensor([[-0.1883],\n",
      "        [ 0.0373]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 291\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.9544],\n",
      "        [-1.4746]])\n",
      "batch_y tensor([[-12.2048],\n",
      "        [  0.3970]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 292\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2938],\n",
      "        [-0.5396]])\n",
      "batch_y tensor([[-0.1107],\n",
      "        [ 0.1226]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 293\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0022],\n",
      "        [ 0.0526]])\n",
      "batch_y tensor([[-0.0289],\n",
      "        [ 0.0003]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 294\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.4373],\n",
      "        [0.1274]])\n",
      "batch_y tensor([[0.1213],\n",
      "        [0.0850]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 295\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6032],\n",
      "        [-1.3905]])\n",
      "batch_y tensor([[-0.0759],\n",
      "        [-0.0414]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 296\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0758],\n",
      "        [0.0273]])\n",
      "batch_y tensor([[-0.0307],\n",
      "        [-0.0564]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 297\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0347],\n",
      "        [-0.1487]])\n",
      "batch_y tensor([[ 0.1468],\n",
      "        [-0.0216]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 298\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1387],\n",
      "        [-0.0055]])\n",
      "batch_y tensor([[-0.0545],\n",
      "        [ 0.0365]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 299\n",
      "================\n",
      "\n",
      "batch_x tensor([[2.0909],\n",
      "        [0.0847]])\n",
      "batch_y tensor([[-0.0635],\n",
      "        [-0.0587]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 300\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0479],\n",
      "        [-0.1120]])\n",
      "batch_y tensor([[0.0610],\n",
      "        [0.0543]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 301\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0074],\n",
      "        [ 0.0860]])\n",
      "batch_y tensor([[ 0.1387],\n",
      "        [-0.0937]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 302\n",
      "================\n",
      "\n",
      "batch_x tensor([[-2.9551],\n",
      "        [-0.1293]])\n",
      "batch_y tensor([[0.1838],\n",
      "        [0.0948]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 303\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0836],\n",
      "        [-0.0290]])\n",
      "batch_y tensor([[-0.0986],\n",
      "        [-0.1551]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 304\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1122],\n",
      "        [-0.2657]])\n",
      "batch_y tensor([[ 0.0159],\n",
      "        [-1.2828]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 305\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0612],\n",
      "        [ 0.1641]])\n",
      "batch_y tensor([[-0.0729],\n",
      "        [ 0.0285]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 306\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0906],\n",
      "        [-0.3784]])\n",
      "batch_y tensor([[0.2538],\n",
      "        [0.3571]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 307\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1169],\n",
      "        [ 0.0630]])\n",
      "batch_y tensor([[-0.5648],\n",
      "        [ 0.4658]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 308\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3047],\n",
      "        [0.3164]])\n",
      "batch_y tensor([[-0.0050],\n",
      "        [ 0.0205]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 309\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1370],\n",
      "        [-0.1090]])\n",
      "batch_y tensor([[-0.3812],\n",
      "        [ 0.0166]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 310\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0924],\n",
      "        [ 0.2123]])\n",
      "batch_y tensor([[-0.2056],\n",
      "        [-0.0576]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 311\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0040],\n",
      "        [ 0.0074]])\n",
      "batch_y tensor([[-0.0732],\n",
      "        [ 0.4074]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 312\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1561],\n",
      "        [-0.0504]])\n",
      "batch_y tensor([[-3.8083],\n",
      "        [-0.0190]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 313\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2734],\n",
      "        [-0.0208]])\n",
      "batch_y tensor([[ 5.0138],\n",
      "        [-0.0941]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 314\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0490],\n",
      "        [0.0567]])\n",
      "batch_y tensor([[0.0527],\n",
      "        [0.5450]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 315\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0494],\n",
      "        [0.0190]])\n",
      "batch_y tensor([[-0.1218],\n",
      "        [-0.0100]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 316\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.7025],\n",
      "        [-0.2690]])\n",
      "batch_y tensor([[-1.0155],\n",
      "        [-0.1438]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 317\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0195],\n",
      "        [0.0241]])\n",
      "batch_y tensor([[ 0.0767],\n",
      "        [-0.0175]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 318\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2479],\n",
      "        [ 0.0523]])\n",
      "batch_y tensor([[-0.0443],\n",
      "        [-0.0742]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 319\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0276],\n",
      "        [0.2643]])\n",
      "batch_y tensor([[-0.0782],\n",
      "        [ 0.0265]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 320\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0480],\n",
      "        [0.0006]])\n",
      "batch_y tensor([[-0.3166],\n",
      "        [ 0.0137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 321\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3371],\n",
      "        [1.5350]])\n",
      "batch_y tensor([[ 0.0517],\n",
      "        [-0.0201]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 322\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0631],\n",
      "        [-0.2179]])\n",
      "batch_y tensor([[-0.0763],\n",
      "        [-0.0509]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 323\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0574],\n",
      "        [0.0827]])\n",
      "batch_y tensor([[-0.1083],\n",
      "        [ 0.1214]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 324\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1114],\n",
      "        [ 0.1227]])\n",
      "batch_y tensor([[-0.0059],\n",
      "        [-0.0346]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 325\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1318],\n",
      "        [-0.0780]])\n",
      "batch_y tensor([[0.0774],\n",
      "        [0.1424]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 326\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0524],\n",
      "        [ 0.6503]])\n",
      "batch_y tensor([[0.9598],\n",
      "        [0.1543]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 327\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0155],\n",
      "        [0.1546]])\n",
      "batch_y tensor([[-2.9458],\n",
      "        [ 0.1273]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 328\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2358],\n",
      "        [ 0.0160]])\n",
      "batch_y tensor([[-0.0392],\n",
      "        [-0.0648]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 329\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.0593],\n",
      "        [0.6594]])\n",
      "batch_y tensor([[0.0873],\n",
      "        [0.0205]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 330\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1603],\n",
      "        [-0.0548]])\n",
      "batch_y tensor([[-0.0601],\n",
      "        [ 0.2107]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 331\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0745],\n",
      "        [ 0.0118]])\n",
      "batch_y tensor([[-0.1465],\n",
      "        [-0.0301]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 332\n",
      "================\n",
      "\n",
      "batch_x tensor([[-3.2533],\n",
      "        [-0.0552]])\n",
      "batch_y tensor([[-0.1710],\n",
      "        [-0.0499]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 333\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0182],\n",
      "        [0.0601]])\n",
      "batch_y tensor([[-0.0576],\n",
      "        [-0.0137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 334\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.4076],\n",
      "        [-0.0099]])\n",
      "batch_y tensor([[ 0.0470],\n",
      "        [-0.6830]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 335\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.9411],\n",
      "        [ 0.0276]])\n",
      "batch_y tensor([[-0.1743],\n",
      "        [-0.2095]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 336\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3794],\n",
      "        [ 0.0501]])\n",
      "batch_y tensor([[-0.0759],\n",
      "        [ 0.0228]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 337\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1220],\n",
      "        [0.1416]])\n",
      "batch_y tensor([[-0.0397],\n",
      "        [ 0.0145]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 338\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0087],\n",
      "        [ 0.1447]])\n",
      "batch_y tensor([[0.1693],\n",
      "        [0.4693]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 339\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.5938],\n",
      "        [0.0996]])\n",
      "batch_y tensor([[-0.0169],\n",
      "        [-0.2761]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 340\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1487],\n",
      "        [-0.1223]])\n",
      "batch_y tensor([[-2.4040],\n",
      "        [-0.0043]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 341\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2861],\n",
      "        [-0.1032]])\n",
      "batch_y tensor([[-0.3737],\n",
      "        [ 0.0145]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 342\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4882],\n",
      "        [-0.1960]])\n",
      "batch_y tensor([[0.1256],\n",
      "        [0.0083]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 343\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1181],\n",
      "        [-0.0495]])\n",
      "batch_y tensor([[-0.4142],\n",
      "        [-0.0558]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 344\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0639],\n",
      "        [5.9961]])\n",
      "batch_y tensor([[-0.0120],\n",
      "        [ 0.0227]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 345\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0371],\n",
      "        [-0.4914]])\n",
      "batch_y tensor([[ 0.0129],\n",
      "        [-0.0077]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 346\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1630],\n",
      "        [-0.0280]])\n",
      "batch_y tensor([[0.7985],\n",
      "        [0.1970]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 347\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1724],\n",
      "        [-0.0092]])\n",
      "batch_y tensor([[ 0.1358],\n",
      "        [-0.0996]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 348\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0383],\n",
      "        [0.3663]])\n",
      "batch_y tensor([[0.1094],\n",
      "        [0.5751]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 349\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.4533],\n",
      "        [3.5573]])\n",
      "batch_y tensor([[ 0.1555],\n",
      "        [-0.1017]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 350\n",
      "================\n",
      "\n",
      "batch_x tensor([[-3.1850],\n",
      "        [ 0.0313]])\n",
      "batch_y tensor([[-0.0756],\n",
      "        [ 0.4900]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 351\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2866],\n",
      "        [-0.2323]])\n",
      "batch_y tensor([[ 0.0466],\n",
      "        [-0.2737]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 352\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0211],\n",
      "        [-0.1934]])\n",
      "batch_y tensor([[0.3392],\n",
      "        [0.0406]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 353\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2548],\n",
      "        [-0.3996]])\n",
      "batch_y tensor([[-1.0940],\n",
      "        [-0.0042]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 354\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0622],\n",
      "        [-0.0532]])\n",
      "batch_y tensor([[-0.0546],\n",
      "        [ 0.0528]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 355\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0646],\n",
      "        [-0.0205]])\n",
      "batch_y tensor([[ 0.3476],\n",
      "        [-0.4021]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 356\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1355],\n",
      "        [0.1717]])\n",
      "batch_y tensor([[-0.1264],\n",
      "        [-0.1658]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 357\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0238],\n",
      "        [-0.1731]])\n",
      "batch_y tensor([[0.0244],\n",
      "        [0.0949]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 358\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0701],\n",
      "        [-0.2452]])\n",
      "batch_y tensor([[-0.0392],\n",
      "        [ 0.0063]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 359\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1793],\n",
      "        [0.1366]])\n",
      "batch_y tensor([[-1.6202],\n",
      "        [ 0.2516]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 360\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0630],\n",
      "        [-0.4585]])\n",
      "batch_y tensor([[-0.1353],\n",
      "        [ 0.0076]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 361\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0722],\n",
      "        [-0.0681]])\n",
      "batch_y tensor([[ 0.0285],\n",
      "        [-0.1372]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 362\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1820],\n",
      "        [-0.0435]])\n",
      "batch_y tensor([[ 0.2255],\n",
      "        [-0.0681]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 363\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0739],\n",
      "        [-0.0905]])\n",
      "batch_y tensor([[ 0.0674],\n",
      "        [47.0076]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 364\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1440],\n",
      "        [-0.0013]])\n",
      "batch_y tensor([[ 0.0262],\n",
      "        [-0.0277]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 365\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0145],\n",
      "        [ 0.0340]])\n",
      "batch_y tensor([[-0.0449],\n",
      "        [ 0.5585]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 366\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1156],\n",
      "        [-0.1699]])\n",
      "batch_y tensor([[-0.0925],\n",
      "        [ 0.1653]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 367\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0122],\n",
      "        [0.1384]])\n",
      "batch_y tensor([[-0.2908],\n",
      "        [ 0.0103]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 368\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3791],\n",
      "        [-0.1794]])\n",
      "batch_y tensor([[-0.0594],\n",
      "        [ 0.0365]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 369\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1850],\n",
      "        [-0.1237]])\n",
      "batch_y tensor([[ 0.0458],\n",
      "        [-0.1687]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 370\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1026],\n",
      "        [-0.0891]])\n",
      "batch_y tensor([[ 0.3623],\n",
      "        [-0.0188]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 371\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0715],\n",
      "        [0.1896]])\n",
      "batch_y tensor([[-0.0650],\n",
      "        [ 0.3805]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 372\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0018],\n",
      "        [-0.0528]])\n",
      "batch_y tensor([[ 0.1391],\n",
      "        [-0.1208]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 373\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0032],\n",
      "        [ 0.0632]])\n",
      "batch_y tensor([[ 0.0582],\n",
      "        [-0.0558]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 374\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4237],\n",
      "        [ 0.0595]])\n",
      "batch_y tensor([[ 0.1527],\n",
      "        [-0.0408]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 375\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2229],\n",
      "        [0.0494]])\n",
      "batch_y tensor([[0.0560],\n",
      "        [0.1046]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 376\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0961],\n",
      "        [-0.1111]])\n",
      "batch_y tensor([[ 0.0676],\n",
      "        [-0.0658]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 377\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5590],\n",
      "        [ 0.0257]])\n",
      "batch_y tensor([[  3.7534],\n",
      "        [-12.0153]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 378\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0156],\n",
      "        [-0.0731]])\n",
      "batch_y tensor([[ 0.0900],\n",
      "        [-0.0077]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 379\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0717],\n",
      "        [-0.0381]])\n",
      "batch_y tensor([[-0.1507],\n",
      "        [-0.2117]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 380\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.7275],\n",
      "        [-0.0349]])\n",
      "batch_y tensor([[-0.2754],\n",
      "        [-1.5215]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 381\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0716],\n",
      "        [ 0.0444]])\n",
      "batch_y tensor([[-0.1300],\n",
      "        [ 0.0185]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 382\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0532],\n",
      "        [0.0040]])\n",
      "batch_y tensor([[0.0327],\n",
      "        [0.2142]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 383\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0933],\n",
      "        [-0.1074]])\n",
      "batch_y tensor([[0.0577],\n",
      "        [0.0183]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 384\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1201],\n",
      "        [ 0.0553]])\n",
      "batch_y tensor([[ 0.0120],\n",
      "        [-0.3698]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 385\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1721],\n",
      "        [-0.1813]])\n",
      "batch_y tensor([[ 0.4630],\n",
      "        [-0.0378]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 386\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0048],\n",
      "        [ 1.6100]])\n",
      "batch_y tensor([[-0.2239],\n",
      "        [-0.1942]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 387\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3521],\n",
      "        [-0.0313]])\n",
      "batch_y tensor([[ 0.1633],\n",
      "        [-0.0214]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 388\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1546],\n",
      "        [ 0.1469]])\n",
      "batch_y tensor([[-0.0307],\n",
      "        [ 0.0380]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 389\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1710],\n",
      "        [ 0.0030]])\n",
      "batch_y tensor([[ 0.3760],\n",
      "        [-0.0171]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 390\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4624],\n",
      "        [ 0.0316]])\n",
      "batch_y tensor([[-0.0838],\n",
      "        [-0.2082]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 391\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0540],\n",
      "        [0.0076]])\n",
      "batch_y tensor([[0.1724],\n",
      "        [0.7841]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 392\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.7866],\n",
      "        [0.2488]])\n",
      "batch_y tensor([[ 0.1391],\n",
      "        [-0.0688]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 393\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.3260],\n",
      "        [-0.0427]])\n",
      "batch_y tensor([[0.1241],\n",
      "        [0.1035]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 394\n",
      "================\n",
      "\n",
      "batch_x tensor([[-13.6289],\n",
      "        [ -0.1221]])\n",
      "batch_y tensor([[-0.0316],\n",
      "        [ 2.9606]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 395\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0736],\n",
      "        [1.1910]])\n",
      "batch_y tensor([[ 0.2004],\n",
      "        [-0.0185]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 396\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0868],\n",
      "        [0.0129]])\n",
      "batch_y tensor([[0.0358],\n",
      "        [0.7761]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 397\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0455],\n",
      "        [ 0.1040]])\n",
      "batch_y tensor([[ 1.3015],\n",
      "        [-0.0756]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 398\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0480],\n",
      "        [0.3340]])\n",
      "batch_y tensor([[ 0.0613],\n",
      "        [-0.0117]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 399\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0333],\n",
      "        [0.3034]])\n",
      "batch_y tensor([[-0.0064],\n",
      "        [ 1.0029]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 400\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3120],\n",
      "        [-0.2800]])\n",
      "batch_y tensor([[-0.0441],\n",
      "        [ 0.1381]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 401\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0746],\n",
      "        [0.4154]])\n",
      "batch_y tensor([[-0.0283],\n",
      "        [ 1.2612]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 402\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.9925],\n",
      "        [-0.1884]])\n",
      "batch_y tensor([[-0.0466],\n",
      "        [ 0.0083]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 403\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0773],\n",
      "        [-0.1958]])\n",
      "batch_y tensor([[ 0.5654],\n",
      "        [-0.0804]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 404\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.3196],\n",
      "        [ 0.0271]])\n",
      "batch_y tensor([[0.3048],\n",
      "        [0.3866]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 405\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6692],\n",
      "        [-0.0794]])\n",
      "batch_y tensor([[-0.0878],\n",
      "        [ 0.4340]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 406\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0007],\n",
      "        [-0.0876]])\n",
      "batch_y tensor([[0.9142],\n",
      "        [0.1390]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 407\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2106],\n",
      "        [1.2070]])\n",
      "batch_y tensor([[ 0.0461],\n",
      "        [-0.0710]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 408\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6437],\n",
      "        [ 0.0098]])\n",
      "batch_y tensor([[-0.0498],\n",
      "        [-0.0619]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 409\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.0411],\n",
      "        [-0.7019]])\n",
      "batch_y tensor([[-0.4166],\n",
      "        [-0.2484]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 410\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0323],\n",
      "        [ 0.1883]])\n",
      "batch_y tensor([[0.0687],\n",
      "        [0.0886]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 411\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6707],\n",
      "        [-1.2384]])\n",
      "batch_y tensor([[ 0.8919],\n",
      "        [-0.0416]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 412\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6851],\n",
      "        [-0.1965]])\n",
      "batch_y tensor([[ 0.0188],\n",
      "        [-0.1720]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 413\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1077],\n",
      "        [ 0.0601]])\n",
      "batch_y tensor([[ 0.2212],\n",
      "        [-1.1535]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 414\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2108],\n",
      "        [-9.5231]])\n",
      "batch_y tensor([[ 0.4934],\n",
      "        [-0.4079]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 415\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1154],\n",
      "        [-0.0466]])\n",
      "batch_y tensor([[-0.0451],\n",
      "        [-0.0467]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 416\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.5555],\n",
      "        [0.0544]])\n",
      "batch_y tensor([[ 0.1036],\n",
      "        [-0.1232]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 417\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0922],\n",
      "        [ 0.0446]])\n",
      "batch_y tensor([[-0.0440],\n",
      "        [ 0.0694]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 418\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0017],\n",
      "        [0.0314]])\n",
      "batch_y tensor([[-0.1252],\n",
      "        [ 0.0384]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 419\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1618],\n",
      "        [-0.0626]])\n",
      "batch_y tensor([[-0.1909],\n",
      "        [-6.8772]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 420\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0244],\n",
      "        [-0.0519]])\n",
      "batch_y tensor([[-0.3775],\n",
      "        [ 0.0037]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 421\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0239],\n",
      "        [ 0.0185]])\n",
      "batch_y tensor([[-0.1915],\n",
      "        [-0.0824]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 422\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0686],\n",
      "        [ 0.0983]])\n",
      "batch_y tensor([[-0.0736],\n",
      "        [ 0.2107]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 423\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0435],\n",
      "        [0.3334]])\n",
      "batch_y tensor([[0.2335],\n",
      "        [0.1496]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 424\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0772],\n",
      "        [0.0658]])\n",
      "batch_y tensor([[-0.6835],\n",
      "        [-0.0900]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 425\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0277],\n",
      "        [ 0.6227]])\n",
      "batch_y tensor([[-0.0163],\n",
      "        [-0.1194]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 426\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0462],\n",
      "        [ 1.2727]])\n",
      "batch_y tensor([[-0.0186],\n",
      "        [-0.0957]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 427\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0344],\n",
      "        [-0.1019]])\n",
      "batch_y tensor([[ 0.1308],\n",
      "        [-0.2814]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 428\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0245],\n",
      "        [-0.0240]])\n",
      "batch_y tensor([[-0.0316],\n",
      "        [-0.0761]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 429\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.5011],\n",
      "        [0.0299]])\n",
      "batch_y tensor([[-0.2270],\n",
      "        [ 0.8072]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 430\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0710],\n",
      "        [-0.1240]])\n",
      "batch_y tensor([[-0.3941],\n",
      "        [ 0.1792]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 431\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0461],\n",
      "        [-0.2023]])\n",
      "batch_y tensor([[ 0.0224],\n",
      "        [-0.2743]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 432\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2424],\n",
      "        [-0.0630]])\n",
      "batch_y tensor([[-0.0225],\n",
      "        [ 1.2020]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 433\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0820],\n",
      "        [0.0598]])\n",
      "batch_y tensor([[0.0283],\n",
      "        [0.0309]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 434\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0057],\n",
      "        [ 0.0067]])\n",
      "batch_y tensor([[0.0088],\n",
      "        [0.1452]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 435\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0236],\n",
      "        [-0.7639]])\n",
      "batch_y tensor([[0.1371],\n",
      "        [2.9238]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 436\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1339],\n",
      "        [ 0.0109]])\n",
      "batch_y tensor([[-0.1319],\n",
      "        [-0.1430]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 437\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0101],\n",
      "        [0.0219]])\n",
      "batch_y tensor([[ 0.0024],\n",
      "        [-0.0034]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 438\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0195],\n",
      "        [13.4745]])\n",
      "batch_y tensor([[0.3847],\n",
      "        [0.0231]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 439\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0698],\n",
      "        [-0.0749]])\n",
      "batch_y tensor([[-0.0467],\n",
      "        [-0.0940]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 440\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.7619],\n",
      "        [ 0.1060]])\n",
      "batch_y tensor([[-0.1866],\n",
      "        [-0.0105]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 441\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0310],\n",
      "        [0.3059]])\n",
      "batch_y tensor([[ 0.0145],\n",
      "        [-0.0679]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 442\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1348],\n",
      "        [0.0940]])\n",
      "batch_y tensor([[0.0442],\n",
      "        [1.3751]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 443\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0649],\n",
      "        [-0.0170]])\n",
      "batch_y tensor([[-0.2736],\n",
      "        [ 0.4522]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 444\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2265],\n",
      "        [-0.0335]])\n",
      "batch_y tensor([[0.5200],\n",
      "        [0.0103]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 445\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0863],\n",
      "        [-0.1879]])\n",
      "batch_y tensor([[-0.4199],\n",
      "        [ 0.0126]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 446\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2873],\n",
      "        [-0.4111]])\n",
      "batch_y tensor([[-0.3047],\n",
      "        [-0.4070]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 447\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0389],\n",
      "        [ 0.2230]])\n",
      "batch_y tensor([[-0.0900],\n",
      "        [-0.0247]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 448\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 2.0899],\n",
      "        [-0.0361]])\n",
      "batch_y tensor([[0.0265],\n",
      "        [0.3883]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 449\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2953],\n",
      "        [1.3905]])\n",
      "batch_y tensor([[-1.7853],\n",
      "        [-0.0105]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 450\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2919],\n",
      "        [-0.0021]])\n",
      "batch_y tensor([[ 0.0876],\n",
      "        [-0.0638]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 451\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1060],\n",
      "        [ 0.0969]])\n",
      "batch_y tensor([[-0.0911],\n",
      "        [-0.0663]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 452\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0240],\n",
      "        [-0.8556]])\n",
      "batch_y tensor([[0.3406],\n",
      "        [6.8802]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 453\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6396],\n",
      "        [0.0142]])\n",
      "batch_y tensor([[0.7479],\n",
      "        [0.1492]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 454\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2226],\n",
      "        [-0.2205]])\n",
      "batch_y tensor([[-0.2934],\n",
      "        [ 0.0539]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 455\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1857],\n",
      "        [-0.0005]])\n",
      "batch_y tensor([[ 3.8361],\n",
      "        [-0.3376]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 456\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0522],\n",
      "        [-0.0588]])\n",
      "batch_y tensor([[-2.1552],\n",
      "        [ 0.0633]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 457\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1365],\n",
      "        [ 0.1194]])\n",
      "batch_y tensor([[0.8182],\n",
      "        [0.0679]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 458\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4221],\n",
      "        [-0.0583]])\n",
      "batch_y tensor([[-0.0375],\n",
      "        [-0.0908]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 459\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3218],\n",
      "        [-0.0077]])\n",
      "batch_y tensor([[0.0328],\n",
      "        [0.0062]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 460\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0136],\n",
      "        [0.1684]])\n",
      "batch_y tensor([[0.5060],\n",
      "        [3.2787]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 461\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2015],\n",
      "        [-0.1035]])\n",
      "batch_y tensor([[-0.2740],\n",
      "        [ 0.4045]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 462\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2837],\n",
      "        [ 0.2273]])\n",
      "batch_y tensor([[0.0339],\n",
      "        [0.0265]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 463\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2671],\n",
      "        [ 0.1526]])\n",
      "batch_y tensor([[0.0076],\n",
      "        [0.0952]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 464\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0391],\n",
      "        [-0.7616]])\n",
      "batch_y tensor([[1.0304e-04],\n",
      "        [6.2231e-01]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 465\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 9.2647],\n",
      "        [-0.3180]])\n",
      "batch_y tensor([[-0.4118],\n",
      "        [ 0.0201]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 466\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0779],\n",
      "        [-3.6585]])\n",
      "batch_y tensor([[0.0454],\n",
      "        [0.0729]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 467\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0246],\n",
      "        [ 0.0790]])\n",
      "batch_y tensor([[0.2093],\n",
      "        [1.0403]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 468\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0163],\n",
      "        [-0.0077]])\n",
      "batch_y tensor([[-1.0637],\n",
      "        [-0.6504]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 469\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1428],\n",
      "        [0.0005]])\n",
      "batch_y tensor([[-0.1005],\n",
      "        [ 0.0008]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 470\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1038],\n",
      "        [0.1265]])\n",
      "batch_y tensor([[22.4297],\n",
      "        [ 0.2331]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 471\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2173],\n",
      "        [ 0.5226]])\n",
      "batch_y tensor([[ 0.0259],\n",
      "        [-0.3906]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 472\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0947],\n",
      "        [-0.2070]])\n",
      "batch_y tensor([[ 0.0823],\n",
      "        [-0.0589]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 473\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1205],\n",
      "        [-0.0527]])\n",
      "batch_y tensor([[ 0.1874],\n",
      "        [-0.0829]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 474\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.5258],\n",
      "        [0.0034]])\n",
      "batch_y tensor([[-0.2878],\n",
      "        [-0.0027]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 475\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0557],\n",
      "        [-0.0191]])\n",
      "batch_y tensor([[ 0.1199],\n",
      "        [-0.3582]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 476\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0010],\n",
      "        [-0.1701]])\n",
      "batch_y tensor([[0.6702],\n",
      "        [0.0478]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 477\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0044],\n",
      "        [ 0.1258]])\n",
      "batch_y tensor([[ 0.0435],\n",
      "        [-0.0408]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 478\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1276],\n",
      "        [-0.2811]])\n",
      "batch_y tensor([[0.1011],\n",
      "        [0.3160]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 479\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1062],\n",
      "        [-0.5204]])\n",
      "batch_y tensor([[-0.4070],\n",
      "        [ 0.1277]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 480\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2333],\n",
      "        [-0.1524]])\n",
      "batch_y tensor([[ 1.3798],\n",
      "        [-0.3027]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 481\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1096],\n",
      "        [ 0.2206]])\n",
      "batch_y tensor([[ 0.1923],\n",
      "        [-0.0444]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 482\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3951],\n",
      "        [ 0.0958]])\n",
      "batch_y tensor([[ 0.1462],\n",
      "        [-0.2615]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 483\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.7334],\n",
      "        [ 0.1602]])\n",
      "batch_y tensor([[-0.0711],\n",
      "        [ 0.1166]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 484\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0140],\n",
      "        [-0.0528]])\n",
      "batch_y tensor([[0.0448],\n",
      "        [0.0562]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 485\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0314],\n",
      "        [-0.0179]])\n",
      "batch_y tensor([[-0.0513],\n",
      "        [ 0.0349]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 486\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0534],\n",
      "        [-0.2983]])\n",
      "batch_y tensor([[ 0.3405],\n",
      "        [-0.0210]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 487\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0144],\n",
      "        [-0.0228]])\n",
      "batch_y tensor([[0.4075],\n",
      "        [0.3376]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 488\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0542],\n",
      "        [ 0.0094]])\n",
      "batch_y tensor([[-0.1716],\n",
      "        [ 0.0123]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 489\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1676],\n",
      "        [-0.4029]])\n",
      "batch_y tensor([[ 0.0067],\n",
      "        [-0.1214]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 490\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0366],\n",
      "        [-0.4196]])\n",
      "batch_y tensor([[-0.9923],\n",
      "        [-0.0131]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 491\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.8598],\n",
      "        [ 9.2424]])\n",
      "batch_y tensor([[ 0.1609],\n",
      "        [-0.0536]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 492\n",
      "================\n",
      "\n",
      "batch_x tensor([[ -0.0382],\n",
      "        [-22.1950]])\n",
      "batch_y tensor([[-0.4732],\n",
      "        [-0.1331]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 493\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0021],\n",
      "        [-0.0975]])\n",
      "batch_y tensor([[0.0152],\n",
      "        [0.3060]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 494\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0056],\n",
      "        [-0.2688]])\n",
      "batch_y tensor([[-0.0999],\n",
      "        [ 0.0777]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 495\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1366],\n",
      "        [ 0.3999]])\n",
      "batch_y tensor([[-0.5090],\n",
      "        [-0.5492]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 496\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0923],\n",
      "        [ 0.1060]])\n",
      "batch_y tensor([[ 0.3393],\n",
      "        [-0.1975]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 497\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1214],\n",
      "        [ 0.5936]])\n",
      "batch_y tensor([[-0.1671],\n",
      "        [-0.0433]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 498\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6472],\n",
      "        [ 0.1586]])\n",
      "batch_y tensor([[-0.0096],\n",
      "        [ 0.8402]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 499\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1222],\n",
      "        [0.1288]])\n",
      "batch_y tensor([[-0.1489],\n",
      "        [-0.0301]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 0\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.9821],\n",
      "        [-0.7019]])\n",
      "batch_y tensor([[-0.0354],\n",
      "        [-0.2484]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 1\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0504],\n",
      "        [-0.0550]])\n",
      "batch_y tensor([[-0.0190],\n",
      "        [ 0.1565]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 2\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0484],\n",
      "        [ 0.3521]])\n",
      "batch_y tensor([[-0.1931],\n",
      "        [ 0.1633]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 3\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0061],\n",
      "        [-0.0869]])\n",
      "batch_y tensor([[-0.0340],\n",
      "        [-0.0435]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 4\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1934],\n",
      "        [ 0.0382]])\n",
      "batch_y tensor([[ 0.0406],\n",
      "        [-0.0860]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 5\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4542],\n",
      "        [ 0.0653]])\n",
      "batch_y tensor([[0.0059],\n",
      "        [0.0373]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 6\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1587],\n",
      "        [ 0.5540]])\n",
      "batch_y tensor([[0.2074],\n",
      "        [0.0192]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 7\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.0771e-01],\n",
      "        [-1.1666e+02]])\n",
      "batch_y tensor([[ 0.2212],\n",
      "        [-0.4727]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 8\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1060],\n",
      "        [0.0746]])\n",
      "batch_y tensor([[-0.1975],\n",
      "        [-0.0283]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 9\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0443],\n",
      "        [ 0.0860]])\n",
      "batch_y tensor([[-0.0763],\n",
      "        [-0.2786]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 10\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0523],\n",
      "        [-0.0559]])\n",
      "batch_y tensor([[-0.0742],\n",
      "        [-0.2908]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 11\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2515],\n",
      "        [0.0232]])\n",
      "batch_y tensor([[-0.6137],\n",
      "        [-0.0905]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 12\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1440],\n",
      "        [-0.0044]])\n",
      "batch_y tensor([[ 0.0262],\n",
      "        [-0.3114]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 13\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0480],\n",
      "        [0.0600]])\n",
      "batch_y tensor([[-0.3166],\n",
      "        [-0.0893]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 14\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4624],\n",
      "        [ 0.0258]])\n",
      "batch_y tensor([[-0.0838],\n",
      "        [ 0.0522]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 15\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1370],\n",
      "        [0.0259]])\n",
      "batch_y tensor([[-0.3812],\n",
      "        [-0.0007]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 16\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1038],\n",
      "        [-0.2433]])\n",
      "batch_y tensor([[22.4297],\n",
      "        [ 0.0363]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 17\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1710],\n",
      "        [-0.0975]])\n",
      "batch_y tensor([[0.3760],\n",
      "        [0.3060]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 18\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0151],\n",
      "        [-0.0768]])\n",
      "batch_y tensor([[ 0.2466],\n",
      "        [-0.0236]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 19\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0698],\n",
      "        [-0.5590]])\n",
      "batch_y tensor([[-0.0467],\n",
      "        [ 3.7534]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 20\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0381],\n",
      "        [ 0.0127]])\n",
      "batch_y tensor([[-0.2117],\n",
      "        [ 0.0252]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 21\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.9544],\n",
      "        [ 0.7842]])\n",
      "batch_y tensor([[-12.2048],\n",
      "        [  0.1413]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 22\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2690],\n",
      "        [ 0.0869]])\n",
      "batch_y tensor([[-0.1438],\n",
      "        [ 0.1932]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 23\n",
      "================\n",
      "\n",
      "batch_x tensor([[2.5413],\n",
      "        [1.2361]])\n",
      "batch_y tensor([[-0.0471],\n",
      "        [-0.7221]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 24\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0586],\n",
      "        [0.2682]])\n",
      "batch_y tensor([[0.2782],\n",
      "        [0.0053]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 25\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.8467],\n",
      "        [-0.0294]])\n",
      "batch_y tensor([[ 0.1318],\n",
      "        [-0.0438]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 26\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2323],\n",
      "        [-1.9411]])\n",
      "batch_y tensor([[-0.2737],\n",
      "        [-0.1743]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 27\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0343],\n",
      "        [-0.0013]])\n",
      "batch_y tensor([[ 0.0388],\n",
      "        [-0.0277]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 28\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1114],\n",
      "        [-0.0391]])\n",
      "batch_y tensor([[-0.0059],\n",
      "        [ 0.0001]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 29\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0330],\n",
      "        [ 0.1863]])\n",
      "batch_y tensor([[-0.1167],\n",
      "        [-0.9076]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 30\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2023],\n",
      "        [-0.0130]])\n",
      "batch_y tensor([[-0.2743],\n",
      "        [ 0.4965]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 31\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1318],\n",
      "        [-0.0061]])\n",
      "batch_y tensor([[0.0774],\n",
      "        [0.6132]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 32\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1318],\n",
      "        [-0.8586]])\n",
      "batch_y tensor([[ 0.1320],\n",
      "        [-0.2599]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 33\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1215],\n",
      "        [-0.0290]])\n",
      "batch_y tensor([[ 0.0546],\n",
      "        [-0.1551]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 34\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0495],\n",
      "        [-0.2567]])\n",
      "batch_y tensor([[ 0.6738],\n",
      "        [-0.0147]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 35\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0280],\n",
      "        [ 0.0601]])\n",
      "batch_y tensor([[ 0.1970],\n",
      "        [-1.1535]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 36\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0049],\n",
      "        [-0.0462]])\n",
      "batch_y tensor([[-0.3343],\n",
      "        [-0.0186]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 37\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0277],\n",
      "        [-0.1302]])\n",
      "batch_y tensor([[-0.0163],\n",
      "        [ 0.2746]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 38\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0243],\n",
      "        [-0.0649]])\n",
      "batch_y tensor([[-0.0222],\n",
      "        [-0.2736]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 39\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0024],\n",
      "        [-0.0905]])\n",
      "batch_y tensor([[-0.1998],\n",
      "        [47.0076]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 40\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0277],\n",
      "        [ 0.2767]])\n",
      "batch_y tensor([[0.0043],\n",
      "        [0.0446]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 41\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0057],\n",
      "        [-0.1096]])\n",
      "batch_y tensor([[0.0088],\n",
      "        [0.1923]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 42\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0313],\n",
      "        [ 0.0191]])\n",
      "batch_y tensor([[-0.0214],\n",
      "        [15.9262]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 43\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1274],\n",
      "        [0.0273]])\n",
      "batch_y tensor([[ 0.0850],\n",
      "        [-0.0564]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 44\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0359],\n",
      "        [-0.2701]])\n",
      "batch_y tensor([[-0.0695],\n",
      "        [ 0.4128]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 45\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2789],\n",
      "        [0.3923]])\n",
      "batch_y tensor([[-0.0617],\n",
      "        [ 2.6874]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 46\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0497],\n",
      "        [ 0.0820]])\n",
      "batch_y tensor([[-0.1068],\n",
      "        [ 0.0283]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 47\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1384],\n",
      "        [ 0.0491]])\n",
      "batch_y tensor([[0.0170],\n",
      "        [0.0141]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 48\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0183],\n",
      "        [-0.4072]])\n",
      "batch_y tensor([[-0.0720],\n",
      "        [-0.1418]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 49\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1169],\n",
      "        [ 0.0333]])\n",
      "batch_y tensor([[ 0.1104],\n",
      "        [-0.0064]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 50\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6637],\n",
      "        [-0.0186]])\n",
      "batch_y tensor([[-0.0846],\n",
      "        [-0.1553]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 51\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2097],\n",
      "        [-0.1260]])\n",
      "batch_y tensor([[0.0714],\n",
      "        [0.0780]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 52\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2837],\n",
      "        [-0.1037]])\n",
      "batch_y tensor([[ 0.0339],\n",
      "        [-0.5053]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 53\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0794],\n",
      "        [ 0.0413]])\n",
      "batch_y tensor([[0.4340],\n",
      "        [0.0274]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 54\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0809],\n",
      "        [0.0376]])\n",
      "batch_y tensor([[ 0.0146],\n",
      "        [-0.1359]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 55\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0595],\n",
      "        [-0.1557]])\n",
      "batch_y tensor([[-0.0408],\n",
      "        [-0.3630]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 56\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3510],\n",
      "        [0.1060]])\n",
      "batch_y tensor([[-0.1403],\n",
      "        [-0.0105]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 57\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0578],\n",
      "        [-0.3791]])\n",
      "batch_y tensor([[-0.0220],\n",
      "        [-0.0594]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 58\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0399],\n",
      "        [-1.1094]])\n",
      "batch_y tensor([[-0.1023],\n",
      "        [-0.0576]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 59\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0643],\n",
      "        [-0.3120]])\n",
      "batch_y tensor([[ 0.1768],\n",
      "        [-0.0441]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 60\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6396],\n",
      "        [-0.0731]])\n",
      "batch_y tensor([[ 0.7479],\n",
      "        [-0.0077]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 61\n",
      "================\n",
      "\n",
      "batch_x tensor([[-4.7651],\n",
      "        [-0.0263]])\n",
      "batch_y tensor([[0.0306],\n",
      "        [0.0234]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 62\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0017],\n",
      "        [-0.0552]])\n",
      "batch_y tensor([[-0.1252],\n",
      "        [-0.0499]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 63\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1604],\n",
      "        [ 0.0288]])\n",
      "batch_y tensor([[0.0136],\n",
      "        [0.0240]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 64\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4995],\n",
      "        [-0.0271]])\n",
      "batch_y tensor([[-0.0327],\n",
      "        [-0.1894]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 65\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0228],\n",
      "        [ 0.1515]])\n",
      "batch_y tensor([[ 0.3376],\n",
      "        [-0.1442]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 66\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0972],\n",
      "        [-0.0946]])\n",
      "batch_y tensor([[-0.2611],\n",
      "        [-0.0851]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 67\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0177],\n",
      "        [-0.0527]])\n",
      "batch_y tensor([[-0.6683],\n",
      "        [-0.0829]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 68\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1366],\n",
      "        [-0.2016]])\n",
      "batch_y tensor([[-0.5090],\n",
      "        [-0.1150]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 69\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0191],\n",
      "        [ 0.0314]])\n",
      "batch_y tensor([[-0.3582],\n",
      "        [ 0.0384]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 70\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0259],\n",
      "        [ 0.5258]])\n",
      "batch_y tensor([[-0.0858],\n",
      "        [-0.2878]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 71\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2265],\n",
      "        [0.0322]])\n",
      "batch_y tensor([[ 0.5200],\n",
      "        [-0.9194]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 72\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1177],\n",
      "        [0.7275]])\n",
      "batch_y tensor([[ 0.0787],\n",
      "        [-0.2754]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 73\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0021],\n",
      "        [ 1.0324]])\n",
      "batch_y tensor([[-0.0638],\n",
      "        [ 0.0864]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 74\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1883],\n",
      "        [-0.2420]])\n",
      "batch_y tensor([[0.0886],\n",
      "        [0.0897]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 75\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0014],\n",
      "        [-0.0920]])\n",
      "batch_y tensor([[-0.0609],\n",
      "        [ 0.0797]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 76\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0056],\n",
      "        [0.2339]])\n",
      "batch_y tensor([[0.3391],\n",
      "        [0.0952]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 77\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.3905e+00],\n",
      "        [-5.0564e-04]])\n",
      "batch_y tensor([[-0.0105],\n",
      "        [-0.3376]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 78\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2861],\n",
      "        [-0.0354]])\n",
      "batch_y tensor([[-0.3737],\n",
      "        [-0.0202]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 79\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.1910],\n",
      "        [0.1288]])\n",
      "batch_y tensor([[-0.0185],\n",
      "        [-0.0301]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 80\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0057],\n",
      "        [-0.1724]])\n",
      "batch_y tensor([[-0.0463],\n",
      "        [ 0.1358]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 81\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1293],\n",
      "        [ 0.0052]])\n",
      "batch_y tensor([[ 0.0948],\n",
      "        [-0.0579]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 82\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0108],\n",
      "        [-0.2873]])\n",
      "batch_y tensor([[-0.1457],\n",
      "        [-0.3047]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 83\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0632],\n",
      "        [-0.1546]])\n",
      "batch_y tensor([[-0.0558],\n",
      "        [-0.0307]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 84\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2919],\n",
      "        [-0.0548]])\n",
      "batch_y tensor([[0.0876],\n",
      "        [0.2107]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 85\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0827],\n",
      "        [-0.0377]])\n",
      "batch_y tensor([[0.1214],\n",
      "        [0.0307]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 86\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.6515],\n",
      "        [ 0.2982]])\n",
      "batch_y tensor([[ 0.1081],\n",
      "        [-0.8488]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 87\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0924],\n",
      "        [ 0.0219]])\n",
      "batch_y tensor([[-0.2056],\n",
      "        [-0.0929]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 88\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1276],\n",
      "        [-0.0730]])\n",
      "batch_y tensor([[ 0.1011],\n",
      "        [-0.0857]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 89\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0285],\n",
      "        [-0.0923]])\n",
      "batch_y tensor([[-0.1544],\n",
      "        [ 0.3393]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 90\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0312],\n",
      "        [ 0.1793]])\n",
      "batch_y tensor([[-0.2576],\n",
      "        [-1.6202]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 91\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1216],\n",
      "        [-0.0461]])\n",
      "batch_y tensor([[-0.1112],\n",
      "        [ 0.0224]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 92\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0532],\n",
      "        [ 0.0735]])\n",
      "batch_y tensor([[ 0.0528],\n",
      "        [-0.1613]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 93\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0588],\n",
      "        [ 0.7449]])\n",
      "batch_y tensor([[-0.0454],\n",
      "        [-0.3689]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 94\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0099],\n",
      "        [-0.1618]])\n",
      "batch_y tensor([[-0.0094],\n",
      "        [-0.1909]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 95\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0479],\n",
      "        [ 1.0411]])\n",
      "batch_y tensor([[ 0.0610],\n",
      "        [-0.4166]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 96\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1048],\n",
      "        [-0.1442]])\n",
      "batch_y tensor([[-0.0367],\n",
      "        [-0.1297]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 97\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0136],\n",
      "        [0.1181]])\n",
      "batch_y tensor([[-0.0267],\n",
      "        [-0.4142]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 98\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0055],\n",
      "        [0.0109]])\n",
      "batch_y tensor([[-0.0736],\n",
      "        [-0.1430]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 99\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0702],\n",
      "        [-0.2205]])\n",
      "batch_y tensor([[0.0252],\n",
      "        [0.0539]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 100\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1767],\n",
      "        [-0.7187]])\n",
      "batch_y tensor([[-0.5116],\n",
      "        [-0.2239]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 101\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0236],\n",
      "        [0.1366]])\n",
      "batch_y tensor([[0.1371],\n",
      "        [0.2516]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 102\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.8556],\n",
      "        [-0.2800]])\n",
      "batch_y tensor([[6.8802],\n",
      "        [0.1381]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 103\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0048],\n",
      "        [-0.0049]])\n",
      "batch_y tensor([[-0.6878],\n",
      "        [ 0.0845]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 104\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0646],\n",
      "        [-0.0604]])\n",
      "batch_y tensor([[0.3476],\n",
      "        [0.0979]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 105\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0417],\n",
      "        [-0.3784]])\n",
      "batch_y tensor([[0.0295],\n",
      "        [0.3571]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 106\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1057],\n",
      "        [-0.0106]])\n",
      "batch_y tensor([[ 0.7384],\n",
      "        [-0.0464]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 107\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0230],\n",
      "        [ 0.0405]])\n",
      "batch_y tensor([[ 0.0399],\n",
      "        [-0.0079]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 108\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0983],\n",
      "        [-0.6170]])\n",
      "batch_y tensor([[0.2107],\n",
      "        [0.0098]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 109\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1202],\n",
      "        [-0.0017]])\n",
      "batch_y tensor([[-0.0200],\n",
      "        [-0.0430]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 110\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0099],\n",
      "        [-0.0739]])\n",
      "batch_y tensor([[-0.6830],\n",
      "        [ 0.0674]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 111\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1819],\n",
      "        [-0.0116]])\n",
      "batch_y tensor([[ 0.6645],\n",
      "        [-0.4727]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 112\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 2.3349],\n",
      "        [-0.0074]])\n",
      "batch_y tensor([[-0.1924],\n",
      "        [ 0.1387]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 113\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0658],\n",
      "        [0.0710]])\n",
      "batch_y tensor([[-0.0900],\n",
      "        [-0.3941]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 114\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1265],\n",
      "        [0.6959]])\n",
      "batch_y tensor([[0.2331],\n",
      "        [0.0223]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 115\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2015],\n",
      "        [ 0.5440]])\n",
      "batch_y tensor([[-0.2740],\n",
      "        [ 0.5176]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 116\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0074],\n",
      "        [-0.0379]])\n",
      "batch_y tensor([[ 0.4074],\n",
      "        [-0.0137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 117\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0186],\n",
      "        [-0.1019]])\n",
      "batch_y tensor([[-0.1993],\n",
      "        [-0.2814]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 118\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0868],\n",
      "        [0.0482]])\n",
      "batch_y tensor([[ 0.0358],\n",
      "        [-0.0284]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 119\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1340],\n",
      "        [ 0.0276]])\n",
      "batch_y tensor([[ 0.1586],\n",
      "        [-0.2095]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 120\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0466],\n",
      "        [ 0.1586]])\n",
      "batch_y tensor([[-0.0467],\n",
      "        [ 0.8402]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 121\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0408],\n",
      "        [0.0546]])\n",
      "batch_y tensor([[ 0.4257],\n",
      "        [-5.2447]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 122\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4795],\n",
      "        [ 0.0544]])\n",
      "batch_y tensor([[-0.0924],\n",
      "        [-0.1232]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 123\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0013],\n",
      "        [-0.0686]])\n",
      "batch_y tensor([[-0.0254],\n",
      "        [-0.0736]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 124\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4196],\n",
      "        [ 0.1222]])\n",
      "batch_y tensor([[-0.0131],\n",
      "        [-0.1489]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 125\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1432],\n",
      "        [-0.1699]])\n",
      "batch_y tensor([[0.0661],\n",
      "        [0.1653]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 126\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0749],\n",
      "        [ 0.1071]])\n",
      "batch_y tensor([[ 0.0186],\n",
      "        [-0.0128]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 127\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1384],\n",
      "        [-0.0069]])\n",
      "batch_y tensor([[0.0103],\n",
      "        [0.1682]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 128\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0584],\n",
      "        [-0.3116]])\n",
      "batch_y tensor([[ 0.0412],\n",
      "        [-0.0725]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 129\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0818],\n",
      "        [ 0.2709]])\n",
      "batch_y tensor([[ 0.0209],\n",
      "        [-1.0447]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 130\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1009],\n",
      "        [ 0.7025]])\n",
      "batch_y tensor([[-0.0418],\n",
      "        [-1.0155]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 131\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1850],\n",
      "        [-0.6692]])\n",
      "batch_y tensor([[ 0.0458],\n",
      "        [-0.0878]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 132\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1530],\n",
      "        [ 0.4895]])\n",
      "batch_y tensor([[-0.1073],\n",
      "        [-0.0754]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 133\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0021],\n",
      "        [-0.0086]])\n",
      "batch_y tensor([[0.0152],\n",
      "        [0.0057]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 134\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2230],\n",
      "        [-0.1460]])\n",
      "batch_y tensor([[-0.0247],\n",
      "        [-0.0115]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 135\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0438],\n",
      "        [-1.9312]])\n",
      "batch_y tensor([[-0.0421],\n",
      "        [ 0.0874]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 136\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0906],\n",
      "        [-0.0508]])\n",
      "batch_y tensor([[ 0.2538],\n",
      "        [-0.0669]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 137\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0299],\n",
      "        [0.0006]])\n",
      "batch_y tensor([[0.8072],\n",
      "        [0.0137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 138\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3393],\n",
      "        [ 0.2333]])\n",
      "batch_y tensor([[-0.0249],\n",
      "        [ 0.0159]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 139\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1676],\n",
      "        [-0.1221]])\n",
      "batch_y tensor([[0.0067],\n",
      "        [2.9606]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 140\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1428],\n",
      "        [0.0005]])\n",
      "batch_y tensor([[-0.1005],\n",
      "        [ 0.0008]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 141\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0730],\n",
      "        [ 1.5350]])\n",
      "batch_y tensor([[ 0.0605],\n",
      "        [-0.0201]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 142\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0435],\n",
      "        [ 1.9400]])\n",
      "batch_y tensor([[-0.0681],\n",
      "        [ 0.0604]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 143\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2479],\n",
      "        [-0.0622]])\n",
      "batch_y tensor([[-0.0443],\n",
      "        [-0.0546]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 144\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4585],\n",
      "        [ 0.2054]])\n",
      "batch_y tensor([[0.0076],\n",
      "        [0.1343]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 145\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0969],\n",
      "        [0.2596]])\n",
      "batch_y tensor([[-0.0663],\n",
      "        [ 0.0172]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 146\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0754],\n",
      "        [-0.0064]])\n",
      "batch_y tensor([[ 0.1254],\n",
      "        [-0.0043]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 147\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0039],\n",
      "        [-0.0773]])\n",
      "batch_y tensor([[0.1385],\n",
      "        [0.5654]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 148\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3996],\n",
      "        [ 0.3334]])\n",
      "batch_y tensor([[-0.0042],\n",
      "        [ 0.1496]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 149\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3475],\n",
      "        [-0.0077]])\n",
      "batch_y tensor([[0.1288],\n",
      "        [0.0062]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 150\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0567],\n",
      "        [-0.3180]])\n",
      "batch_y tensor([[0.0175],\n",
      "        [0.0201]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 151\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1786],\n",
      "        [-0.0663]])\n",
      "batch_y tensor([[0.6692],\n",
      "        [0.2775]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 152\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0534],\n",
      "        [-0.6610]])\n",
      "batch_y tensor([[ 0.3405],\n",
      "        [-1.9760]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 153\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1529],\n",
      "        [-0.0481]])\n",
      "batch_y tensor([[ 0.5244],\n",
      "        [-0.0184]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 154\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1526],\n",
      "        [-0.0425]])\n",
      "batch_y tensor([[ 0.0952],\n",
      "        [-3.8582]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 155\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1077],\n",
      "        [ 0.0018]])\n",
      "batch_y tensor([[-0.0273],\n",
      "        [ 0.1391]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 156\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1701],\n",
      "        [-0.7616]])\n",
      "batch_y tensor([[0.0478],\n",
      "        [0.6223]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 157\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0546],\n",
      "        [-0.0775]])\n",
      "batch_y tensor([[0.0149],\n",
      "        [0.1342]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 158\n",
      "================\n",
      "\n",
      "batch_x tensor([[13.4745],\n",
      "        [-0.1879]])\n",
      "batch_y tensor([[0.0231],\n",
      "        [0.0126]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 159\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0142],\n",
      "        [-0.9553]])\n",
      "batch_y tensor([[0.1492],\n",
      "        [0.0549]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 160\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0443],\n",
      "        [0.1258]])\n",
      "batch_y tensor([[-0.2654],\n",
      "        [-0.0408]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 161\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1026],\n",
      "        [-9.3257]])\n",
      "batch_y tensor([[0.3623],\n",
      "        [0.1101]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 162\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4914],\n",
      "        [ 0.3962]])\n",
      "batch_y tensor([[-0.0077],\n",
      "        [-0.0633]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 163\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0528],\n",
      "        [ 0.0240]])\n",
      "batch_y tensor([[ 0.0562],\n",
      "        [-0.0115]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 164\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0189],\n",
      "        [ 0.1717]])\n",
      "batch_y tensor([[-1.3523],\n",
      "        [-0.1658]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 165\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.6032],\n",
      "        [-0.2255]])\n",
      "batch_y tensor([[-0.0759],\n",
      "        [ 0.0525]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 166\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2229],\n",
      "        [-0.0144]])\n",
      "batch_y tensor([[0.0560],\n",
      "        [0.4075]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 167\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0044],\n",
      "        [-0.1674]])\n",
      "batch_y tensor([[ 0.0435],\n",
      "        [-5.2304]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 168\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0272],\n",
      "        [ 1.3260]])\n",
      "batch_y tensor([[-0.0358],\n",
      "        [ 0.1241]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 169\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1074],\n",
      "        [ 0.0276]])\n",
      "batch_y tensor([[ 0.0183],\n",
      "        [-0.0782]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 170\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2039],\n",
      "        [0.3121]])\n",
      "batch_y tensor([[-0.1846],\n",
      "        [-0.1386]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 171\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5396],\n",
      "        [-0.1365]])\n",
      "batch_y tensor([[0.1226],\n",
      "        [0.8182]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 172\n",
      "================\n",
      "\n",
      "batch_x tensor([[-10.0248],\n",
      "        [ -0.0407]])\n",
      "batch_y tensor([[-0.0304],\n",
      "        [ 0.0641]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 173\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0958],\n",
      "        [0.0184]])\n",
      "batch_y tensor([[-0.2615],\n",
      "        [ 0.0398]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 174\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2858],\n",
      "        [0.0050]])\n",
      "batch_y tensor([[-0.0187],\n",
      "        [-0.2178]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 175\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0048],\n",
      "        [ 0.0896]])\n",
      "batch_y tensor([[-0.2239],\n",
      "        [ 0.2049]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 176\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2206],\n",
      "        [0.0637]])\n",
      "batch_y tensor([[-0.0444],\n",
      "        [ 0.4407]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 177\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.4373],\n",
      "        [0.0340]])\n",
      "batch_y tensor([[0.1213],\n",
      "        [0.5585]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 178\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1170],\n",
      "        [ 0.1403]])\n",
      "batch_y tensor([[ 0.0271],\n",
      "        [-0.1393]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 179\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0730],\n",
      "        [-0.0208]])\n",
      "batch_y tensor([[ 1.4516],\n",
      "        [-0.0941]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 180\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0192],\n",
      "        [0.1684]])\n",
      "batch_y tensor([[0.0077],\n",
      "        [3.2787]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 181\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.4945],\n",
      "        [0.3344]])\n",
      "batch_y tensor([[-0.2043],\n",
      "        [ 0.0722]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 182\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0960],\n",
      "        [-0.1000]])\n",
      "batch_y tensor([[-0.6540],\n",
      "        [-0.3291]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 183\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0891],\n",
      "        [ 0.0446]])\n",
      "batch_y tensor([[-0.0188],\n",
      "        [ 0.0694]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 184\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2273],\n",
      "        [-0.2505]])\n",
      "batch_y tensor([[ 0.0265],\n",
      "        [-0.0410]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 185\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5552],\n",
      "        [-0.0246]])\n",
      "batch_y tensor([[-0.0185],\n",
      "        [ 0.2093]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 186\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0565],\n",
      "        [-0.1884]])\n",
      "batch_y tensor([[-0.1500],\n",
      "        [ 0.0083]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 187\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1144],\n",
      "        [-0.1032]])\n",
      "batch_y tensor([[-0.0526],\n",
      "        [ 0.0145]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 188\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0415],\n",
      "        [-0.0371]])\n",
      "batch_y tensor([[-0.1654],\n",
      "        [ 0.0129]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 189\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0335],\n",
      "        [ 0.1416]])\n",
      "batch_y tensor([[0.0103],\n",
      "        [0.0145]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 190\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0068],\n",
      "        [-0.0010]])\n",
      "batch_y tensor([[0.0832],\n",
      "        [0.0279]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 191\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.5105],\n",
      "        [-0.6472]])\n",
      "batch_y tensor([[ 0.0613],\n",
      "        [-0.0096]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 192\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0612],\n",
      "        [-0.5204]])\n",
      "batch_y tensor([[-0.0729],\n",
      "        [ 0.1277]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 193\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0231],\n",
      "        [-0.1861]])\n",
      "batch_y tensor([[-0.0988],\n",
      "        [-0.0635]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 194\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3256],\n",
      "        [-0.0314]])\n",
      "batch_y tensor([[ 0.0298],\n",
      "        [-0.0513]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 195\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0223],\n",
      "        [0.1100]])\n",
      "batch_y tensor([[ 0.2031],\n",
      "        [-0.0147]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 196\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0490],\n",
      "        [-0.1158]])\n",
      "batch_y tensor([[0.0527],\n",
      "        [0.0559]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 197\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1348],\n",
      "        [-0.0443]])\n",
      "batch_y tensor([[-0.0324],\n",
      "        [ 0.0402]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 198\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0630],\n",
      "        [-0.0349]])\n",
      "batch_y tensor([[-0.1353],\n",
      "        [-1.5215]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 199\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0729],\n",
      "        [-0.0232]])\n",
      "batch_y tensor([[-0.0030],\n",
      "        [ 0.1965]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 200\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1447],\n",
      "        [1.1838]])\n",
      "batch_y tensor([[0.4693],\n",
      "        [0.1626]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 201\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0879],\n",
      "        [ 0.0601]])\n",
      "batch_y tensor([[ 0.2403],\n",
      "        [-0.0137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 202\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0182],\n",
      "        [0.2226]])\n",
      "batch_y tensor([[-0.0576],\n",
      "        [-0.2934]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 203\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0108],\n",
      "        [-0.0630]])\n",
      "batch_y tensor([[-6.1399e-04],\n",
      "        [ 1.2020e+00]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 204\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5625],\n",
      "        [ 0.0193]])\n",
      "batch_y tensor([[ 0.1459],\n",
      "        [-0.3555]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 205\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2715],\n",
      "        [0.2270]])\n",
      "batch_y tensor([[ 0.0240],\n",
      "        [-1.3681]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 206\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2996],\n",
      "        [-0.1213]])\n",
      "batch_y tensor([[-0.0872],\n",
      "        [-0.0226]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 207\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0067],\n",
      "        [0.0383]])\n",
      "batch_y tensor([[0.1452],\n",
      "        [0.1094]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 208\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0630],\n",
      "        [ 0.0271]])\n",
      "batch_y tensor([[ 0.0076],\n",
      "        [-0.4447]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 209\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0240],\n",
      "        [-0.0630]])\n",
      "batch_y tensor([[0.3406],\n",
      "        [0.0615]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 210\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0780],\n",
      "        [-0.0522]])\n",
      "batch_y tensor([[ 0.1424],\n",
      "        [-2.1552]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 211\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.3905],\n",
      "        [-0.0974]])\n",
      "batch_y tensor([[-0.0414],\n",
      "        [ 0.2742]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 212\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0553],\n",
      "        [0.2106]])\n",
      "batch_y tensor([[-0.3698],\n",
      "        [ 0.0461]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 213\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.3196],\n",
      "        [ 0.0122]])\n",
      "batch_y tensor([[ 0.3048],\n",
      "        [-0.2908]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 214\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0359],\n",
      "        [-0.0980]])\n",
      "batch_y tensor([[0.1222],\n",
      "        [0.7191]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 215\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2154],\n",
      "        [ 0.0245]])\n",
      "batch_y tensor([[-0.0170],\n",
      "        [-0.0316]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 216\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1539],\n",
      "        [9.1587]])\n",
      "batch_y tensor([[0.0441],\n",
      "        [0.0069]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 217\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2589],\n",
      "        [-0.5093]])\n",
      "batch_y tensor([[-0.0074],\n",
      "        [ 0.0945]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 218\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1641],\n",
      "        [0.3164]])\n",
      "batch_y tensor([[0.0285],\n",
      "        [0.0205]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 219\n",
      "================\n",
      "\n",
      "batch_x tensor([[-8.2940],\n",
      "        [ 3.5573]])\n",
      "batch_y tensor([[-0.1497],\n",
      "        [-0.1017]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 220\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0278],\n",
      "        [-0.0897]])\n",
      "batch_y tensor([[ 0.1093],\n",
      "        [-0.0188]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 221\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0501],\n",
      "        [-0.0072]])\n",
      "batch_y tensor([[0.0228],\n",
      "        [0.0013]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 222\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6503],\n",
      "        [0.3364]])\n",
      "batch_y tensor([[ 0.1543],\n",
      "        [-0.1883]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 223\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0625],\n",
      "        [-2.9294]])\n",
      "batch_y tensor([[0.0099],\n",
      "        [0.0002]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 224\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2991],\n",
      "        [0.3606]])\n",
      "batch_y tensor([[-0.0526],\n",
      "        [ 0.5226]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 225\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0491],\n",
      "        [ 0.0342]])\n",
      "batch_y tensor([[-0.0259],\n",
      "        [ 0.0245]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 226\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2733],\n",
      "        [0.0253]])\n",
      "batch_y tensor([[ 0.0231],\n",
      "        [-0.1333]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 227\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1463],\n",
      "        [0.2061]])\n",
      "batch_y tensor([[ 0.0773],\n",
      "        [-0.2202]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 228\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0906],\n",
      "        [-0.2332]])\n",
      "batch_y tensor([[-0.1511],\n",
      "        [ 0.1918]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 229\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0274],\n",
      "        [-0.1935]])\n",
      "batch_y tensor([[0.1619],\n",
      "        [0.1751]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 230\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0856],\n",
      "        [-0.0382]])\n",
      "batch_y tensor([[-0.9376],\n",
      "        [-0.4732]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 231\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1201],\n",
      "        [ 0.1210]])\n",
      "batch_y tensor([[0.0120],\n",
      "        [0.2108]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 232\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.5100],\n",
      "        [-0.0231]])\n",
      "batch_y tensor([[-0.0044],\n",
      "        [ 0.0549]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 233\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0722],\n",
      "        [ 0.0836]])\n",
      "batch_y tensor([[-0.1266],\n",
      "        [-0.0986]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 234\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0496],\n",
      "        [ 0.1835]])\n",
      "batch_y tensor([[ 0.3400],\n",
      "        [-2.9778]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 235\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1623],\n",
      "        [-0.0719]])\n",
      "batch_y tensor([[ 0.0966],\n",
      "        [-0.1990]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 236\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3351],\n",
      "        [ 0.1381]])\n",
      "batch_y tensor([[-0.1528],\n",
      "        [-4.4293]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 237\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0982],\n",
      "        [-0.1154]])\n",
      "batch_y tensor([[ 0.1598],\n",
      "        [-0.0451]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 238\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1965],\n",
      "        [-0.1370]])\n",
      "batch_y tensor([[-0.1720],\n",
      "        [12.8843]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 239\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4256],\n",
      "        [-0.0007]])\n",
      "batch_y tensor([[0.0086],\n",
      "        [0.9142]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 240\n",
      "================\n",
      "\n",
      "batch_x tensor([[2.0754],\n",
      "        [0.0089]])\n",
      "batch_y tensor([[ 0.1136],\n",
      "        [-0.2947]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 241\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0427],\n",
      "        [ 0.0371]])\n",
      "batch_y tensor([[0.1035],\n",
      "        [0.3098]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 242\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0574],\n",
      "        [0.8248]])\n",
      "batch_y tensor([[-0.1083],\n",
      "        [-0.0647]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 243\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1090],\n",
      "        [ 0.0571]])\n",
      "batch_y tensor([[ 0.0166],\n",
      "        [-0.4094]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 244\n",
      "================\n",
      "\n",
      "batch_x tensor([[-13.6289],\n",
      "        [  0.0258]])\n",
      "batch_y tensor([[-0.0316],\n",
      "        [-0.1342]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 245\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0494],\n",
      "        [0.6227]])\n",
      "batch_y tensor([[-0.1218],\n",
      "        [-0.1194]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 246\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0502],\n",
      "        [-0.1717]])\n",
      "batch_y tensor([[-0.2100],\n",
      "        [-0.0920]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 247\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0388],\n",
      "        [-0.0145]])\n",
      "batch_y tensor([[-0.0794],\n",
      "        [-0.5437]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 248\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0907],\n",
      "        [-0.0543]])\n",
      "batch_y tensor([[ 0.0043],\n",
      "        [-0.3313]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 249\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0087],\n",
      "        [-0.0441]])\n",
      "batch_y tensor([[0.1693],\n",
      "        [0.3653]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 250\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4237],\n",
      "        [-7.9219]])\n",
      "batch_y tensor([[0.1527],\n",
      "        [0.1399]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 251\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0366],\n",
      "        [-0.0635]])\n",
      "batch_y tensor([[-0.9923],\n",
      "        [ 0.0310]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 252\n",
      "================\n",
      "\n",
      "batch_x tensor([[ -0.0922],\n",
      "        [-11.0609]])\n",
      "batch_y tensor([[-0.0440],\n",
      "        [-5.9082]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 253\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1203],\n",
      "        [-0.1458]])\n",
      "batch_y tensor([[0.0147],\n",
      "        [0.0015]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 254\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4859],\n",
      "        [-0.0023]])\n",
      "batch_y tensor([[ 0.1397],\n",
      "        [-0.0940]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 255\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.2727],\n",
      "        [-0.0654]])\n",
      "batch_y tensor([[-0.0957],\n",
      "        [-0.0173]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 256\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3461],\n",
      "        [0.3340]])\n",
      "batch_y tensor([[ 0.0223],\n",
      "        [-0.0117]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 257\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1240],\n",
      "        [ 0.0722]])\n",
      "batch_y tensor([[0.1792],\n",
      "        [0.0285]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 258\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0344],\n",
      "        [ 0.0261]])\n",
      "batch_y tensor([[0.1308],\n",
      "        [1.2595]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 259\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0716],\n",
      "        [ 1.0593]])\n",
      "batch_y tensor([[-0.1300],\n",
      "        [ 0.0873]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 260\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3059],\n",
      "        [0.0444]])\n",
      "batch_y tensor([[-0.0679],\n",
      "        [ 0.0185]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 261\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0123],\n",
      "        [-0.0740]])\n",
      "batch_y tensor([[0.0520],\n",
      "        [0.0974]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 262\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0373],\n",
      "        [ 0.0772]])\n",
      "batch_y tensor([[ 0.1220],\n",
      "        [-0.6835]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 263\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3951],\n",
      "        [ 0.1096]])\n",
      "batch_y tensor([[ 0.1462],\n",
      "        [-0.2422]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 264\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1782],\n",
      "        [0.1301]])\n",
      "batch_y tensor([[ 0.0909],\n",
      "        [-0.1916]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 265\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1246],\n",
      "        [0.0030]])\n",
      "batch_y tensor([[-0.8318],\n",
      "        [-0.0171]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 266\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0365],\n",
      "        [-0.0055]])\n",
      "batch_y tensor([[-0.0159],\n",
      "        [ 0.0365]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 267\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0285],\n",
      "        [-0.0751]])\n",
      "batch_y tensor([[ 0.1520],\n",
      "        [-0.3107]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 268\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0423],\n",
      "        [0.1571]])\n",
      "batch_y tensor([[-0.0175],\n",
      "        [ 0.0096]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 269\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2657],\n",
      "        [-0.0038]])\n",
      "batch_y tensor([[-1.2828],\n",
      "        [-0.0137]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 270\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0964],\n",
      "        [-0.4522]])\n",
      "batch_y tensor([[-0.1082],\n",
      "        [-0.4247]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 271\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0170],\n",
      "        [ 0.0811]])\n",
      "batch_y tensor([[ 0.4522],\n",
      "        [-0.0809]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 272\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0357],\n",
      "        [0.3828]])\n",
      "batch_y tensor([[0.1462],\n",
      "        [0.0317]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 273\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0113],\n",
      "        [-0.0178]])\n",
      "batch_y tensor([[-0.2971],\n",
      "        [ 0.2084]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 274\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0434],\n",
      "        [-0.1590]])\n",
      "batch_y tensor([[-0.3743],\n",
      "        [-0.0136]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 275\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0072],\n",
      "        [0.0481]])\n",
      "batch_y tensor([[-0.0122],\n",
      "        [ 0.1894]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 276\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1820],\n",
      "        [-0.1524]])\n",
      "batch_y tensor([[ 0.2255],\n",
      "        [-0.3027]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 277\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1146],\n",
      "        [-0.0179]])\n",
      "batch_y tensor([[0.0245],\n",
      "        [0.0349]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 278\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.4154],\n",
      "        [0.0630]])\n",
      "batch_y tensor([[1.2612],\n",
      "        [0.0304]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 279\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 7.0559e-05],\n",
      "        [-6.4060e-02]])\n",
      "batch_y tensor([[-0.0220],\n",
      "        [-0.1445]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 280\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1455],\n",
      "        [ 0.2548]])\n",
      "batch_y tensor([[ 0.1155],\n",
      "        [-1.0940]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 281\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0040],\n",
      "        [-0.1630]])\n",
      "batch_y tensor([[-0.0732],\n",
      "        [ 0.7985]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 282\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1632],\n",
      "        [0.0540]])\n",
      "batch_y tensor([[0.0234],\n",
      "        [1.7219]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 283\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3214],\n",
      "        [-0.1857]])\n",
      "batch_y tensor([[-0.1618],\n",
      "        [ 3.8361]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 284\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0758],\n",
      "        [-0.1117]])\n",
      "batch_y tensor([[-0.0307],\n",
      "        [-0.0511]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 285\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0085],\n",
      "        [-0.0271]])\n",
      "batch_y tensor([[0.1964],\n",
      "        [1.9280]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 286\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0098],\n",
      "        [0.0101]])\n",
      "batch_y tensor([[-0.0619],\n",
      "        [ 0.0024]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 287\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0524],\n",
      "        [ 0.0385]])\n",
      "batch_y tensor([[ 0.9598],\n",
      "        [-0.0455]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 288\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0175],\n",
      "        [ 0.2953]])\n",
      "batch_y tensor([[ 0.1103],\n",
      "        [-1.7853]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 289\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0936],\n",
      "        [0.0878]])\n",
      "batch_y tensor([[ 0.1237],\n",
      "        [-0.1688]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 290\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0036],\n",
      "        [0.0408]])\n",
      "batch_y tensor([[-0.2519],\n",
      "        [-0.0292]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 291\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1859],\n",
      "        [-3.1850]])\n",
      "batch_y tensor([[-0.0478],\n",
      "        [-0.0756]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 292\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2123],\n",
      "        [0.2424]])\n",
      "batch_y tensor([[-0.0576],\n",
      "        [-0.0225]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 293\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0845],\n",
      "        [0.0630]])\n",
      "batch_y tensor([[-0.0894],\n",
      "        [ 0.4658]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 294\n",
      "================\n",
      "\n",
      "batch_x tensor([[-2.9551],\n",
      "        [-0.0311]])\n",
      "batch_y tensor([[ 0.1838],\n",
      "        [-0.0025]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 295\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2160],\n",
      "        [-0.1205]])\n",
      "batch_y tensor([[0.0806],\n",
      "        [0.1874]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 296\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0779],\n",
      "        [ 0.1546]])\n",
      "batch_y tensor([[0.0454],\n",
      "        [0.1273]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 297\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1460],\n",
      "        [-0.4221]])\n",
      "batch_y tensor([[-0.0213],\n",
      "        [-0.0375]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 298\n",
      "================\n",
      "\n",
      "batch_x tensor([[-5.6912e-04],\n",
      "        [ 6.1831e-01]])\n",
      "batch_y tensor([[-0.1052],\n",
      "        [-0.1388]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 299\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1275],\n",
      "        [-0.4111]])\n",
      "batch_y tensor([[ 0.2255],\n",
      "        [-0.4070]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 300\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.7866],\n",
      "        [1.5555]])\n",
      "batch_y tensor([[0.1391],\n",
      "        [0.1036]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 301\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.5936],\n",
      "        [-0.1269]])\n",
      "batch_y tensor([[-0.0433],\n",
      "        [ 0.1622]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 302\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0681],\n",
      "        [-0.0179]])\n",
      "batch_y tensor([[-0.1372],\n",
      "        [ 0.2357]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 303\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0357],\n",
      "        [ 0.2878]])\n",
      "batch_y tensor([[ 0.3158],\n",
      "        [-0.1774]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 304\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2333],\n",
      "        [-0.0184]])\n",
      "batch_y tensor([[1.3798],\n",
      "        [0.4155]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 305\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0145],\n",
      "        [ 0.1812]])\n",
      "batch_y tensor([[-0.0449],\n",
      "        [-0.1107]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 306\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.2384],\n",
      "        [-0.0323]])\n",
      "batch_y tensor([[-0.0416],\n",
      "        [ 0.0687]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 307\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.4533],\n",
      "        [-0.0755]])\n",
      "batch_y tensor([[ 0.1555],\n",
      "        [-0.2830]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 308\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0252],\n",
      "        [-0.0455]])\n",
      "batch_y tensor([[0.0934],\n",
      "        [1.3015]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 309\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0090],\n",
      "        [0.5938]])\n",
      "batch_y tensor([[-0.0368],\n",
      "        [-0.0169]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 310\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1348],\n",
      "        [-0.0137]])\n",
      "batch_y tensor([[0.0442],\n",
      "        [0.0871]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 311\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0175],\n",
      "        [ 0.1896]])\n",
      "batch_y tensor([[-0.0710],\n",
      "        [ 0.3805]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 312\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0540],\n",
      "        [-3.2533]])\n",
      "batch_y tensor([[ 0.1724],\n",
      "        [-0.1710]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 313\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3178],\n",
      "        [0.0260]])\n",
      "batch_y tensor([[-0.0264],\n",
      "        [ 0.3167]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 314\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1096],\n",
      "        [-0.1494]])\n",
      "batch_y tensor([[-0.0223],\n",
      "        [ 0.0810]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 315\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0195],\n",
      "        [-0.1585]])\n",
      "batch_y tensor([[0.0767],\n",
      "        [0.3778]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 316\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0381],\n",
      "        [-0.6437]])\n",
      "batch_y tensor([[ 0.0301],\n",
      "        [-0.0498]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 317\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4726],\n",
      "        [-0.8598]])\n",
      "batch_y tensor([[-0.0243],\n",
      "        [ 0.1609]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 318\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0947],\n",
      "        [ 0.0155]])\n",
      "batch_y tensor([[ 0.0823],\n",
      "        [-2.9458]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 319\n",
      "================\n",
      "\n",
      "batch_x tensor([[-6.9505],\n",
      "        [ 0.0203]])\n",
      "batch_y tensor([[-0.0415],\n",
      "        [ 0.1145]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 320\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.1810],\n",
      "        [ 1.0695]])\n",
      "batch_y tensor([[-1.7052],\n",
      "        [ 0.0315]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 321\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0438],\n",
      "        [-0.0495]])\n",
      "batch_y tensor([[-0.8253],\n",
      "        [-0.0558]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 322\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0302],\n",
      "        [-0.0526]])\n",
      "batch_y tensor([[-0.0836],\n",
      "        [ 0.1420]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 323\n",
      "================\n",
      "\n",
      "batch_x tensor([[2.0899],\n",
      "        [0.0040]])\n",
      "batch_y tensor([[0.0265],\n",
      "        [0.2142]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 324\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0156],\n",
      "        [-4.5253]])\n",
      "batch_y tensor([[ 0.0900],\n",
      "        [-0.2021]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 325\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1795],\n",
      "        [-0.1214]])\n",
      "batch_y tensor([[-0.0851],\n",
      "        [-0.1671]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 326\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0394],\n",
      "        [-0.1223]])\n",
      "batch_y tensor([[ 0.0412],\n",
      "        [-0.0043]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 327\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0997],\n",
      "        [ 0.2716]])\n",
      "batch_y tensor([[-0.0248],\n",
      "        [ 0.5787]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 328\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0567],\n",
      "        [-0.1025]])\n",
      "batch_y tensor([[0.5450],\n",
      "        [0.0611]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 329\n",
      "================\n",
      "\n",
      "batch_x tensor([[2.3350],\n",
      "        [0.8126]])\n",
      "batch_y tensor([[0.0270],\n",
      "        [0.1602]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 330\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0676],\n",
      "        [-0.0961]])\n",
      "batch_y tensor([[0.1392],\n",
      "        [0.0676]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 331\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0287],\n",
      "        [ 0.2129]])\n",
      "batch_y tensor([[-0.0554],\n",
      "        [ 0.0051]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 332\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0526],\n",
      "        [-0.0304]])\n",
      "batch_y tensor([[0.0003],\n",
      "        [0.0206]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 333\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0329],\n",
      "        [-0.0384]])\n",
      "batch_y tensor([[-1.7879],\n",
      "        [-0.0456]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 334\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4643],\n",
      "        [ 2.3356]])\n",
      "batch_y tensor([[-0.0328],\n",
      "        [-4.1971]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 335\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0847],\n",
      "        [0.0129]])\n",
      "batch_y tensor([[-0.0587],\n",
      "        [-0.1011]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 336\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0512],\n",
      "        [0.1029]])\n",
      "batch_y tensor([[-0.1365],\n",
      "        [ 0.0032]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 337\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0580],\n",
      "        [-0.9925]])\n",
      "batch_y tensor([[ 0.0024],\n",
      "        [-0.0466]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 338\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0188],\n",
      "        [-0.0749]])\n",
      "batch_y tensor([[ 0.2029],\n",
      "        [-0.0940]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 339\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2452],\n",
      "        [-0.0029]])\n",
      "batch_y tensor([[0.0063],\n",
      "        [0.5204]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 340\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0701],\n",
      "        [-0.4029]])\n",
      "batch_y tensor([[-0.0392],\n",
      "        [-0.1214]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 341\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2643],\n",
      "        [0.1171]])\n",
      "batch_y tensor([[0.0265],\n",
      "        [0.0277]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 342\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0216],\n",
      "        [0.0656]])\n",
      "batch_y tensor([[-2.1257],\n",
      "        [-0.1490]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 343\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6700],\n",
      "        [0.2329]])\n",
      "batch_y tensor([[0.1428],\n",
      "        [0.1007]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 344\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1062],\n",
      "        [0.0487]])\n",
      "batch_y tensor([[-0.4070],\n",
      "        [ 0.0392]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 345\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.7639],\n",
      "        [-0.0077]])\n",
      "batch_y tensor([[ 2.9238],\n",
      "        [-0.6504]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 346\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0582],\n",
      "        [0.6326]])\n",
      "batch_y tensor([[0.0205],\n",
      "        [0.0656]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 347\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0096],\n",
      "        [0.5483]])\n",
      "batch_y tensor([[ 4.2309],\n",
      "        [-0.2069]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 348\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2938],\n",
      "        [0.0076]])\n",
      "batch_y tensor([[-0.1107],\n",
      "        [-0.0595]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 349\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2866],\n",
      "        [-0.1672]])\n",
      "batch_y tensor([[ 0.0466],\n",
      "        [-0.1421]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 350\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.9873],\n",
      "        [0.2108]])\n",
      "batch_y tensor([[0.3446],\n",
      "        [0.4934]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 351\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0427],\n",
      "        [-0.1111]])\n",
      "batch_y tensor([[-0.4218],\n",
      "        [-0.0658]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 352\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1358],\n",
      "        [ 0.1823]])\n",
      "batch_y tensor([[-0.1947],\n",
      "        [ 0.0468]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 353\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0381],\n",
      "        [0.6851]])\n",
      "batch_y tensor([[-0.0843],\n",
      "        [ 0.0188]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 354\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0436],\n",
      "        [-0.0276]])\n",
      "batch_y tensor([[-0.0032],\n",
      "        [-0.0953]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 355\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2039],\n",
      "        [0.1981]])\n",
      "batch_y tensor([[ 0.0208],\n",
      "        [-0.0494]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 356\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1469],\n",
      "        [-0.2707]])\n",
      "batch_y tensor([[0.0380],\n",
      "        [0.1510]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 357\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1355],\n",
      "        [0.0170]])\n",
      "batch_y tensor([[-0.1264],\n",
      "        [ 0.0904]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 358\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3663],\n",
      "        [-0.2675]])\n",
      "batch_y tensor([[0.5751],\n",
      "        [0.0484]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 359\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0211],\n",
      "        [-0.0339]])\n",
      "batch_y tensor([[ 0.3392],\n",
      "        [-0.0724]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 360\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0499],\n",
      "        [-0.1958]])\n",
      "batch_y tensor([[ 0.1795],\n",
      "        [-0.0804]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 361\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0160],\n",
      "        [0.0250]])\n",
      "batch_y tensor([[-0.0648],\n",
      "        [-0.3594]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 362\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0205],\n",
      "        [-0.1731]])\n",
      "batch_y tensor([[-0.4021],\n",
      "        [ 0.0949]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 363\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1414],\n",
      "        [-0.0211]])\n",
      "batch_y tensor([[-0.0798],\n",
      "        [-0.0175]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 364\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.5470],\n",
      "        [-0.0528]])\n",
      "batch_y tensor([[-0.0774],\n",
      "        [-0.1208]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 365\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2734],\n",
      "        [-0.2983]])\n",
      "batch_y tensor([[ 5.0138],\n",
      "        [-0.0210]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 366\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0519],\n",
      "        [-0.0846]])\n",
      "batch_y tensor([[0.0037],\n",
      "        [0.3187]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 367\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0855],\n",
      "        [ 0.2689]])\n",
      "batch_y tensor([[-0.0816],\n",
      "        [ 0.0934]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 368\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0583],\n",
      "        [-0.7619]])\n",
      "batch_y tensor([[-0.0908],\n",
      "        [-0.1866]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 369\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1122],\n",
      "        [ 0.0736]])\n",
      "batch_y tensor([[0.0159],\n",
      "        [0.2004]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 370\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2905],\n",
      "        [-0.2671]])\n",
      "batch_y tensor([[0.0310],\n",
      "        [0.0076]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 371\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0854],\n",
      "        [-0.0790]])\n",
      "batch_y tensor([[0.2240],\n",
      "        [1.5125]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 372\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0335],\n",
      "        [0.1194]])\n",
      "batch_y tensor([[0.0316],\n",
      "        [0.0679]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 373\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0035],\n",
      "        [-0.0239]])\n",
      "batch_y tensor([[-0.8611],\n",
      "        [-0.1915]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 374\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0924],\n",
      "        [-0.1721]])\n",
      "batch_y tensor([[0.8969],\n",
      "        [0.4630]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 375\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.3034],\n",
      "        [-0.0092]])\n",
      "batch_y tensor([[ 1.0029],\n",
      "        [-0.0996]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 376\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0551],\n",
      "        [0.0025]])\n",
      "batch_y tensor([[0.0103],\n",
      "        [0.0217]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 377\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0864],\n",
      "        [0.0010]])\n",
      "batch_y tensor([[0.0622],\n",
      "        [0.6702]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 378\n",
      "================\n",
      "\n",
      "batch_x tensor([[ -0.0430],\n",
      "        [-22.1950]])\n",
      "batch_y tensor([[-0.5469],\n",
      "        [-0.1331]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 379\n",
      "================\n",
      "\n",
      "batch_x tensor([[-3.9765],\n",
      "        [-0.1599]])\n",
      "batch_y tensor([[ 0.1815],\n",
      "        [-0.0563]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 380\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0150],\n",
      "        [-0.0072]])\n",
      "batch_y tensor([[0.1102],\n",
      "        [0.2603]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 381\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0112],\n",
      "        [ 3.8335]])\n",
      "batch_y tensor([[-0.1118],\n",
      "        [ 0.0094]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 382\n",
      "================\n",
      "\n",
      "batch_x tensor([[ -0.0681],\n",
      "        [-13.5472]])\n",
      "batch_y tensor([[ 0.6968],\n",
      "        [-0.2685]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 383\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0306],\n",
      "        [0.0241]])\n",
      "batch_y tensor([[ 0.0366],\n",
      "        [-0.0175]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 384\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1794],\n",
      "        [ 0.1603]])\n",
      "batch_y tensor([[ 0.0365],\n",
      "        [-0.0601]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 385\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4430],\n",
      "        [ 0.1602]])\n",
      "batch_y tensor([[0.1011],\n",
      "        [0.1166]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 386\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2358],\n",
      "        [-0.0542]])\n",
      "batch_y tensor([[-0.0392],\n",
      "        [-0.1716]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 387\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0422],\n",
      "        [-0.0172]])\n",
      "batch_y tensor([[-0.2286],\n",
      "        [-0.0026]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 388\n",
      "================\n",
      "\n",
      "batch_x tensor([[-34.8098],\n",
      "        [ -0.3794]])\n",
      "batch_y tensor([[ 0.0648],\n",
      "        [-0.0759]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 389\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1939],\n",
      "        [0.1732]])\n",
      "batch_y tensor([[ 0.0532],\n",
      "        [-0.5055]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 390\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6707],\n",
      "        [0.0056]])\n",
      "batch_y tensor([[ 0.8919],\n",
      "        [-0.0999]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 391\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1399],\n",
      "        [0.0046]])\n",
      "batch_y tensor([[0.0084],\n",
      "        [0.0511]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 392\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0598],\n",
      "        [0.3054]])\n",
      "batch_y tensor([[ 0.0309],\n",
      "        [-0.5500]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 393\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0543],\n",
      "        [ 0.0034]])\n",
      "batch_y tensor([[-0.1267],\n",
      "        [-0.0027]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 394\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0515],\n",
      "        [-0.0168]])\n",
      "batch_y tensor([[ 0.0173],\n",
      "        [-1.1459]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 395\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.7334],\n",
      "        [-0.0259]])\n",
      "batch_y tensor([[-0.0711],\n",
      "        [ 0.0683]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 396\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0055],\n",
      "        [-0.0904]])\n",
      "batch_y tensor([[-0.1014],\n",
      "        [-0.0648]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 397\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.8350],\n",
      "        [ 0.0639]])\n",
      "batch_y tensor([[-0.1049],\n",
      "        [-0.0120]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 398\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0118],\n",
      "        [-0.0863]])\n",
      "batch_y tensor([[-0.0301],\n",
      "        [-0.4199]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 399\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0715],\n",
      "        [-0.0326]])\n",
      "batch_y tensor([[-0.0650],\n",
      "        [ 0.0807]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 400\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0317],\n",
      "        [0.1147]])\n",
      "batch_y tensor([[-0.6142],\n",
      "        [-0.0043]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 401\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3112],\n",
      "        [0.1981]])\n",
      "batch_y tensor([[-1.6625],\n",
      "        [ 0.4482]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 402\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0389],\n",
      "        [0.0049]])\n",
      "batch_y tensor([[0.0824],\n",
      "        [0.0956]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 403\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0933],\n",
      "        [-0.0745]])\n",
      "batch_y tensor([[ 0.0577],\n",
      "        [-0.1465]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 404\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1387],\n",
      "        [-0.3142]])\n",
      "batch_y tensor([[-0.0545],\n",
      "        [ 0.0192]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 405\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0131],\n",
      "        [ 0.0771]])\n",
      "batch_y tensor([[ 0.0804],\n",
      "        [-0.1744]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 406\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0628],\n",
      "        [-0.2179]])\n",
      "batch_y tensor([[ 0.0894],\n",
      "        [-0.0509]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 407\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0038],\n",
      "        [-0.4255]])\n",
      "batch_y tensor([[0.0021],\n",
      "        [1.8376]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 408\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0447],\n",
      "        [1.2070]])\n",
      "batch_y tensor([[ 0.1062],\n",
      "        [-0.0710]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 409\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6400],\n",
      "        [0.0466]])\n",
      "batch_y tensor([[-1.2248],\n",
      "        [ 0.0162]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 410\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0325],\n",
      "        [0.0076]])\n",
      "batch_y tensor([[-0.0564],\n",
      "        [ 0.7841]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 411\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0032],\n",
      "        [-0.1670]])\n",
      "batch_y tensor([[0.0582],\n",
      "        [0.1113]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 412\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0101],\n",
      "        [-0.0344]])\n",
      "batch_y tensor([[-0.3852],\n",
      "        [ 0.1966]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 413\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0149],\n",
      "        [ 0.1040]])\n",
      "batch_y tensor([[ 0.3111],\n",
      "        [-0.0756]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 414\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0717],\n",
      "        [0.0257]])\n",
      "batch_y tensor([[ -0.1507],\n",
      "        [-12.0153]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 415\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0738],\n",
      "        [-0.0588]])\n",
      "batch_y tensor([[0.3641],\n",
      "        [0.0633]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 416\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0906],\n",
      "        [-0.1169]])\n",
      "batch_y tensor([[-0.4131],\n",
      "        [-0.5648]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 417\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1835],\n",
      "        [ 0.0790]])\n",
      "batch_y tensor([[-0.0089],\n",
      "        [ 1.0403]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 418\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0532],\n",
      "        [-0.0027]])\n",
      "batch_y tensor([[ 0.0327],\n",
      "        [-0.0161]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 419\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.1721],\n",
      "        [0.2386]])\n",
      "batch_y tensor([[-0.0161],\n",
      "        [-0.1309]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 420\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0480],\n",
      "        [-0.1290]])\n",
      "batch_y tensor([[0.0613],\n",
      "        [0.0007]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 421\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1820],\n",
      "        [-0.0819]])\n",
      "batch_y tensor([[-0.3703],\n",
      "        [ 0.2819]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 422\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0768],\n",
      "        [-0.0377]])\n",
      "batch_y tensor([[0.5039],\n",
      "        [0.3356]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 423\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0234],\n",
      "        [ 0.4107]])\n",
      "batch_y tensor([[ 0.3033],\n",
      "        [-0.0836]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 424\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0316],\n",
      "        [0.3400]])\n",
      "batch_y tensor([[-0.2082],\n",
      "        [-0.3813]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 425\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1370],\n",
      "        [-0.4425]])\n",
      "batch_y tensor([[0.1234],\n",
      "        [0.7120]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 426\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3047],\n",
      "        [0.0271]])\n",
      "batch_y tensor([[-0.0050],\n",
      "        [ 0.3866]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 427\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0239],\n",
      "        [-0.1339]])\n",
      "batch_y tensor([[ 6.7613],\n",
      "        [-0.1319]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 428\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0136],\n",
      "        [-2.0326]])\n",
      "batch_y tensor([[0.5060],\n",
      "        [0.0056]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 429\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0290],\n",
      "        [ 0.0323]])\n",
      "batch_y tensor([[-0.0226],\n",
      "        [ 0.0044]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 430\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0307],\n",
      "        [-0.1156]])\n",
      "batch_y tensor([[ 0.0202],\n",
      "        [-0.0925]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 431\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0996],\n",
      "        [0.1220]])\n",
      "batch_y tensor([[-0.2761],\n",
      "        [-0.0397]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 432\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1843],\n",
      "        [-0.0389]])\n",
      "batch_y tensor([[-0.2624],\n",
      "        [-0.0900]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 433\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1113],\n",
      "        [-6.7449]])\n",
      "batch_y tensor([[ 0.1788],\n",
      "        [-0.0033]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 434\n",
      "================\n",
      "\n",
      "batch_x tensor([[-9.5231],\n",
      "        [ 0.0163]])\n",
      "batch_y tensor([[-0.4079],\n",
      "        [-1.0637]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 435\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2150],\n",
      "        [-0.2688]])\n",
      "batch_y tensor([[-0.0212],\n",
      "        [ 0.4213]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 436\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 9.2647],\n",
      "        [-0.2107]])\n",
      "batch_y tensor([[-0.4118],\n",
      "        [ 0.3215]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 437\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0043],\n",
      "        [ 0.1041]])\n",
      "batch_y tensor([[-0.6834],\n",
      "        [ 0.0924]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 438\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0795],\n",
      "        [0.0891]])\n",
      "batch_y tensor([[0.0482],\n",
      "        [0.0546]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 439\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0240],\n",
      "        [-0.0498]])\n",
      "batch_y tensor([[-0.0761],\n",
      "        [-0.2539]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 440\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0438],\n",
      "        [ 0.4920]])\n",
      "batch_y tensor([[-0.0088],\n",
      "        [-0.3303]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 441\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0557],\n",
      "        [0.4091]])\n",
      "batch_y tensor([[0.1199],\n",
      "        [0.0339]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 442\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0381],\n",
      "        [1.1099]])\n",
      "batch_y tensor([[-0.0628],\n",
      "        [-0.0403]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 443\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0036],\n",
      "        [0.1356]])\n",
      "batch_y tensor([[ 9.8770],\n",
      "        [-0.1491]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 444\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1813],\n",
      "        [-0.0022]])\n",
      "batch_y tensor([[-0.0378],\n",
      "        [-0.0289]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 445\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0332],\n",
      "        [ 0.0195]])\n",
      "batch_y tensor([[0.1379],\n",
      "        [0.3847]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 446\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3999],\n",
      "        [0.0219]])\n",
      "batch_y tensor([[-0.5492],\n",
      "        [-0.0034]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 447\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0940],\n",
      "        [-0.0674]])\n",
      "batch_y tensor([[ 1.3751],\n",
      "        [-0.2691]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 448\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.2773],\n",
      "        [-0.2214]])\n",
      "batch_y tensor([[0.0932],\n",
      "        [0.0134]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 449\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1227],\n",
      "        [-0.0372]])\n",
      "batch_y tensor([[-0.0346],\n",
      "        [-0.5305]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 450\n",
      "================\n",
      "\n",
      "batch_x tensor([[-2.8702],\n",
      "        [ 0.0218]])\n",
      "batch_y tensor([[-0.0834],\n",
      "        [ 0.0749]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 451\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1150],\n",
      "        [-3.6585]])\n",
      "batch_y tensor([[0.1704],\n",
      "        [0.0729]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 452\n",
      "================\n",
      "\n",
      "batch_x tensor([[9.2424],\n",
      "        [0.0230]])\n",
      "batch_y tensor([[-0.0536],\n",
      "        [-0.1815]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 453\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1337],\n",
      "        [-0.0626]])\n",
      "batch_y tensor([[-0.0082],\n",
      "        [-6.8772]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 454\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0140],\n",
      "        [-0.1029]])\n",
      "batch_y tensor([[0.0448],\n",
      "        [0.3501]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 455\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0207],\n",
      "        [-0.0347]])\n",
      "batch_y tensor([[0.4405],\n",
      "        [0.1468]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 456\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0405],\n",
      "        [-0.2424]])\n",
      "batch_y tensor([[ 0.0020],\n",
      "        [-0.2221]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 457\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2173],\n",
      "        [-0.1157]])\n",
      "batch_y tensor([[0.0259],\n",
      "        [0.2178]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 458\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6594],\n",
      "        [0.0835]])\n",
      "batch_y tensor([[0.0205],\n",
      "        [0.0360]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 459\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2270],\n",
      "        [ 0.1971]])\n",
      "batch_y tensor([[-0.1743],\n",
      "        [ 0.0739]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 460\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.7610],\n",
      "        [0.6642]])\n",
      "batch_y tensor([[0.1777],\n",
      "        [0.0938]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 461\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2797],\n",
      "        [ 0.0303]])\n",
      "batch_y tensor([[-0.2957],\n",
      "        [ 0.1629]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 462\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1120],\n",
      "        [ 0.1129]])\n",
      "batch_y tensor([[0.0543],\n",
      "        [0.1008]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 463\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0364],\n",
      "        [0.0650]])\n",
      "batch_y tensor([[ 0.0727],\n",
      "        [-0.0476]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 464\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.2232],\n",
      "        [ 0.1001]])\n",
      "batch_y tensor([[0.0623],\n",
      "        [0.0330]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 465\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.6143],\n",
      "        [0.0733]])\n",
      "batch_y tensor([[0.0234],\n",
      "        [0.0132]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 466\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0876],\n",
      "        [-0.0264]])\n",
      "batch_y tensor([[ 0.1390],\n",
      "        [-1.0639]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 467\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1487],\n",
      "        [-0.1119]])\n",
      "batch_y tensor([[-2.4040],\n",
      "        [ 0.0735]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 468\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2268],\n",
      "        [0.0372]])\n",
      "batch_y tensor([[0.1663],\n",
      "        [0.0465]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 469\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 5.9961],\n",
      "        [-0.1060]])\n",
      "batch_y tensor([[ 0.0227],\n",
      "        [-0.0911]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 470\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0322],\n",
      "        [-0.0216]])\n",
      "batch_y tensor([[-0.0967],\n",
      "        [-0.1879]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 471\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0244],\n",
      "        [-0.3087]])\n",
      "batch_y tensor([[-0.3775],\n",
      "        [ 0.0241]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 472\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.4044],\n",
      "        [-0.2070]])\n",
      "batch_y tensor([[-0.6524],\n",
      "        [-0.0589]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 473\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0185],\n",
      "        [-0.0119]])\n",
      "batch_y tensor([[-0.0824],\n",
      "        [-1.3602]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 474\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0129],\n",
      "        [0.0190]])\n",
      "batch_y tensor([[ 0.7761],\n",
      "        [-0.0100]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 475\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0853],\n",
      "        [-0.0957]])\n",
      "batch_y tensor([[ 0.0802],\n",
      "        [-0.1661]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 476\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 1.1196],\n",
      "        [-0.0095]])\n",
      "batch_y tensor([[-0.0656],\n",
      "        [ 0.6538]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 477\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0313],\n",
      "        [0.0504]])\n",
      "batch_y tensor([[ 0.4900],\n",
      "        [-0.1404]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 478\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3763],\n",
      "        [0.0860]])\n",
      "batch_y tensor([[ 0.0017],\n",
      "        [-0.0937]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 479\n",
      "================\n",
      "\n",
      "batch_x tensor([[-2.3456],\n",
      "        [-0.1487]])\n",
      "batch_y tensor([[-0.2963],\n",
      "        [-0.0216]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 480\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.4076],\n",
      "        [-0.2688]])\n",
      "batch_y tensor([[0.0470],\n",
      "        [0.0777]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 481\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.5226],\n",
      "        [0.3260]])\n",
      "batch_y tensor([[-0.3906],\n",
      "        [-0.3484]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 482\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0435],\n",
      "        [-0.1960]])\n",
      "batch_y tensor([[0.2335],\n",
      "        [0.0083]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 483\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0631],\n",
      "        [0.0215]])\n",
      "batch_y tensor([[-0.0763],\n",
      "        [ 0.0391]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 484\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.3218],\n",
      "        [0.1249]])\n",
      "batch_y tensor([[0.0328],\n",
      "        [0.4028]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 485\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0310],\n",
      "        [-0.4882]])\n",
      "batch_y tensor([[0.0145],\n",
      "        [0.1256]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 486\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0629],\n",
      "        [-0.2811]])\n",
      "batch_y tensor([[-0.3234],\n",
      "        [ 0.3160]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 487\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.2072],\n",
      "        [-0.0238]])\n",
      "batch_y tensor([[0.1975],\n",
      "        [0.0244]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 488\n",
      "================\n",
      "\n",
      "batch_x tensor([[-1.4746],\n",
      "        [-0.1237]])\n",
      "batch_y tensor([[ 0.3970],\n",
      "        [-0.1687]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 489\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0361],\n",
      "        [ 0.2331]])\n",
      "batch_y tensor([[ 0.3883],\n",
      "        [-0.0546]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 490\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.0487],\n",
      "        [0.5011]])\n",
      "batch_y tensor([[-0.0186],\n",
      "        [-0.2270]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 491\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.0274],\n",
      "        [-0.1232]])\n",
      "batch_y tensor([[-0.7972],\n",
      "        [-0.0628]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 492\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.3282],\n",
      "        [-0.0857]])\n",
      "batch_y tensor([[-1.0422],\n",
      "        [ 0.1795]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 493\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.1035],\n",
      "        [-0.4280]])\n",
      "batch_y tensor([[0.4045],\n",
      "        [0.0663]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 494\n",
      "================\n",
      "\n",
      "batch_x tensor([[-8.2897e-04],\n",
      "        [ 2.0909e+00]])\n",
      "batch_y tensor([[ 0.3119],\n",
      "        [-0.0635]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 495\n",
      "================\n",
      "\n",
      "batch_x tensor([[0.2488],\n",
      "        [0.0791]])\n",
      "batch_y tensor([[-0.0688],\n",
      "        [ 0.0168]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 496\n",
      "================\n",
      "\n",
      "batch_x tensor([[ 0.1057],\n",
      "        [-0.1561]])\n",
      "batch_y tensor([[-0.7170],\n",
      "        [-3.8083]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 497\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0251],\n",
      "        [ 0.0494]])\n",
      "batch_y tensor([[-0.6435],\n",
      "        [ 0.1046]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 498\n",
      "================\n",
      "\n",
      "batch_x tensor([[1.6100],\n",
      "        [0.0094]])\n",
      "batch_y tensor([[-0.1942],\n",
      "        [ 0.0123]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n",
      "iteration 499\n",
      "================\n",
      "\n",
      "batch_x tensor([[-0.0516],\n",
      "        [ 0.3371]])\n",
      "batch_y tensor([[0.1064],\n",
      "        [0.0517]])\n",
      "y_pred tensor([[nan],\n",
      "        [nan]], grad_fn=<MulBackward0>)\n",
      "weight nan\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "torch.manual_seed(4) # for reproducibility\n",
    "num_samples = 1000\n",
    "num_epochs = 10\n",
    "batch_size = 2\n",
    "lr = 0.01\n",
    "w_init = torch.Tensor([0.1])\n",
    "\n",
    "# x_data, y_data = torch.normal(0, 1, (2, num_samples))\n",
    "m = torch.distributions.Cauchy(torch.tensor([0.0]), torch.tensor([0.1]))\n",
    "x_data, y_data = m.sample((2, num_samples))\n",
    "\n",
    "dataset = TensorDataset(x_data, y_data)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Train function\n",
    "model = TrivialModel(w_init)\n",
    "loss_values, weights_over_epochs =  train_model(model, data_loader, linear = False, num_epochs = num_epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_range = np.linspace(-2*10**4, 10**4, 10000)\n",
    "fig, ax = plt.subplots()\n",
    "plot_loss_landscape(ax, model, x_data, y_data, weight_range, weights_over_epochs, linear=False)\n",
    "ax.set_yscale('linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06635119765996933,\n",
       " 0.0787595584988594,\n",
       " 0.06890074908733368,\n",
       " 0.06352823972702026,\n",
       " 0.0793941542506218,\n",
       " 0.06603951752185822,\n",
       " 0.07806762307882309,\n",
       " 0.08320670574903488,\n",
       " 0.07042593508958817,\n",
       " 0.07850005477666855]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_over_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(weights_over_epochs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Distribution of w looks Gaussian\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(weights_over_epochs, bins=\"auto\")\n",
    "# ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "$\\var w$ is looks like its growing linearly\n",
    "\"\"\"\n",
    "cv = np.convolve(weights_over_epochs, weights_over_epochs)[:len(weights_over_epochs)//2]\n",
    "plt.plot(cv)\n",
    "df = pd.DataFrame(cv)\n",
    "plt.plot(df.rolling(window=50).mean(), '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion in the non-trivial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingModel(torch.nn.Module):\n",
    "    def __init__(self, w0:float, d1:int, d2:int, in_features:int, cst: float,\n",
    "                 out_features:int, w_init: Optional[Tensor] = None) -> None:\n",
    "        super(SingModel, self).__init__()\n",
    "        self.w0 = w0\n",
    "        self.d1 = d1\n",
    "        self.d2 = d2\n",
    "        self.cst = cst\n",
    "        self.eps = 0.\n",
    "        if w_init is not None:\n",
    "            self.weight = torch.nn.Parameter(w_init)\n",
    "        else:\n",
    "            self.weight = torch.nn.Parameter(torch.randn((out_features, in_features)))\n",
    "         \n",
    "#     def forward(self, input:Tensor):\n",
    "#         # Chose cst1 and cst2 such that K(1) = 0 and K'(1) = cst\n",
    "#         cst1 = - self.cst**(1/3)/2**(1/3)\n",
    "#         cst2 = (16*self.cst - 2**(2/3)*self.cst**(4/3))/64\n",
    "#         sing1 = (self.weight + self.w0)**self.d1\n",
    "#         sing2 = torch.sqrt((self.weight - self.w0 + cst1)**(2*self.d2) + cst2)\n",
    "#         return input * (sing1 * sing2 + 1.)\n",
    "\n",
    "    def forward(self, input:Tensor):\n",
    "        return input * (self.weight + self.w0) * self.weight**2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_init = -1.2\n",
    "num_samples = 2000\n",
    "num_epochs = 5000\n",
    "batch_size = 10\n",
    "lr = 0.05\n",
    "cst = 0\n",
    "\n",
    "# Generate data\n",
    "w_init = torch.Tensor([[w_init]])\n",
    "torch.manual_seed(4) # for reproducibility\n",
    "x_data = torch.normal(0, 1, (num_samples, 1))\n",
    "y_data = torch.normal(0, 1, (num_samples, 1))\n",
    "dataset = TensorDataset(x_data, y_data)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training\n",
    "model = SingModel(w0=1.1, d1=2, d2=3, in_features=1, out_features=1, \n",
    "                  cst=cst, w_init=w_init)\n",
    "loss_values, weights_over_epochs =  train_model(model, data_loader, w_init=w_init,\n",
    "                                                linear=False, num_epochs = num_epochs, lr=lr)\n",
    "plot_loss_curve(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss landscape\n",
    "weight_range = np.linspace(-1.4, .3, 100)\n",
    "model = SingModel(w0=1.1, d1=2, d2=3, in_features=1, out_features=1, \n",
    "                  cst=cst, w_init=w_init)  # create a model instance\n",
    "fig, ax = plt.subplots()\n",
    "plot_loss_landscape(ax, model, x_data, y_data,\n",
    "                        weight_range, weights_over_epochs, linear=False)\n",
    "plt.show()\n",
    "fig.savefig(\"loss_landscape.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cauchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pramaters\n",
    "w_init = -.5\n",
    "num_samples = 10**4\n",
    "num_epochs = 100\n",
    "batch_size = 10\n",
    "lr = 0.00001\n",
    "cst = 0\n",
    "\n",
    "# Generate data\n",
    "w_init = torch.Tensor([[w_init]])\n",
    "torch.manual_seed(42) # for reproducibility\n",
    "\n",
    "m = torch.distributions.Cauchy(torch.tensor([0.0]), torch.tensor([0.1]))\n",
    "x_data, y_data = m.sample((2,num_samples))\n",
    "\n",
    "dataset = TensorDataset(x_data, y_data)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training\n",
    "model = SingModel(w0=1.1, d1=2, d2=3, in_features=1, out_features=1, \n",
    "                  cst=cst, w_init=w_init)\n",
    "loss_values, weights_over_epochs =  train_model(model, data_loader, w_init=w_init,\n",
    "                                                linear=False, num_epochs = num_epochs, lr=lr)\n",
    "plot_loss_curve(loss_values)\n",
    "print(weights_over_epochs[0])\n",
    "\n",
    "# Plot loss landscape\n",
    "weight_range = np.linspace(-2, 2, 100)\n",
    "model = SingModel(w0=1.1, d1=2, d2=3, in_features=1, out_features=1, \n",
    "                  cst=cst, w_init=w_init)  # create a model instance\n",
    "plot_loss_landscape(model, x_data, y_data,\n",
    "                        weight_range, weights_over_epochs, linear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
