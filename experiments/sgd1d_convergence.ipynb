{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from typing import Optional\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    Langevin dynamics approximating SGD on a 1D model\n",
    "    \"\"\"\n",
    "    def __init__(self, lr, q, grad_q, mxx, std_xx, std_xy, w_init, seed):\n",
    "        \"\"\"\n",
    "        lr: learning rate\n",
    "        q: model\n",
    "        grad_q: gradient of the model\n",
    "        mxx: expected value of X^2\n",
    "        vxx: Var(X^2)\n",
    "        vxy: Var(XY)\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.q = q\n",
    "        self.grad_q = grad_q\n",
    "        self.mxx = mxx\n",
    "        self.std_xx = std_xx\n",
    "        self.std_xy = std_xy\n",
    "        self.w_init = w_init\n",
    "        self.w = [self.w_init]\n",
    "        self.state = np.random.RandomState(seed=seed)\n",
    "        \n",
    "    def update(self, w_old, d1, d2,a=-1,b=1):\n",
    "        xi_xx = self.state.normal(self.mxx, self.std_xx)\n",
    "        xi_xy = self.state.normal(0.0, self.std_xy)\n",
    "        return w_old - self.lr*(xi_xx * self.q(w_old, d1, d2,a,b) - xi_xy) * self.grad_q(w_old, d1, d2,a,b)\n",
    "    \n",
    "    def evolve(self, nstep, d1, d2,a=-1,b=1):\n",
    "        wc = self.w[-1]\n",
    "        for _ in range(nstep):\n",
    "            wc = self.update(wc, d1, d2,a,b)\n",
    "            self.w.append(wc)\n",
    "\n",
    "def q(w, d1 ,d2, a=-1, b=1):\n",
    "    return (w - a)**d1 * (w - b)**d2\n",
    "    \n",
    "def grad_q(w, d1, d2, a=-1, b=1):\n",
    "    return (w-a)**(d1-1) * (w - b)**(d2-1) * (d1 * (w -a) + d2*(w - b))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
