# Some Questions:

* Do we know wether NN are singular in full generality: 3 sources of evidence:
  * Proof that ReLu NN. are strictly singular
  * Empirical evidence hessian degeneracy
  * What about general NN such as transformers etc?
* Internal model selection, restricted free energy and local/effective potential
* How often should we expect phase transitions to happen in neural network?
* Link between critical points and singularities of the domain on which K is 0. Link between singularity and singular models
* How constraining is the nonrealisability assumption? For example if we do not have it, can we just study the empirical KL between local minima and Ln? But there are many local minima, which one to chose?
  * See relative finite variance/renormalisability
* How large n needs to be for the asymptotic expansion to be valid?
  * Just look at the Fn expansion!
* Intuition behind RLCT, degeneracy of a node, symmetry around a critical point.
* Local Symetries around critical points are important. Can we formalise in interesting ways?
* Are the lotery ticket hypothesis and SLT really that incompatible?
* Something something jet schemes and excpetional divisors
* Intuition about SGD and fluctuations of K
* 



